[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Processos Estocásticos: Um Curso de Graduação",
    "section": "",
    "text": "Apresentação\n\nDisciplina: Processos Estocásticos  Código: IEE018  Pré–Requisito: Probabilidade C (IEE057)  Créditos: 4  Carga Horária: 60h \n\nObjetivos: Apresentar resultados da teoria elementar de probabilidade aplicada ao estudo de processos estocásticos e os principais modelos desses processos.\n\nEmenta:\n\nClassificação e caracterização de processos estocásticos;\nCadeia de Markov a parâmetro discreto;\nCadeia de Markov à parâmetro contínuo;\nProcesso de Poisson;\nProcesso de Renovação.\n\n\nReferências Básicas:\n\nCLARKE, A. B., DISNEY, R. L. Probabilidade e Processos Estocásticos, Rio de Janeiro: Livros Técnicos e Científicos Editora, 1979.\nGrimmett, G. R. e Stirzaker, D. R. Probability and Random Processes. 3a ed. Oxford University Press, 2001.\nHoel, P. G., Port, S. C. e Stone, C. J. Introduction to Stochastic Processes. Waveland Press, 1972.\n\n\nReferências Complementares:\n\nKarlin, S. e Taylor, H. M. A First Course in Stochastic Processes. 2a ed. Academic Press, 1975.\nKarlin, S. e Taylor, H. M. An Introduction to Stochastic Modeling. 3a ed. Academic Press, 1998.\nRoss, S. M. Introduction to Probability Models. 10a ed. Academic Press, 2010.\nPapoulis, A. Probability, Random Variables and Stochastic Processes. 3ª Ed. McGraw Hill, 1991.\nMagalhães, M. N. Introdução a redes de filas. 12o. SINAPE. Caxambu, 1996."
  },
  {
    "objectID": "cap_1_pe.html#introdução",
    "href": "cap_1_pe.html#introdução",
    "title": "1  Processos Estocásticos",
    "section": "1.1 Introdução",
    "text": "1.1 Introdução\nUma coleção de variáveis aleatórias é denominada processo estocástico.\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 1.1 O conjunto \\(\\{X(t),t\\in \\mathcal{T}\\}\\), onde \\(X(t)\\) é uma variável aleatória para cada \\(t \\in \\mathcal{T}\\subset \\mathbb{R}\\), é um processo estocástico.\n\n\n\nO conjunto dos possíveis valores de \\(X(t)\\) é denominado espaço dos estados e o conjunto \\(\\mathcal{T}\\) é denominado espaço do tempo ou conjunto de índices1.\nSe \\(\\mathcal{T}\\) for um conjunto contínuo, diremos que \\(\\{X(t),t\\in\\mathcal{T}\\}\\) é um processo a tempo contínuo e será mantida a notação \\(X(t)\\). Se \\(\\mathcal{T}\\) for discreto, diremos que \\(\\{X_t,t\\in\\mathcal{T}\\}\\) é um processo a tempo discreto (neste caso, a notação \\(X_t\\) é mais conveniente).\n\n\n\n\n\n\nExemplo: Amostra iid\n\n\n\n\nExemplo 1.1 Sejam \\(X_1,X_2,\\ldots,X_n\\), variáveis aleatórias independentes e identicamente distribuídas com \\(X_i\\in D\\subseteq \\mathbb{R}\\). Neste caso, temos que \\(\\{X_i: i=1,2,\\ldots,n\\}\\) é um processo estocástico a tempo discreto, com espaço dos estados igual a \\(D\\).\n\n\n\nNo exemplo acima, os índices não possuem influência. De fato, como as variáveis são iid, para qualquer permutação \\(\\{t_1,\\ldots,t_n\\}\\) dos índices em \\(\\mathcal{T}\\), tem-se que \\(\\{X_1,X_2,\\ldots,X_n\\}\\sim\\{X_{t_1},X_{t_2},\\ldots,X_{t_n}\\}\\). Os próximos exemplos ilustram casos nos quais os índices desempenham um papel fundamental.\n\n\n\n\n\n\nExemplo: Reposição de estoque - caso simples\n\n\n\n\nExemplo 1.2 Um funcionário de uma loja deve verificar o estoque de certo produto no fim de cada dia. Seja \\(X_i\\) o número de itens deste produto no \\(i\\)-ésimo dia. Temos então o processo estocástico \\(\\{X_i:i=0,1,2,\\ldots\\}\\), onde \\(X_0\\) é o estoque no momento inicial. Claramente, enquanto não houver reposição de estoque, o \\(X_i\\leq X_{i-1}\\) para todo \\(i=1,2,\\ldots\\). Neste caso, as variáveis \\(X_i\\) e \\(X_{i-1}\\) são dependentes e não possuem a mesma distribuição. Considere o seguinte caso particular:\n\nO estoque suporta no máximo três itens.\nNo instante inicial, o estoque está cheio (\\(X_0=3\\)).\nEm cada dia, o número de itens que é retirado do estoque tem distribuição \\(Bernoulli(p)\\).\nQuando o estoque chega a zero ao final do dia, a reposição é feita de noite, de modo que haverão 3 itens em estoque no dia seguinte.\n\nSeja \\(Z_i\\sim\\hbox{Benoulli}(p)\\), onde \\(Z_i\\) é independente de \\(Z_j\\) para todo \\(i\\neq j\\) (esta variável representa o que foi subtraído do estoque no dia \\(i\\)). Então, se \\(X_i\\neq 0\\), tem-se que \\[X_{i+1}=X_i-Z_i\\] e quando \\(X_i=0\\) (o estoque no dia \\(i\\) está vazio) tem-se que \\[X_{i+1}=3.\\] Este processo estocástico pode ser resumido pelo seguinte grafo, onde cada vértice representa um dos possíveis valores da variável \\(X_i\\) e cada aresta mostra a probabilidade de \\(P(X_{n+1}=j|X_{n}=i)\\), onde \\(i\\) é o vértice de origem e \\(j\\) o de destino.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExemplo: Visualizações de Os Simpsons\n\n\n\n\nExemplo 1.3 O gráfico abaixo mostra o número de visualizações, em milhões nos EUA, dos episódios de Os Simpsons, para as dez primeiras temporadas. Pode-se definir um processo estocástico onde \\(X_i\\) é o número de visualizações do \\(i\\)-ésimo episódio.\n\n\n\n\n\n\n\n\n\nNote que, na medida que o número de episódios aumenta, há uma tendência de queda nos valores observados do processo."
  },
  {
    "objectID": "cap_1_pe.html#processos-estacionários",
    "href": "cap_1_pe.html#processos-estacionários",
    "title": "1  Processos Estocásticos",
    "section": "1.2 Processos Estacionários",
    "text": "1.2 Processos Estacionários\nUm processo estocástico \\(\\{X(t),t\\in\\mathcal{T}\\}\\) é dito ser estacionário se \\(P(X(t)<x)=P(X(t+k)<x)\\) para todo \\(k\\). Isto quer dizer que a distribuição permanece inalterada com a mudança do índice.\n\n\n\n\n\n\nExemplo: Amostra iid\n\n\n\n\nExemplo 1.4 Se \\(X_1,X_2\\ldots,\\) é um processo formado por variáveis independentes e identicamente distribuídas, então, \\[P(X_{t}<x)=P(X_{t+k}<x)=P(X_1<x)\\] para todo \\(k=0,1,2,\\ldots\\). Portanto, uma amostra de vaiid é um processo estacionário.\n\n\n\n\n\n\n\n\n\nExemplo: Estoque simples\n\n\n\n\nExemplo 1.5 Considere o processo estocástico dado no Exemplo 1.2, onde\n\\[X_i=\\left\\{ \\begin{array}{ll}X_{i-1}-Z, & \\hbox{se  }X_{i-1}>0 \\\\ 3, & \\hbox{se  } X_{i-1}=0 \\end{array}\\right.\\]\ncom \\(Z_i\\sim\\hbox{Bernoulli}(p)\\) independente de \\(Z_j\\) para todo \\(i\\neq j\\). Note que\n\\[\\begin{align*}\nP(X_1\\leq 2) &= P(Z_1=1) = p\\\\\nP(X_2\\leq 2) &= P(Z_1=1,Z_2=1) +P(Z_1=0,Z_2=1)+P(Z_1=1,Z_2=0)\\\\\n&= p^2 + 2p(1-p)\n\\end{align*}\\] Como \\(P(X_1\\leq 2)\\neq P(X_2\\leq 2)\\), este processo não é estacionário.\n\n\n\n\n\n\n\n\n\nExemplo: Visualizações de Os Simpsons\n\n\n\n\nExemplo 1.6 Considere novamente o processo estocástico \\(X_i\\), onde \\(i\\)-é é a visualização registrada no dia da exibição do \\(i\\)-ésimo episódio desta série. Note que conhecemos o processo estocástico, mas apenas temos uma amostra observada deste. Contudo, existem evidências de que este processo não é estacionário. Por exemplo, podemos notar que existe uma tendência de queda, algo que seria esperado se o processo fosse estacionário."
  },
  {
    "objectID": "cap_1_pe.html#processos-de-contagem",
    "href": "cap_1_pe.html#processos-de-contagem",
    "title": "1  Processos Estocásticos",
    "section": "1.3 Processos de contagem",
    "text": "1.3 Processos de contagem\nUm processo \\(\\{N(t),t>0\\}\\) com espaço dos estados igual a \\(\\{0,1,2,\\ldots\\}\\) é denominado processo de contagem se, para qualquer \\(t\\), a variável aleatória \\(N(t)\\) representar o total de eventos que ocorreram durante o intervalo de tempo \\([0,t]\\).\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 1.2 O processo estocástico \\(\\{N(t),t\\geq 0\\}\\) é um processo de contagem (PC) se \\(N(t)\\) representa o total de eventos ocorridos até o tempo \\(t\\). Um processo de contagem deve satisfazer:\n\n\\(N(t)\\geq 0\\);\n\\(N(t)\\) é inteiro positivo;\nSe \\(s<t\\), então \\(N(s)\\leq N(t)\\).\n\n\n\n\nA diferença \\(N(r)-N(s)\\), com \\(r>s\\), é denominada incremento e representa o número de ocorrências no intervalo \\((s,r]\\). A figura abaixo ilustra um processo de contagem. Nesta, o tempo de ocorrência do evento é representado no eixo Tempo através de um círculo. Acima do eixo do tempo estão registrados os valores do processo \\(N(t)\\) para os tempo \\(t=2,6,8,13\\). Abaixo do eixo estão registrados o número de ocorrências entre estes tempos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExemplo: Volume de vendas simples\n\n\n\n\nExemplo 1.7 Suponha que o número de vendas diárias de certo estabelecimento tem distribuição Poisson, sendo que as vendas são independentes. Defina o processo \\(\\{N(t),t\\geq 0\\}\\) como \\[N(t)=\\sum_{j=1}^{\\lfloor t\\rfloor} X_j,\\] onde \\(\\lfloor t\\rfloor\\) é a parte inteira de \\(t\\) e \\(X_t\\sim\\hbox{Poisson}(\\lambda)\\). Defina \\(N(0)=0\\). Note que este processo representa o volume de vendas até o tempo \\(t\\). Vamos mostrar que \\(\\{N(t)\\}\\) é um processo de contagem provando as seguintes proposições:\n\n\nProposição 1: \\(N(t)\\geq 0\\).Prova: Para \\(t=0,1,2,\\ldots\\), temos que \\(X_t\\geq 0\\).Então \\(N(t)\\) é a soma de número não negativos e, portanto, maior que zero.\n\n\n\n\nProposição 2: \\(N(t)\\) é inteiro positivo.Prova: segue pelo fato de que \\(N(t)\\) é soma de números naturais.\n\n\n\n\nProposição 3: Se \\(s<t\\), então \\(N(s)\\leq N(t)\\)  Prova: Para \\(s<t\\), teremos que \\[N(t)-N(s)=X_{\\lfloor s\\rfloor+1}+\\cdots +X_{\\lfloor t\\rfloor}\\geq 0,\\] pois \\(X_t\\geq0\\) para \\(t\\in\\mathbb{N}\\).\n\n\n\n\n\n\n1.3.1 Incrementos independentes\n\n\n\n\n\n\nDefinição: Incrementos Independentes\n\n\n\n\nDefinição 1.3 Dizemos que um PC possui incrementos independentes se, para quaisquer dois intervalos disjuntos \\((s_1,r_1]\\) e \\((s_2,r_2]\\) teremos que os incrementos \\(N(r_1)-N(s_1)\\) e \\(N(r_2)-N(s_2)\\) são independentes. Em outras palavras, os incrementos do PC em intervalos disjuntos são independentes.\n\n\n\n\n\n\n\n\n\nExemplo: Volume de vendas simples\n\n\n\n\nExemplo 1.8 Voltando ao nosso exemplo, vamos provar que \\(\\{N(t),t\\geq 0\\}\\) tem incrementos independentes. Considere os intervalos arbitrários da Definição 1.3. Teremos:\n\\[\\begin{align*}\n    &P(N(r_1)-N(s_1)=n,N(r_2)-N(s_2)=m)=\\\\ \\\\\n    &P\\left(\\sum_{i=\\lfloor s_1 \\rfloor +1}^{\\lfloor r_1 \\rfloor}\n    X_i=n,\\sum_{j=\\lfloor s_2 \\rfloor +1}^{\\lfloor r_2\\rfloor }\n    X_j=m\\right)=\\\\ \\\\\n    &P\\left(\\sum_{i=\\lfloor s_1 \\rfloor+1}^{\\lfloor r_1 \\rfloor}\n    X_i=n\\right)P\\left(\\sum_{j=\\lfloor s_2 \\rfloor +1}^{\\lfloor r_2 \\rfloor}\n    X_j=m\\right)=\\\\ \\\\\n    &P(N(r_1)-N(s_1)=n)P(N(r_2)-N(s_2)=m)\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nExemplo: Artigos na Wikipedia\n\n\n\n\nExemplo 1.9 A figura abaixo mostra o número de artigos publicados (em lingua inglesa) na Wikipedia, contados em cada 1 de Janeiro, entre 2002 e 2018. Você pode acessar os dados aqui.\n\n\n\n\n\n\n\n\n\nConsidere \\(N(t)\\) o número de artigos publicados até o ano \\(t\\) (neste caso, \\(t=0\\) representa o ano de 2001, \\(t=1\\) o de 2002, e assim por diante). A figura acima ilustra o \\(N(t)\\) observado.\nEvidenciar que o processo \\(\\{N(t),t\\geq0\\}\\) não tem incrementos indepndentes é uma tarefa simples. Por exemplo, considere o incremento \\(P_{t}=X(t,t-1)\\), que representa o número de artigos publicados no ano \\(t\\) e considere a autocorrelação \\[r =\n\\frac{\\sum_{t=2}^{n}(P_t -\n\\bar{P})(P_{t-1}-\\bar{P})}{(n-1)S_p^2},\\] onde \\(n\\) \\((=15)\\) é o número de incrementos, \\(\\bar{P}\\) e \\(S_p^2\\) são a média e variância amostrais de \\(P_t\\). Se os incrementos forem independentes, \\(r\\) deveria está próximo de zero. Entretanto, temos que \\[r = 0,697,\\] com um erro padrão2 estimado em \\(0,10\\). Portanto, um intervalo com confiança aproximadamente igual a 95% é dado por \\((0,48\\;\\;,\\;\\;0,91)\\). Como este intervalo está afastado de zero, temos evidências de que os incrementos deste processo não são independentes.\n\n\n\n\n\n1.3.2 Incrementos estacionários\n\n\n\n\n\n\nDefinição: Incrementos Estacionários\n\n\n\n\nDefinição 1.4 Dizemos que um PC possui incrementos estacionários se, para um intervalo \\((s,s+h]\\) a distribuição de \\(N(s+h)-N(s)\\) depende apenas de \\(h\\) (mas não de \\(s\\)).\n\n\n\n\n\n\n\n\n\nExemplo: Volume de vendas simples\n\n\n\n\nExemplo 1.10 Voltando ao nosso exemplo, para quaisquer \\(s,h>0\\), teremos que \\[\\begin{align*}\n    N(s+h)-N(s) = \\sum_{j=\\lfloor s \\rfloor+1 }^{\\lfloor s+h \\rfloor}X_j.\n    \\end{align*}\\]\nComo o lado direito da igualdade acima é descrito como a soma de variáveis aleatórias independentes com distribuição Poisson\\((\\lambda)\\), teremos que \\[N(s+h)-N(s) \\sim\\hbox{Poisson}\\left( \\sum_{j=\\lfloor s \\rfloor+1 }^{\\lfloor s+h \\rfloor}\\lambda\\right)\\] Utilizando o fato de que, para quaisquer \\(a,b\\) \\[\\lfloor a+b \\rfloor - \\lfloor a \\rfloor =b,\\] teremos que \\[\\sum_{j=\\lfloor s \\rfloor+1 }^{\\lfloor s+h \\rfloor}\\lambda=\\lambda\\left\\{[ \\lfloor s+h \\rfloor -(\\lfloor s \\rfloor+1 )+1 \\right\\}\\lambda h.\\] Portanto, \\(N(s+h)-N(s)\\sim\\hbox{Poisson}(\\lambda h)\\) e, como esta distribuição depende apenas de \\(h\\), teremos que os incrementos do processo são estacionários."
  },
  {
    "objectID": "cap_1_pe.html#exercícios",
    "href": "cap_1_pe.html#exercícios",
    "title": "1  Processos Estocásticos",
    "section": "1.4 Exercícios",
    "text": "1.4 Exercícios\n\n\n\n\n\n\n\n\n\n\n\nExercício 1.1 \n\nSeja \\(\\{X(t),t>0\\}\\), com \\(X(t)\\in\\{0,1\\}\\) a classificação de uma pessoa como sadia (\\(X(t)=0\\)) ou doente \\((X(t)=1)\\). Identifique o espaço dos estados, o conjunto de índices e classifique este processo como a tempo discreto ou contínuo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 1.2 \n\nSeja \\(\\{X_i,i=1,2,\\ldots,\\}\\) um processo estocástico onde \\[\\begin{align*}\n  X_0 &= \\mu \\\\\n  X_{t+1} &= X_{t} + \\varepsilon_{t+1},\n\\end{align*}\\]\nonde \\(\\mu\\) é uma constante arbitrária, \\(\\varepsilon_t\\sim\\hbox{Normal}(0,1)\\) e \\(\\varepsilon_i\\) é independente de \\(\\varepsilon_j\\) para todo \\(i\\neq j\\).\n\n\nDetermine o espaço dos estados e o conjunto de índices deste processo.\nMostre que \\(\\{X_t,t=0,1,\\ldots\\}\\) não é um processo de contagem.\nMostre que \\[X_t = \\mu + \\sum_{j=1}^{t}\\varepsilon_j,\\]\ne determine a distribuição de \\(X_t\\). Conclua que este processo não é estacionário.\nProve que o processo \\(\\{X_{t+1}-X_t,t=1,2,\\ldots\\}\\) é estacionário.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 1.3 \n\nSeja \\(\\{X_t, t=0,1,\\ldots,\\}\\) um processo estocástico onde \\[\\begin{align*}\n  X_0 &= 0 \\\\\n  X_{t+1} &= X_{t}+ Z_{t+1}\n\\end{align*}\\] onde \\(Z_t\\sim\\hbox{Bernoulli}(1/2)\\) e \\(Z_i\\) é independente de \\(Z_j\\) para qualquer \\(i\\neq j\\).\n\n\nIdentifique o espaço dos estados e o conjunto de índices deste processo.\nMostre que \\(\\{X_t,t=0,1\\ldots,\\}\\) é um processo de contagem.\nMostre que \\(X_t=Z_1+\\cdots +Z_t\\). Qual é a distribuição de \\(X_t\\)?\nO processo tem incrementos independentes?\nO processo tem incrementos estacionários?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 1.4 \n\nSeja \\(\\{N(t),t\\geq 0\\}\\) um processo de contagem com incrementos estacionários, com \\(N(0)=0\\). Prove que \\(N(t+s)-N(s)\\) e \\(N(t)\\) tem a mesma distribuição."
  },
  {
    "objectID": "cap_2_poisson.html#introdução",
    "href": "cap_2_poisson.html#introdução",
    "title": "2  Processo de Poisson",
    "section": "2.1 Introdução",
    "text": "2.1 Introdução\nO número de acidentes aéreos por mês, de suicídios por ano e de novos casos de hanseníase possuem uma característica comum: todos são processos de contagem. Neste capítulo é apresentado um processo de contagem, denominado Processo de Poisson, definido formalmente a seguir.\n\n\n\n\n\n\nDefinição: Processo de Poisson\n\n\n\n\nDefinição 2.1 Um processo de contagem \\(\\{ N(t),t\\geq 0 \\}\\) é um processo de Poisson (PP) se:\n\n\\(N(0)=0\\)\nO processo possui incrementos independentes e estacionários.\nPara qualquer intervalo de comprimento \\(t\\), teremos\n\n\\[\\begin{equation}\nP(N(t)=n)=\\frac{e^{-\\lambda t}(\\lambda t)^n}{n!}\n\\end{equation}\\]\nO parâmetro \\(\\lambda\\) é denominado taxa do processo.\n\n\n\nPortanto, o PP é um processo de contagem com incrementos independentes e estacionários, cuja distribuição é Poisson com taxa proporcional ao tempo \\(t\\).\n\n\n\n\n\n\nExemplo: Terremotos no Estreito de Messina\n\n\n\n\nExemplo 2.1 O gráfico abaixo apresenta a sequência histórica de terremotos em uma região ao redor do Estreito de Messina, que divide a ilha da Sicília, na Itália continental. A tabela está limitada aos terremotos de magnitude 4,5 ou superior, durante o período de 1700-1980. Os dados estão em frações de ano (ou seja, a parte fracionária vezes 365 dá o dia da ocorrência dentro do ano).\n\n\n\n\n\n\n\n\n\nSeja \\(n(t)\\) o número de terremotos observados até o tempo \\(t\\). O gráfico acima mostra os pares \\((t, n(t))\\). Note o comportamento aproximadamente linear. Lembremos que em um PP, \\(E(N(t))=\\lambda t\\). Portanto, em média, existe uma relação linear entre \\(N(t)\\) e \\(t\\). Voltaremos neste exemplo posteriormente para verificar se ele pode ser modelado por um PP."
  },
  {
    "objectID": "cap_2_poisson.html#tempos-de-chegada-e-de-espera",
    "href": "cap_2_poisson.html#tempos-de-chegada-e-de-espera",
    "title": "2  Processo de Poisson",
    "section": "2.2 Tempos de Chegada e de Espera",
    "text": "2.2 Tempos de Chegada e de Espera\n\n2.2.1 Definições e propriedades\nO tempo de chegada, denotado por \\(T_{n}\\), é o tempo transcorrido entre a chegada da \\((n-1)\\)-ésima e da \\(n\\)-ésima ocorrência. Seu comportamento pode revelar características importantes sobre o processo. Em especial, se \\(\\{N(t),t>0\\}\\) é um PP, temos a seguinte proposição.\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 2.1 Consideremos um processo de Poisson e sejam \\(T_1,T_2,T_3,\\ldots\\) os tempos de chegada dos eventos 1, 2, 3\\(\\ldots\\). Então:\n\nOs tempos de chegada são identicamente distribuídos, com \\(T_i\\sim\\hbox{Exponencial}(\\lambda)\\), i.é, \\[f_{T_i}(t)=\\lambda e^{-\\lambda t},\\lambda>0,t>0.\\] onde \\(\\lambda\\) é a taxa do processo de Poisson.\nOs tempos de chegada são independentes.\n\nDemonstração: Temos:\n\nComecemos com o primeiro tempo de chegada. Notemos que \\(T_1>t\\) implica que a primeira chegada só ocorreu após o tempo \\(t\\). Isto quer dizer que não ocorreram chegadas antes de \\(t\\). Disto, \\[\\begin{align*}\nP(T_1>t)&=P(N(t)=0)=e^{-\\lambda t}.\n\\end{align*}\\] Como \\[F_{T_1}(t)= 1-P(T_1>t)=1-e^{-\\lambda t},\\] temos que \\[f_{T_1}(t)=\\frac{d}{dt}F_{T_1}(t)=\\lambda e ^{-\\lambda t}.\\] Portanto, \\(T_1\\sim\\hbox{Exponencial}(\\lambda)\\).\n\nAgora, suponha que \\(T_{n-1}\\sim \\hbox{Exponencial}(\\lambda)\\) (o que é verdade para \\(n=1\\)). Observe a figura abaixo.\n\n\n\n\n\n\n\n\n\nConsidere que o tempo de chegada da \\(n\\)-ésima observação é maior que \\(t\\) unidades de tempo. Se sabemos que o tempo da \\((n-1)\\)-ésima ocorrência foi \\(s\\), sabemos também que a \\(n\\)-ésima ocorrência ocorreu depois do tempo \\(t+s\\). Logo, não houveram ocorrências no intervalo \\((s,t+s]\\), fazendo com que \\(N(t+s)-N(s)=0\\). Mas, como o processo possui incrementos estacionários, temos que \\(N(t+s)-N(s)\\sim N(t)-N(0)\\equiv N(t)\\). Assim,\n\\[\\begin{align*}\nP(T_n > t)&=\\int_0^{\\infty}P(T_{n}>t| T_{n-1}=s)f_{T_1}(s)ds\\\\\n&=\\int_0^{\\infty}P(T_{n}>t| T_{n-1}=s)\\lambda e^{-\\lambda s}ds\\\\\n&=\\int_{0}^{\\infty}P(N(t+s)-N(s)=0)\\lambda e^{-\\lambda s}ds, \\left(\\hbox{ incrementos estacionários}\\right)\\\\\n&=\\int_0^{\\infty}P(N(t)=0)\\lambda e^{-\\lambda s}ds \\\\\n&=\\int_0^{\\infty}e^{-\\lambda t}\\lambda e^{-\\lambda s}ds=e^{-\\lambda t}\\underbrace{\\int_0^{\\infty}\\lambda e^{-\\lambda s}ds}_{1}=e^{-\\lambda t}\n\\end{align*}\\]\nlogo, por indução teremos que \\(T_n\\sim\\hbox{Exponencial}(\\lambda)\\) para todo \\(n\\leq 1\\).\n\nComo os incrementos são independentes, os tempos entre as ocorrências também devem ser independentes. Por exemplo, considere o evento \\(\\{T_1>t_1\\}\\cap \\{T_2>t_2\\}\\), esquematizado abaixo:\n\n\n\n\n\n\n\n\n\n\nEntão, \\[\\begin{align*}\nP(T_1>t_1,T_2>t_2)&=P(N(t_1)=0,N(t_1 + t_2)- N(t_))\n\\end{align*}\\]\nPodemos também definir o tempo transcorrido até a \\(n\\)-ésima chegada.\n\n\n\n\n\n\n\n\n\nDefinição: Tempo de Espera\n\n\n\n\nDefinição 2.2 Para um processo de Poisson, seja \\[S_n=\\sum_{i=1}^{n}T_i.\\] Denominamos \\(S_n\\) como o tempo de espera até o \\(n\\)-ésimo evento.\nPara motivar a definição, se \\(S_n>t\\), então o \\(n\\)-ésimo evento não ocorreu até o tempo \\(t\\). A diferença entre \\(T_n\\) e \\(S_n\\) deve ficar clara: \\(T_n\\) é o tempo transcorrido entre as observações \\(n\\) e \\(n-1\\), enquanto que \\(S_n\\) é o tempo transcorrido, desde o começo do processo, até a ocorrência do \\(n\\)-ésimo evento.\nComo \\(T_i\\sim\\hbox{Exponencial}(\\lambda)\\), e \\(T_i\\) e \\(T_j\\) são independentes para todo \\(i\\neq j\\), teremos que \\(S_n\\sim\\hbox{Gama}(n,\\lambda)\\).\n\n\n\n\n\n\n\n\n\nExemplo: Imigrantes\n\n\n\n\nExemplo 2.2 Suponha que pessoas imigram para determinada área segundo um processo de Poisson com taxa uma por dia.\n\nQual o tempo esperado até a chegada do 10º imigrante?\nQual a probabilidade de que o tempo gasto entre a chegada do 10º e do 11º imigrante exceda dois dias?\n\n\nSolução:\n\nO tempo esperado até a décima chegada é a esperança do 10º tempo de espera, ou seja \\[E(S_{10})=\\frac{10}{\\lambda}=10\\]\nO tempo entre chegadas possui distribuição exponencial com média 1. Assim \\[P(T_{11}>2)=e^{-2\\times 1}\\]\n\n\n\n\n\n\n\n\n\n\nExemplo: Terremotos no Estreito de Messina - continuação\n\n\n\n\nExemplo 2.3 A figura abaixo (lado esquerdo) mostra os tempos de espera dos terremotos com magnitude maior que 5. Já o lado esquerdo mostra a distribuição acumulada (linha verde) dos respectivos tempos entre chegadas, com a função de distribuição exponencial ajustada (linha marrom).\n\n\n\n\n\n\n\n\n\nPara ajustar a exponencial acima, utilizamos o estimador de máxima verossimilhança para \\(\\lambda\\), dado por \\[\\hat{\\lambda}=\\frac{n-1}{\\sum_{i=1}^{n}t_i}=0,072.\\]\nDe modo análogo, estimamos que \\(N(t)\\sim\\hbox{Poisson}(0,072 t)\\).\n\n\n\n\n\n2.2.2 Distribuição condicional dos tempos de chegada\nInicialmente, considere que apenas um evento ocorreu no intervalo \\((0,t]\\). Gostaríamos de saber qual a probabilidade deste evento ter ocorrido no tempo \\(s\\), com \\(s<t\\).\nNotemos que o evento \\(\\{S_1<s,N(t)=1\\}\\) é equivalente ao evento no qual ocorre uma chegada no intervalo \\((0,s]\\) e nenhuma chegada no intervalo \\((s,t]\\), conforme ilustra a figura abaixo, na qual \\(\\mathbf{\\times}\\) indica o primeiro tempo de espera:\n\n\n\n\n\n\n\n\n\nDisto, teremos\n\\[\\begin{align*}\nP(S_1<s|N(t)=1)&=\\frac{P(S_1<s,N(t)=1)}{P(N(t)=1)}=\\frac{P(N(s)=1,N(t)-N(s)=0)}{P(N(t)=1)}\\\\\n&=\\frac{P(N(s)=1)P(N(t)-N(s)=0)}{P(N(t)=1)}\\\\\n&=\\left. \\frac{e^{-\\lambda s}(\\lambda s)^1}{1!} \\times\n    \\frac{e^{-\\lambda (t-s)}(\\lambda (t-s))^0}{0!} \\right/\n    \\frac{e^{-\\lambda t}(\\lambda t)^1}{1!} \\\\\n&\\frac{e^{\\lambda s}(\\lambda s)e^{-\\lambda(t-s)}}{e^{-\\lambda t}\\lambda t}=\\frac{s}{t}.\n\\end{align*}\\]\nAssim, \\[f_{S_1|N(t)=1}(s)=\\frac{d}{ds}P(S_1<s|N(t)=1)=\\frac{d}{ds}\\left(\\frac{s}{t}\\right)=\\frac{1}{t},\\] e \\((S_1|N(t)=1)\\sim \\hbox{Uniforme}(0,t)\\). Intuitivamente, se sabemos que houve apenas uma ocorrência no intervalo \\((0,t)\\), devido aos incrementos estacionários e independentes esta chegada seria um ponto escolhido ao acaso dentro deste intervalo.\nAgora discutiremos a distribuição dos tempos de espera \\(\\mathbf{S} =\\{S_1,\\ldots,S_n\\}\\) condicionadas ao evento \\(N(t)=n\\). Seja \\(h_i\\), \\(i=1,\\ldots,n\\) um valor positivo pequeno o suficiente para garantir que \\(s_{i-1}<s_{i}-h_i< S_i <s_i\\). Neste caso, para garantir que \\(N(t)=n\\), cada intervalo \\((s_i-h_i,s_i]\\) terá exatamente uma ocorrência e os intervalos \\((0,s_1-h_1]\\), \\((s_n,t]\\) e \\((s_{i-1},s_{i}-h_{i}]\\) para \\(i=,2\\ldots,n\\) não terão ocorrências. Portanto, dado \\(N(t)\\):\n\nProbabilidade de exatamente uma ocorrência em cada intervalo \\((s_i-h_i,s_i]\\), \\(i=1,\\ldots,n\\):\n\n\\[\n\\begin{align*}\n     p_1&=P(N(s_i)-N(s_i-h_i)=1,i=1,\\ldots,n)\\\\\n         &=P(N(h_i)=1,i=1,\\ldots,n)\\\\&=\\prod_{i=1}^ne^{-\\lambda h_i}(\\lambda h_i)\\\\\n     &=\\prod_{i=1}^ne^{-\\lambda h_i}(\\lambda h_i)\\\\\n     &= \\lambda^n e^{-\\lambda \\sum_{i=1}^{n}h_i} \\prod_{i=1}^{n}h_i\n\\end{align*}\n\\]\n\nProbabilidade de nenhuma ocorrência nos demais intervalos:\n\n\\[\n\\begin{align*}\n      p_2&= P\\left(N(s_1-h_1)=0, N(t)-N(s_n)=0,\\left\\{N(s_i-h_i)-N(s_{i-1})=0,i=2,\\ldots,n\\right\\}\\right)\\\\\n      &= e^{-\\lambda (s_1-h) }\\times e^{-\\lambda (t-s_n)}\\times\\prod_{i=2}^n e^{-\\lambda (s_i-s_{i-1}-h_i)}\\\\\n      &= e^{-\\lambda (s_1-h_1) }\\times e^{-\\lambda (t-s_n)}\\times e^{-\\lambda (s_n-s_1 -\\sum_{i=2}^n h_i)}\\\\\n      &=e^{-\\lambda t}e^{\\lambda \\sum_{i=1}^n h_i}\n\\end{align*}\n\\]\nLogo,\n\\[\\begin{align*}\nP( s_i-h_i<S_i< s_i, i=1,\\ldots,n|N(t)=n)&=\\frac{p_1p_2}{P(N(t)=n)}\\\\\n&=\\left. \\lambda^n e^{-\\lambda t} \\prod_{i=1}^n h_i \\right/ \\frac{e^{-\\lambda t}(\\lambda t)^n}{n!}\\\\\n&=\\frac{t^n}{n!}\\prod_{i=1}^n h_i.\n\\end{align*}\\]\nComo a densidade de \\(f(s_1,\\ldots,s_n|N(t)=n)\\) pode ser obtida derivando a função de distribuição, e como\n\\[\n\\begin{align*}\n\\frac{\\partial^n}{\\partial \\mathbf{s}}F(s_1,\\ldots,s_n|N(t)=n)&=\\lim_{\\mathbf{h}\\rightarrow\\mathbf{0}}\\frac{P( s_i-h_i<S_i< s_i, i=1,\\ldots,n|N(t)=n)}{\\prod_{i=1}^nh_i}\\\\\n&=\\lim_{\\mathbf{h}\\rightarrow\\mathbf{0}}\\left.\\frac{t^n}{n!}\\prod_{i=1}^n h_i\\right/\\prod_{i=1}^{n}h_i=\\frac{t^n}{n!}\n\\end{align*}\n\\]\nteremos que \\[f(s_1,\\ldots,s_n|N(t)=n)=\\frac{t^n}{n!},\\quad 0<s_1<\\cdots<s_n\\leq t,\\] ou seja, \\(\\mathbf{S}|N(t)=n\\) tem a mesma distribuição que as estatísticas de ordem de uma amostra de variáveis aleatórias independentes com distribuição Uniforme\\((0,t)\\) de tamanho \\(n\\) \\[f(s_1,\\ldots,s_n|N(t)=n)=\\frac{t^n}{n!},\\quad 0<s_1<\\cdots<s_n<t.\\]\n\n\n\n\n\n\nExemplo: Número de indivíduos no sistema\n\n\n\n\nExemplo 2.4 Indivíduos entram em um sistema segundo um PP com taxa \\(\\lambda\\). Seja \\(Y_i\\) tempo que o indivíduo \\(i\\) permanece no sistema. Considere que os tempos \\(Y_1,Y_2\\ldots,\\) são variáveis aleatórias independentes e identicamente distribuídas e que são independentes dos tempos de chegada.\nSeja \\(N(t)\\) o número de indivíduos que entraram no sistema até o tempo \\(t\\). Considerando que \\(S_i\\) é o tempo de espera do \\(i\\)-ésimo indivíduo. Este indivíduo abandona o sistema no tempo \\(S_i+Y_i\\).\nSeja \\(X(t)\\) o número de indivíduos que estão no sistema no tempo \\(t\\). Podemos criar a variável \\[Z_i(t)=\\left\\{\\begin{array}{ll}\n     1,&S_i+Y_i\\geq t \\\\\n     0,& S_i+Y_i<t\\end{array} \\right.\\] Note que \\(Z_i(t)=1\\) é equivalente a dizer que o \\(i\\)-ésimo indivíduo ainda está no sistema no tempo \\(t\\). No diagrama abaixo temos 5 chegadas. As linhas horizontais mais grossas mostram o tempo que cada indivíduo permaneceu no sistema (\\(S_i+Y_i\\)). Neste diagrama, apenas 3 indivíduos estavam no sistema no tempo \\(t\\).\n\n\n\n\n\n\n\n\n\nNote que \\[X(t)=\\sum_{i=1}^{N(t)}Z_i.\\] Portanto,\n\\[\n\\begin{align*}\n     P(X(t)=x)&=\\sum_{n=0}^\\infty P(X(t)=x|N(t)=n)P(N(t)=n)\\\\\n     &=\\sum_{n=0}^\\infty P\\left(\\sum_{i=1}^{N(t)}Z_i=x|N(t)=n\\right)P(N(t)=n)\\\\\n         &=\\sum_{n=0}^\\infty P\\left(\\sum_{i=1}^{n}Z_i=x|N(t)=n\\right)P(N(t)=n).\n\\end{align*}\n\\]\nDevemos então descobrir a distribuição de \\(Z_i|N(t)\\). Seja \\(U_1,\\ldots,U_n\\) uma amostra de variáveis independentes com distribuição Uniforme\\((0,t)\\) e sejam \\(U_{(1)},\\ldots,U_{(n)}\\) as respectivas estatísticas de ordem. Então,\n\\[\\begin{align}\n     P\\left(\\sum_{i=1}^{N(t)}Z_i=z|N(t)=n\\right) &=\n     P\\left(\\sum_{i=1}^{N(t)}I(S_i+Y_i\\geq t)=z|N(t)=n\\right)\\\\\n     &=\n     P\\left(\\sum_{i=1}^{n}I(S_i+Y_i\\geq t)=z|N(t)=n\\right)\\\\\n     &= P\\left(\\sum_{i=1}^{n}I(U_{(i)}+Y_i\\geq t)=z\\right),\n\\end{align}\\]\nmas, como \\(\\sum_{i=1}^{n}U_{(i)}=\\sum_{i=1}^{n}U_{i}\\), teremos\n\\[\\begin{align*}\n     P\\left(\\sum_{i=1}^{N(t)}Z_i=z|N(t)=n\\right)  \n     &= P\\left(\\sum_{i=1}^{n}I(U_{i}+Y_i\\geq t)=z\\right).\n     \\end{align*}\\] Ora, é imediato que \\[I(U_{i} + Y_i \\geq t)\\sim\\hbox{Bernoulli}( p(t) ),\\]\nonde\n\\[\\begin{align}\n     p(t)&=P\\left( I(U_{i}+Y_i\\geq t)=1\\right)=\n     P\\left( U_{i}+Y_i\\geq t\\right)\\\\\n     &=\\int_0^t P\\left( U_{i}+Y_i\\geq t\\right|U_i=y)f_U(u)du\\\\\n     &=\\int_0^t P\\left( u+Y_i\\geq t\\right|U_i=u)f_U(u)du,\n     \n\\end{align}\\]\ne, como \\(U_i\\) é independente de \\(Y_i\\),\n\\[\\begin{align}\n     p(t)&=\\int_0^t P\\left( u+Y_{i}\\geq t\\right)f_U(u)du\\\\\n     &=\\int_0^t P\\left( Y_{i}\\geq t-u\\right)f_U(u)du\\\\\n     &=\\int_0^t P\\left( Y_{i}\\geq t-u\\right)\\frac{1}{t}du\\\\\n     &=\\int_0^t P\\left( Y_{i}\\geq y\\right)\\frac{1}{t}dy\\\\\n     &=\\int_0^t [1-F_Y(y)]\\frac{1}{t}dy\\\\    \n     \n\\end{align}\\]\nComo as variáveis \\(U_i\\) e \\(Y_i\\) são independentes e identicamente distribuídas, temos que\n\\[\\sum_{i=1}^{N(t)}Z_i|N(t)\\sim\\hbox{Binomial}\\left(N(t),p(t)\\right).\\]\nPodemos finalmente concluir a distribuição de \\(X(t)\\):\n\\[\n\\begin{align*}\n         P(X(t)=x)&=\\sum_{n=0}^\\infty P\\left(\\sum_{i=1}^{n}Z_i=x|N(t)=n\\right)P(N(t)=n)\\\\\n         &=\\sum_{n=x}^\\infty P\\left(\\sum_{i=1}^{n}Z_i=x|N(t)=n\\right)P(N(t)=n)\\\\\n         &=\\sum_{n=x}^\\infty {n \\choose x} p(t)^x \\left[1-p(t)\\right]^{n-x}\\frac{e^{-\\lambda t}(\\lambda t)^n}{n!}\\\\\n         &=\\sum_{n=x}^\\infty \\frac{n!}{x!(n-x)!} p(t)^x \\left[1-p(t)\\right]^{n-x}\\frac{e^{-\\lambda t}(\\lambda t)^n}{n!}\\\\\n         &=\\frac{e^{-\\lambda t}p(t)^x}{(1-p(t))^xx!}\\sum_{n=x}^\\infty \\frac{\\left(\\lambda t [1-p(t)]\\right)^n}{(n-x)!}\\\\\n         &=\\frac{e^{-\\lambda t}p(t)^x}{(1-p(t))^xx!}\\sum_{w=0}^\\infty \\frac{\\left(\\lambda t [1-p(t)]\\right)^{w+x}}{w!}\\\\\n         &=\\frac{e^{-\\lambda t}p(t)^x}{(1-p(t))^xx!}[\\lambda t(1-p(t))]^x\\sum_{w=0}^\\infty \\frac{\\left(\\lambda t(1-p(t))\\right)^{w}}{w!}\\\\\n         &=\\frac{e^{-\\lambda t}p(t)^x}{x!}(\\lambda t)^x\\sum_{w=0}^\\infty \\frac{\\left(\\lambda t(1-p(t))\\right)^{w}}{w!}\\\\\n                 &=\\frac{e^{-\\lambda t}p(t)^x}{x!}(\\lambda t)^xe^{\\lambda t(1-p(t))}\\\\\n         &=\\frac{e^{-\\lambda tp(t)}[\\lambda t p(t)]^x}{x!}           \n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\n\nExemplo\n\n\n\n\nExemplo 2.5 Pessoas chegam a um grande supermercado segundo um PP com taxa 40 por hora. O tempo que elas permanecem no supermercado possui distribuição Exponencial com média 0,75 horas. Considerando que o supermercado abre as 8h, qual é o número esperado de clientes às 12h?\nSolução: Seja \\(N(t)\\) o número de clientes que entraram no supermercado até o tempo \\(t\\). Então,\n\\[N(t)\\sim\\hbox{Poisson}(\\lambda t).\\]\nSeja \\(Y_i\\) o tempo que o \\(i\\)-ésimo cliente leva para deixar o supermercado. Como\n\\[E(Y_i)=\\frac{1}{\\alpha}=0,75,\\]\nteremos que \\(Y_i\\sim\\hbox{Exponencial}(1/0,75)\\equiv\\hbox{Exponencial}(4/3)\\). Como\n\\[F_Y(y)=1-e^{-\\alpha y}=1-e^{-\\frac{4}{3}t},\\]\nteremos que\n\\[\n\\begin{align*}\np(t)&=\\frac{1}{t}\\int_0^t[1-F_Y(y)]dy=\\frac{1}{t}\\int_0^t e^{-\\frac{4}{3}y}dy\\\\\n&=\\frac{3}{4t}[1-e^{-\\frac{4}{3}t}].\n\\end{align*}\n\\]\nDeste modo, o número de cliente no supermercado para qualquer tempo é\n\\[X(t)\\sim\\hbox{Poisson}\\left( \\lambda t p(t)\\right)\\equiv\n\\hbox{Poisson}\\left( 30[1-e^{-\\frac{4}{3}t}]\\right).\\]\nConsiderando que o tempo \\(t=0\\) é equivalente as 8h, teremos que 12h é equivalente a \\(t=4\\). Assim,\n\\[E(X(4))=30[1-e^{-\\frac{4}{3}4}]=29,85516.\\]\nPortanto, são esperados aproximadamente 30 clientes as 12h dentro do supermercado."
  },
  {
    "objectID": "cap_2_poisson.html#soma-de-processos-de-poisson",
    "href": "cap_2_poisson.html#soma-de-processos-de-poisson",
    "title": "2  Processo de Poisson",
    "section": "2.3 Soma de Processos de Poisson",
    "text": "2.3 Soma de Processos de Poisson\nDesejamos estudar o comportamento da ocorrência de óbitos por tuberculose no Amazonas. Comecemos considerando apenas os dois processos de contagem a seguir:\n\n\\(N_1(t):\\) número de óbitos por tuberculose respiratória com confirmação até tempo \\(t\\);\n\\(N_2(t):\\) número de outros tipos de óbitos por tuberculose até tempo \\(t\\);\n\nApós observar os dados, poderíamos verificar se cada um destes processos pode ser modelado como um PP. Entretanto, existe outro processo de contagem envolvido: o total de óbitos por tuberculose até o tempo \\(t\\). Denotando este processo por \\(N(t)\\), podemos caracterizá-lo a partir das seguintes proposições.\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 2.2 Considere que os existem dois tipos de eventos, 1 e 2, que ocorrem independentemente e sejam \\(p\\) e \\(1-p\\) suas respectivas probabilidades de ocorrência. Sejam \\(N_1(t)\\) e \\(N_2(t)\\) seus respectivos processos de contagem. Então, se \\(N(t)=N_1(t) + N_2(t)\\) for um PP com taxa \\(\\lambda\\), teremos:\n\n\\(N_1(t)\\) e \\(N_2(t)\\) também serão um PP com taxas \\(\\lambda p\\) e \\(\\lambda(1-p)\\) respectivamente, onde \\(p\\) é a probabilidade de uma ocorrência ser do tipo 1.\n\\(N_1(t)\\) e \\(N_2(t)\\) são independentes.\n\nDemonstração: Para quaisquer variáveis aleatórias discretas \\(X\\) e \\(Y\\), temos que \\[P(X=x)=\\sum_{y=-\\infty}^{\\infty} P(X=x|Y=y)P(Y=y),\\] e o resultado continua verdadeiro se \\(X\\) for um vetor de variáveis aleatórias discretas. Fazendo, na expressão acima, \\(X=(N_1(t),N_2(t))\\) e \\(Y=N(t)\\), teremos \\[\\begin{align*}\n  &P(N_1(t)=n,N_2(t)=m)= \\sum_{k=0}^{\\infty}P(N_1(t)=n,N_2(t)=m|N(t)=k)P(N(t)=k),  \n\\end{align*}\\]\nonde a soma começa em zero porque a probabilidade de \\(N(t)<0\\) é nula. Embora a soma seja feita para todo \\(k\\), as probabilidades só serão diferentes de zero se \\(N(t)=n+m\\), uma vez que \\(N_1(t)=n\\) e \\(N_2(t)=m\\). Portanto,\n\\[\n\\begin{align*}\n   P(N_1(t)=n,N_2(t)=m)&= P(N_1(t)=n,N_2(t)=m|N(t)=n+m)\\\\\n   &\\times P(N(t)=n+m) \\\\\n  &= P(N_1(t)=n,N(t)-N_1(t)=m|N(t)=n+m)\\\\\n  &\\times P(N(t)=n+m)\n\\end{align*}\n\\]\nDado que \\(N(t)=n+m\\), os eventos \\(\\{N_1(t)=n, N(t)-N_1(t)=m\\}\\) e \\(\\{N_1(t)=n\\}\\) são equivalentes. Deste modo \\[P(N_1(t)=n,N_2(t)=m|N(t)=n+m)=P(N_1(t)=n|N(t)=n+m).\\]\nA segunda probabilidade acima está relacionada com o número de ocorrências do evento do tipo 1 até o tempo \\(t\\), considerando que o número total de ocorrências (sem descriminar os eventos) é conhecido. Considerando que a probabilidade de ocorrência dos eventos do tipo 1 é \\(p\\) e que as ocorrências são independentes, teremos que \\[N_1(t)|N(t)\\sim\\hbox{Binomial}\\left(N(t),p\\right).\\] Assim, \\[\\begin{align}\n  P(N_1(t)=n,N_2(t)=m)&= P(N_1(t)=n|N(t)=n+m)P(N(t)=n+m)\\notag \\\\\n  &={n+m\\choose n}p^{n}(1-p)^{m}\\frac{e^{-\\lambda t}(\\lambda t)^{n+m}}{(n+m)!}\\notag \\\\\n  &=\\frac{e^{-\\lambda pt}(\\lambda pt)^n}{n!}\\times  \\frac{e^{-\\lambda (1-p)t}(\\lambda (1-p)t)^m}{m!}\\label{eq::prova_soma_contagem_2}\n  \\end{align}\\] Como a distribuição fatorou em duas distribuições Poisson, temos que \\(N_1(t)\\sim\\hbox{Poisson}(\\lambda p t)\\), \\(N_2(t)\\sim\\hbox{Poisson}(\\lambda (1-p) t)\\) e os processos são independentes.\n\n\n\nPortanto, podemos verificar se o total dos eventos possui distribuição Poisson. Se isto for verdadeiro, será imediado que cada um dos dois processos de contagem também serão PP.\nA proposição acima pode ser generalizada:\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 2.3 Consideremos \\(k\\) eventos distintos e sejam \\(N_{1}(t),\\ldots,N_k(t)\\) seus respectivos processos de contagem. Então, se \\(N(t)=N_1(t)+\\cdots +N_k(t)\\) for um PP, teremos que \\(N_i(t),i=1,\\ldots, k\\) também será um PP com taxa \\(\\lambda p_i\\), com \\(p_i>0\\) e \\(\\sum_{i=1}^{k}p_i=1\\). Temos que \\(p_i\\) será a probabilidade de que o evento do tipo \\(i\\) aconteça. Além disso, teremos que os processos \\(N_i(t)\\) serão independentes.\n\n\n\n\n\n\n\n\n\nExemplo: Casos de Hanseníase em Manaus\n\n\n\n\nExemplo 2.6 A abaixo mostra o número de casos de hanseníase registrados em 2007 e 2008 na cidade de Manaus por região. Podemos definir \\(N_N(t),N_S(t),N_L(t)\\) e \\(N_O(t)\\) como sendo o número de casos de hanseníase observados até o instante \\(t\\) nas regiões norte, sul, leste e oeste, respectivamente. Seja \\(N(t)\\) o total de casos de hanseníase registrados em Manaus entre 2007 e 2008. Realizamos um teste de Kolmogorov-Smirnov para testar se os incrementos do processo \\(N(t)\\), dados na coluna Total, possuem distribuição Poisson. O p-valor deste teste foi igual a 0,507, o que nos trás evidências de que \\(N(t)\\sim\\hbox{Poisson}(7,375)\\). Assumindo que esta hipótese é verdadeira, teremos pela Proposição 2.5 que os processos \\(N_N(t),N_S(t),N_L(t)\\) e \\(N_O(t)\\) também são processos de Poisson, com as seguintes taxas estimadas: 2(norte), 0,625(sul), 2,083(leste) e 2,667(oeste). Assim, a probabilidade de que um caso de hanseníase tomado ao acaso ocorra em determinada região é: 0,271(norte), 0,084(sul), 0,282(leste) e 0,361(oeste).\n\n\n\n\n\n\n\n\nTabela 2.1: Nº de casos mensais de hanseníase por região de Manaus em 2007 e 2008"
  },
  {
    "objectID": "cap_2_poisson.html#inferência-para-o-processo-de-poisson",
    "href": "cap_2_poisson.html#inferência-para-o-processo-de-poisson",
    "title": "2  Processo de Poisson",
    "section": "2.4 Inferência para o Processo de Poisson",
    "text": "2.4 Inferência para o Processo de Poisson\nHabitualmente, os dados de um PP são apresentados de duas formas: através do registro dos incrementos, contados em intervalos disjuntos e geralmente de comprimentos iguais, ou através do registro dos tempos de chegada e/ou espera.\n\n2.4.1 Inferência para incremento\nEm um estudo realizado em XXX, os autores levantaram evidencias de que as morte por paradas cardíacas seguem um processo de Poisson. Para verificar se esse comportamento também é válido para o estado do Amazonas, coletamos as informações sobre os óbitos no estado. A seguinte tabela mostra o número de óbitos por parada cardíaca em cada mês dos anos de 2009 e 2010.\n\n\n\n\n\n\n\n\nNa tabela acima, o número de observações em cada mês é um incremento do processo de contagem \\(\\{N(t),t>0\\}\\), onde \\(N(t)\\) é o número de óbitos por parada cardíaca registrados até o tempo \\(t\\).\n\n\n2.4.1.1 Estimação para \\(\\lambda\\)\nSeja \\(X(s,t)\\) o número de ocorrências no intervalo \\((s,t]\\). É comum que os dados estejam representados em um tabela, identificando o intervalo e o número de ocorrências de cada intervalo. Também é usual que estes intervalos sejam disjuntos e contíguos. Com essas considerações, sejam \\((s_i,t_i]\\) uma sequência de intervalos disjuntos de comprimento \\(h_i=h\\), com \\(i=1,\\ldots,n\\). Consideremos então que, nos tempos \\(t_1,\\ldots,t_k\\), foram registrados os valores \\(N(t_1),\\ldots,N(t_k)\\). Assim, temos a amostra de incrementos \\(Y_i=X(t_i,t_{i-1}),\\), \\(i=1,\\ldots,n\\), onde \\(t_0=0\\). Agora, seja \\(y_i\\) o valor observado do \\(i\\)-ésimo incremento. Como os incrementos são independentes, teremos que \\[P(N(t)=k)=P(Y_1=y_1,\\ldots,Y_n=y_n)=\\prod_{i=1}^{n}\\frac{e^{-\\lambda h}(\\lambda h)^{y_i}}{y_i!}.\\] A verossimilhança deste processo é \\[\\begin{align*}\nL(\\lambda)\\propto e^{-nh\\lambda}\\lambda^{\\sum_{i=1}^{n}y_i}.\n\\end{align*}\\] Encontraremos o EMV para \\(\\lambda\\). O logaritmo da função de verossimilhança será \\[\\begin{equation}\nl(\\lambda)=-nh\\lambda +\\log(\\lambda)\\sum_{i=1}^{n}y_i,\n\\end{equation}\\] e \\[\\begin{align*}\n\\frac{d}{d\\lambda}l(\\lambda) &= -nh +\\frac{1}{\\lambda}\\sum_{i=1}^{n}y_i \\\\\n\\frac{d^2}{d\\lambda^2}l(\\lambda)&= -\\frac{1}{\\lambda^2}\\sum_{i=1}^{n}y_i.\n\\end{align*}\\] Fazendo a primeira derivada de \\(l(\\lambda)\\) igual a zero, teremos \\(\\hat{\\lambda}=\\sum_{i=1}^{n}Y_i/nh=\\bar{Y}/h\\). A derivada segunda aplicada em \\(\\lambda=\\hat{\\lambda}\\) é negativa, mostrando que \\(\\hat{\\lambda}\\) é ponto de máximo. Portanto, o estimador de máxima verossimilhança para \\(\\lambda\\) é \\(\\hat{\\lambda}\\). Teremos que \\[\\begin{align*}\nE(\\hat{\\lambda})&=\\frac{1}{h}E(Y_1)=\\lambda\n\\end{align*}\\] logo, \\(\\hat{\\lambda}\\) é não viesado. Além disso, \\[\\begin{align}\nVar(\\hat{\\lambda})&=\\frac{1}{h^2}Var(\\bar{Y})=\\frac{\\lambda}{nh},\n\\end{align}\\] logo, o estimador é consistente e seu erro padrão pode ser estimado por \\[\\begin{equation}\n\\hat{EP}(\\hat{\\lambda})=\\sqrt{\\frac{\\hat{\\lambda}}{nh}}.\n\\end{equation}\\] Existem diversas estratégias para construir intervalos de confiança para \\(\\lambda\\). Uma delas, seria utilizar a aproximação normal \\[\\sqrt{nh}\\frac{\\hat{\\lambda}-\\lambda}{\\sqrt{\\hat{\\lambda}}}\\approx \\hbox{Normal}(0,1)\\] (decorrente do TCL). Com isso, um intervalo com confiança aproximada de \\((1-\\alpha)\\) para \\(\\lambda\\) é dado por \\[\\left(\\hat{\\lambda}-z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{\\lambda}}{nh}};\\hat{\\lambda}-z_{\\alpha/2}\\sqrt{\\frac{\\hat{\\lambda}}{nh}}\\right).\\] Via de regra, a aproximação acima é válida para \\(\\hat{\\lambda}>20\\).\nNo exemplo do número de óbitos por ataque cardíaco, temos que todos os incrementos tem o mesmo comprimento (\\(h=1\\) mês). O valor estimado para \\(\\lambda\\) é, \\[\\hat{\\lambda}=148,75.\\] com um erro-padrão estimado de \\(2,489\\). Um intervalo aproximado com confiança \\(95\\%\\) para \\(\\lambda\\) é \\[[144,66;152,85].\\]\n\n\n2.4.1.2 Verificando se os dados seguem um processo de Poisson\nLembremos que um processo de Poisson possui incrementos independentes e estacionários, e que \\(E[N(t)]=\\lambda t\\). Abaixo, seguem quatro gráficos que podem nos auxiliar a verificar se estas condições estão satisfeitas.\n\nUm diagrama de dispersão entre \\(Y_1,Y_2,\\ldots,Y_{n-1}\\) e \\(Y_2,Y_3,\\ldots,Y_{n}\\): se houver qualquer tendência entre \\(Y_i\\) e \\(Y_{i-1}\\) existem evidências para suspeitarmos da hipótese de independência.\nUm diagrama de dispersão entre os índices \\(1,2,\\ldots,n\\) e \\(Y_1,Y_2\\ldots,Y_n\\): dados dispersos em torno de \\(\\hat{\\lambda}\\) dão evidências de estacionaridade.\nUm diagrama de dispersão entre os índices \\(1,2,\\ldots,n\\) e \\(N(t_1),N(t_2)\\ldots,N(t_n)\\): um comportamento linear dá indícios de que \\(E[N(t)]=\\lambda t\\).\nUm envelope de confiança para a função de distribuição em conjunto com a função de distribuição de uma Poisson com taxa \\(\\hat{\\lambda}\\): se a distribuição da Poisson estiver dentro do envelope, existem evidências de os incrementos seguem uma distribuição Poisson com taxa \\(\\hat{\\lambda}\\).\n\n\n\n\n\n\n\n\n\n\n\n2.4.1.2.1 Testes de hipóteses\nSe os incrementos \\(Y_1,\\ldots,Y_n\\) são provenientes de um processo de Poisson, então eles devem ser independentes e estacionários.\n\n\n\n2.4.1.3 Inferências para \\(T\\)\nSejam \\(T_1,\\ldots,T_n\\) uma amostra dos tempos de chegadas de um processo de Poisson com taxa \\(\\lambda\\). A função de verossimilhança para \\(\\lambda\\) é dada por\n\\[\n\\begin{align*}\nL(\\lambda)&=\\prod_{i=1}^{n}f(t_i|\\lambda)=\\lambda^{n}e^{-\\lambda\\sum_{i=1}^{n}t_i}\\\\\n&=\\lambda^{n}e^{-\\lambda S_n}\n\\end{align*}\n\\]\nO logaritmo da verossimilhança será \\[\\begin{equation*}l(\\lambda)=n\\log(\\lambda) -\\lambda S_n\n\\end{equation*}\\] e sua primeira e segunda derivada é:\n\\[\n\\begin{align*}\n\\frac{d}{d\\lambda}&=\\frac{n}{\\lambda} -S_n \\\\\n\\frac{d^2}{d\\lambda^2}&=-\\frac{n}{\\lambda^2}.\n\\end{align*}\n\\]\nAnalisando as duas derivadas, vemos que \\(\\hat{\\lambda}=n/S_n\\) é ponto de máximo e portanto é EMV.\nPelo Exercício Exercício 6.17, sabemos que \\(Z=\\lambda\\hat{\\lambda}\\sim\\hbox{GI}(n,n)\\). Assim, podemos calcular \\(a\\) e \\(b\\) tais que \\(P(a<Z<b)=1-\\alpha\\) e criar o intervalo de confiança \\[\\begin{equation*}\n\\left( \\frac{a}{\\hat{\\lambda}}, \\frac{b}{\\hat{\\lambda}}\\right).\n\\end{equation*}\\]\n\n\n\n2.4.2 Suicídios no MIT\nQuando ocorre um suicídio no MIT - Massachusetts Institute of Technology - diversas áreas da comunidade pedem uma açao da administração. Se os suicídios foram provenientes de um processo aleatório, tais ações não deveriam ser da competência da administração, apesar de que programas para reduzir a taxa global de suicídios no MIT devem sempre ser insentivados.\nEm (CHEW, et al.), os autores gostariam de saber se os suicídios ocorridos no MIT poderiam ser modelados segundo um processo de Poisson. Apesar do MIT não manter estatísticas sobre a saúde de seus estudantes e pessoal em geral, suicídios são casos excepcionais e dados sobre estes puderam ser obtidos no Office of the Dean for Students Affairs. Os autores pesquisaram os suicídios ocorridos entre os anos de 1964 e 1991. Alguns dados estavam incompletos, uma vez que apenas o ano e o mês do suicídio foram registrados. Para estes dados, os autores assumiram que o suicídio ocorreu no dia 15. As datas do histórico se suicídios são mostradas na Tabela a seguir:\n\n\n\nData\n\\(T_i\\)\nData\n\\(T_i\\)\nData\n\\(T_i\\)\n\n\n\n\n10/06/1964\n-\n26/07/1974\n428\n20/10/1986\n16\n\n\n15/11/1964\n158\n27/07/1975\n366\n02/10/1987\n347\n\n\n17/10/1965\n336\n12/12/1975\n138\n03/10/1987\n1\n\n\n17/03/1966\n151\n02/02/1976\n52\n22/10/1987\n19\n\n\n04/06/1967\n444\n16/10/1977\n622\n08/04/1988\n169\n\n\n19/10/1969\n868\n03/04/1978\n169\n15/04/1988\n7\n\n\n15/07/1970\n269\n08/02/1983\n1772\n15/06/1988\n61\n\n\n19/03/1973\n978\n30/11/1983\n295\n15/06/1988\n0\n\n\n15/04/1973\n27\n21/06/1984\n204\n15/10/1990\n852\n\n\n15/05/1973\n30\n18/05/1986\n696\n15/06/1991\n243\n\n\n24/05/1973\n9\n04/10/1986\n139\n15/06/1991\n0\n\n\n\n\nData do suicídio e o tempo transcorrido, em dias, entre os suicídios."
  },
  {
    "objectID": "cap_2_poisson.html#o-processo-de-poisson-composto",
    "href": "cap_2_poisson.html#o-processo-de-poisson-composto",
    "title": "2  Processo de Poisson",
    "section": "2.5 O Processo de Poisson Composto",
    "text": "2.5 O Processo de Poisson Composto\nClientes chegam em uma loja de conveniências segundo um processo de Poisson com taxa \\(\\lambda\\). Cada cliente gasta uma quantidade \\(D_i\\) de dinheiro, independente dos demais. Neste caso, podemos estar interessados em estudar a quantidade de dinheiro ganho pelo loja ao longo do tempo, ou seja, na variável \\(Y(t)=\\sum_{i=1}^{N(t)}D_i\\). Este é um típico exemplo de um processo de Poisson composto.\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 2.3 Seja \\(Y(t)=\\sum_{i=1}^{N(t)}D_i\\), onde as variáveis aleatórias \\(D_i\\)s são independentes e identicamente distribuídas e seja \\(\\{N(t),t\\geq 0\\}\\) um processo de Poisson. Então, processo estocástico \\(\\{Y(t),t>0\\}\\) é denominado processo de Poisson composto.\n\n\n\nUm modo de analisar o processo \\(\\{Y(t),t\\geq 0\\}\\) seria encontrar a expressão analítica de sua distribuição, ou seja\n\\[\n\\begin{align}\nF(y(t))&=\\sum_{n=0}^{\\infty}P(Y(t)\\leq y(t)|N(t)=n)P(N(t)=n)\\\\&=\\sum_{n=0}^{\\infty}P(Y(t)\\leq y(t)|N(t)=n)\\frac{e^{-\\lambda t}(\\lambda t)^n}{n!}.\n\\end{align}\n\\]\nEm geral, esta distribuição não possui forma analítica e métodos computacionais são necessários para estimar a distribuição. Entretanto, apenas o conhecimento dos momentos de \\(Y(t)\\) podem ser úteis para realizar inferências sobre média, variância, assimetria e curtose. Podemos encontrar a função geratriz de momentos de \\(Y(t)\\), desde que exista a função geratriz de momentos de \\(D\\). De fato, seja \\(M_D(r)\\) a função geratriz de momentos de \\(D\\). Então\n\\[\n\\begin{align*}\nM_{Y(t)}(r)&=E(e^{Y(t)r})=E[E(e^{Y(t)r}|N(t))]=\nE[E(e^{r\\sum_{i=1}^{N(t)}D_i}|N(t))]\\\\\n&=E[\\prod_{i=1}^{N(t)}E(e^{rD_i}|N(t))]=E[\\prod_{i=1}^{N(t)}M_{D_i}(r)]=\nE[(M_{D}(r))^{N(t)}]\\\\\n&=\\sum_{n=0}^{\\infty}(M_{D_i}(r))^n\\frac{e^{-\\lambda t}(\\lambda t)^n}{n!}\n=e^{-\\lambda t}\\sum_{n=0}^{\\infty} \\frac{(M_D(r)\\lambda t)^n}{n!}\\\\\n&=e^{\\lambda t( M_D(r) -1)}.\n\\end{align*}\n\\]\nComo usual, o \\(k\\)-ésimo momento é obtido calculando \\((d^k/d r^k)M_{y(t)}(r)|_{r=0}\\). Por exemplo, o primeiro momento é calculando fazendo\n\\[\n\\begin{align*}\nE(Y(t))&=\\left.\\frac{d}{dr}M_{Y(t)}(r)\\right|_{r=0}= \\lambda t e^{\\lambda t( M_D(r) -1)}\\left.\\frac{d}{dr}M_{D}(r)\\right|_{r=0}=\\lambda t E(D),\n\\end{align*}\n\\]\ne o segundo momento será, \\[\\begin{align*}\n\nE(Y(t)^2)&=\\left.\\frac{d^2}{dr^2}M_{Y(t)}(r)\\right|_{r=0}\\\\&=  e^{\\lambda t( M_D(r) -1)}\\left(\\lambda t\\frac{d}{dr}M_{D}(r)\\right)^2 +\\lambda te^{\\lambda(M_D(r)-1)} \\left.\\frac{d^2}{dr^2}M_D(r)\\right|_{r=0}\\\\\n&=(\\lambda t E(D))^2 + \\lambda t E(D^2).\n\\end{align*}\\]\nAssim, a variância será\n\\[\n\\begin{align*}\nVar(Y(t))&= \\lambda t E(D^2)\n\\end{align*}\n\\]\n\n\n\n\n\n\nExemplo: Número de vítimas fatais em acidentes aéreos\n\n\n\n\nExemplo 2.7 Consideremos os dados sobre o número de acidentes aéreos no Brasil em 2008. Suponha que que este é um processo de Poisson. Sua taxa está estimada em 12,83. Seja \\(D_i\\) o numero de vítimas fatais no \\(i\\)-ésimo acidente. A distribuição de frequências do número de acidentes fatais por acidente é dado na Tabela a seguir:\n\n\n\nNº de vítimas fatais\n0\n1\n2\n3\n4\n5\n\n\n\n\nFrequência observada\n127\n9\n12\n1\n3\n1\n\n\n\n\nDistribuição de Frequências do número de vítimas fatais por acidente.\n\n\nOs valores estimados para \\(E(D)\\) e \\(Var(D)\\) são, respectivamente, 0,38 e 1,136. Assim, teremos que \\[\\hat{E}(Y(t))=\\hat{\\lambda}\\hat{E}(D)t = 4,916t\\]\n\ne\n\n\\[\\hat{Var}(Y(t))=\\hat{\\lambda}\\hat{E}(D^2)t=14,583t.\\] Além disso, fazendo \\(\\mu(t)=E(Y(t))\\) e \\(\\sigma^2(t)=Var(Y(t))\\), temos que um intervalo (aproximado) com \\((1-\\alpha)\\%\\) de confiança aproximado para \\(\\mu(t)\\) é dado por \\[(Y(t)\\pm z_{1-\\alpha/2}\\hat{\\sigma}(t))=(Y(t)\\pm 3,818z_{1-\\alpha/2}\\sqrt{t})\\] e, em particular, para o período em estudo, temos que \\(Y(12)=59\\) e um intervalo com 95% de confiança para \\(\\mu(t)\\) é \\((33,07;84,92)\\)."
  },
  {
    "objectID": "cap_2_poisson.html#generalizações-do-processo-de-poisson",
    "href": "cap_2_poisson.html#generalizações-do-processo-de-poisson",
    "title": "2  Processo de Poisson",
    "section": "2.6 Generalizações do Processo de Poisson",
    "text": "2.6 Generalizações do Processo de Poisson\nPodemos generalizar um PP relaxando alguma de suas hipóteses. Se assumimos que \\(E(N(t))=\\lambda(t)\\), onde a função \\(\\lambda(.)\\) não é linear, teremos um {}. Se os incrementos do processo forem estacionários, mas não forem independentes, teremos um processo de ponto estacionário. Neste curso, apresentaremos apenas a primeira destas generalizações.\n\n2.6.1 O Processo de Poisson Não-Homogêneo\nO processo de Poisson visto até agora possui taxa constante ao longo do tempo. Isto pode não ser verdade para todo processo de Poisson. Por exemplo, clientes podem chegar em um supermercado com intensidades diferentes em relação ao horário, como por exemplo em horário comercial, ou em épocas como começo/fim de mês. Nestes casos, quando permitimos que a taxa seja função de \\(t\\), temos um processo de Poisson não-homogêneo.\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 2.4 O processo estocástico \\(\\{N(t),t\\leq 0\\}\\) será um processo de Poisson não-homogêneo se:\n\n\\(N(0)=0\\)\n\\(\\{N(t),t\\geq 0\\}\\) possui incrementos independentes\nA taxa do processo é dada por \\(\\lambda(t)\\) e \\(N(t)\\sim\\hbox{Poisson}(m(t))\\), onde \\[m(t)=\\int_0^t \\lambda(s)ds,\\] é denominada função do valor médio do processo.\n\nNotemos que esse processo é uma generalização do processo de Poisson, com o processo homogêneo sendo um caso particular, quando \\(\\lambda(t)=\\lambda\\;\\forall t>\\geq 0\\).\n\n\n\n\n\n\n\n\n\nExemplo\n\n\n\n\nExemplo 2.8 Considere um restaurante que só abre a noite. Clientes chegam segundo um processo de Poisson não-homogêneo com taxas (por hora) \\[\\begin{align*}\n\\lambda(t)=\\left\\{\\begin{array}{l}10,\\quad 18\\leq t < 19\\\\\n15,\\quad 19\\leq t < 21 \\\\\n12\\quad 21\\leq t< 22\\end{array}\\right.\n\\end{align*}\\]\nPergunta-se:\n\nQual o número esperado de clientes em uma noite?\nQual a probabilidade de que nenhum cliente vá ao restaurante entre 18h e 18:30h?\nQual a probabilidade de que nenhum cliente vá ao restaurante entre as 18:30h e 19:30h?\n\nResolução:\nSeja \\(N(t)\\) o número de clientes que entraram no restaurante até o tempo \\(t\\). Sem perda de generalidade, notemos que os seguintes horários são equivalentes:\n\n\n\nHorário Normal\n18h\n19h\n21h\n22h\n\n\n\n\nTempo após a abertura\n0\n1\n3\n4\n\n\n\nNão importa qual tipo de horário você vai escolher, uma vez que a distribuição não vai se alterar. A segunda opção, que considera \\(t=0\\) como o instante no qual o restaurante abre, é uma escolha usual e iremos adotá-la. Notemos que a taxa do processo será reescrita como\n\\[\\begin{align}\n\\lambda(t)=\\left\\{\\begin{array}{l}10,\\quad 0\\leq t < 1\\\\\n15,\\quad 1\\leq t < 3 \\\\\n12\\quad 3\\leq t< 4\\end{array}\\right.\n\n\\end{align}\\]\n\nO período de uma noite de trabalho corresponde ao intervalo entre \\((0,4)\\) horas de funcionamento do estabelecimento. Logo, queremos calcular \\(E(N(4))\\). Teremos que \\[\\begin{align*}\nE(N(4))&=\\int_0^4 \\lambda(t)dt =\\int_0^1 \\lambda(t)dt+\\int_1^3 \\lambda(t)dt+\\int_3^4 \\lambda(t)dt \\\\\n&=10 +30 + 12 =52.\n\\end{align*}\\]\nO intervalo entre 18h e 18:30h corresponde ao intervalo da primeira meia hora, isto é, entre 0 e 0,5 no segunda escala. Assim, a probabilidade de não chegarem clientes neste intervalo é \\[\\begin{align*}\nP(N(1/2)=0)=e^{-10/2}\n\\end{align*}\\]\nNeste caso, o intervalo entre 18:30h e 19:30h corresponde ao intervalo \\((0,5;1,5)\\). Notemos que queremos o evento \\(\\{N(3/2)-N(1/2)=0\\}\\). Como \\[\\begin{align*} m(3/2)-m(1/2)&=\\int_{1/2}^{3/2}\\lambda(t)dt=\\left. 10t\\right|_{1/2}^{1} + \\left. 15t\\right|_{1}^{3/2}\\\\\n&= \\frac{10}{2}+\\frac{15}{2}=\\frac{25}{2}=12,5,\n\\end{align*}\\] logo, \\[\\begin{align*} P(N(3/2)-N(1/2)=0)=e^{-12,5}\n\\end{align*}\\]"
  },
  {
    "objectID": "cap_2_poisson.html#exercícios",
    "href": "cap_2_poisson.html#exercícios",
    "title": "2  Processo de Poisson",
    "section": "2.7 Exercícios",
    "text": "2.7 Exercícios\n\nSeção 2.1\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.1 \n\nEventos ocorrem segundo um processo de Poisson com taxa 2 por hora.\n\n\nQual a probabilidade de que nenhum evento ocorra entre 20h e 21h?\nComeçando ao meio-dia, qual o tempo esperado para o quarto evento ocorrer?\nQual a probabilidade de que dois ou mais eventos ocorram entre as 18h e às 20h?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.2 Carros atravessam certa rodovia de acordo com um processo de Poisson com taxa \\(3\\) por minuto. Érica demora 2 minutos para atravessar esta rodovia. Se ela atravessar a rodovia sem olhar para os lados, então qual a probabilidade de que ela se envolva em um acidente? (considere que se ela estiver na rodovia quando um carro passar, então ela sofrerá um acidente).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.3 Clientes chegam a um banco segundo um processo de Poisson com taxa \\(\\lambda\\). Suponha que dois clientes chegaram durante a primeira hora. Qual é a probabilidade de que\n\nAmbos tenham chegado durante os primeiros 20 minutos?\nPelo menos um chegou durante os primeiros 20 minutos?\n\n\n\n\n\nSeção 2.3\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.4 Potenciais clientes solicitam uma linha telefônica segundo um processo de Poisson com taxa 70 pedidos por dia. Entretanto, um pedido só é aceito se o propenso cliente não tiver na lista do SPC/SERASA. A experiência diz que de cada 100 clientes 30 deles estão com o nome nesta lista.\n\nQual é o valor esperado de solicitações aceitas em um mês (de 30 dias)?\nEm um dia foram registradas 50 solicitações. Qual a probabilidade de que metade delas seja aceita?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.5 Pulsos chegam a um contador Geiger de acordo com um processo de Poisson com taxa de três por minuto. Cada partícula tem uma probabilidade 2/3 de ser contabilizada. Seja \\(N(t)\\) o número de pulsos registrados até o tempo t (em minutos).\n\n\\(P(N(t)=0)=?\\)\n\\(E(N(t))=?\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.6 Carros passam por uma rodovia segundo um processo de Poisson com taxa um por minuto. Se 5% dos carros são vans, então\n\nQual a probabilidade de que pelo menos um van passe durante uma hora?\nDado que dez vans passaram em uma hora, qual o número esperado de carros que passam pela rodovia naquela hora?\nSe 50 carros passaram em uma hora, qual é a probabilidade de que cinco deles sejam vans?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.7 Suponha que o número de erros tipográficos em um novo texto tem distribuição Poisson com média \\(\\lambda\\). Dois revisadores lêem o texto independentemente. Suponha que cada erro é encontrado pelo revisador \\(i\\) com probabilidade \\(p_i\\), \\(i=1,2\\). Seja \\(X_1\\) o número de erros que foram encontrados pelo revisor 1, mas que não o foram pelo revisor 2. Seja \\(X_2\\) o número de erros encontrados pelo revisor 2 que não foram notados pelo revisor 1. Seja \\(X_3\\) o número de erros encontrados por ambos os revisadores e \\(X_4\\) o número de erros que não foram encontrados por nenhum deles.\n\nEncontre a distribuição conjunta de \\(X_1,X_2,X_3,X_4\\).\n\nMostre que \\[\\frac{\\mathbb{E}(X_1)}{\\textcolor{blue}{\\mathbb{E}(X_3)}}=\\frac{1-p_2}{p_2}\\hbox{ e }\\frac{\\mathbb{E}(X_2)}{\\mathbb{E}(X_3)}=\\frac{1-p_1}{p_1}\\]\n\nSuponha que \\(\\lambda,p_1\\) e \\(p_2\\) são ambos desconhecidos.\n\nUsando \\(X_i\\) como estimador para \\(\\mathbb{E}(X_i)\\), apresente os estimadores para \\(\\lambda,p_1\\) e \\(p_2\\).\nEncontre um estimador para \\(X_4\\), o número de erros não encontrado nenhum dos revisadores.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.8 Homens e mulheres entram em um supermercado segundo processos de Poisson com taxas 3 e 4 respectivamente. Começando num dado momento \\(s\\), seja \\(t\\) o momento da chegada do segundo homem. Calcule a probabilidade de que o número de mulheres que chegaram no intervalo \\((s,t]\\) seja menor que 3.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.9 Uma empresa tem dois tipos de clientes. Clientes chegam de acordo com um processo de Poisson com taxa \\(\\lambda\\). Num dado momento \\(t\\), a probabilidade do cliente ser do tipo I é \\(P_1(t)=e^{-t}\\) e a probabilidade dele ser do tipo II é \\(P_2(t)=1-e^{-t}\\). Seja \\(N_1(t)\\) o número de clientes do tipo I que chegaram no intervalo \\((0,t]\\). Calcule a distribuição de \\(N_1(t)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.10 José está pescando no lago. Ele pega peixes de acordo com um processo de Poisson com taxa 3 (peixes por hora) e os classifica como grandes e pequenos. A probabilidade de que um peixe seja grande é \\(1/3\\). Calcule a probabilidade de que:\n\nEm 2 horas ele vai pegar 3 peixes grandes e pelo menos um pequeno;\nEm algum momento ele vai ter exatamente \\(i\\) peixes grandes e \\(j\\) pequenos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.11 Numa região, os furacões ocorrem de acordo com um processo de Poisson com taxa 3 por unidade de tempo nos anos “bons” e com taxa 5 nos anos “ruins”. Suponha que o próximo ano vai ser bom com probabilidade 0,3. Seja \\(N(t)\\) o número de furacões nas primeiras \\(t\\) unidades de tempo do próximo ano.\n\nCalcule \\(\\mathbb{P}(N(t)=n)\\).\n\\(\\{N(t),t\\geq 0\\}\\) um processo de Poisson?\nSe o próximo ano começar com 3 furacões até o tempo \\(t\\) , calcule a probabilidade condicional de que o ano é “bom”.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.12 ejam \\(N_1(t)\\) e $N_2(t) $dois processo de Poisson independentes com respectivas taxas \\(\\lambda_1\\) e \\(\\lambda_2\\). Seja \\(N(t)=N_1(t)+N_2(t)\\). Mostre que \\(N(t)\\) é um processo de Poisson com taxa \\(\\lambda_1 +\\lambda_2\\) e calcule a probabilidade do primeiro evento do processo \\(N(t)\\) ser do processo \\(N_1(t)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.13 Em uma cidade fictícia, chamadas telefônicas solicitando um policial chegam a uma central segundo um processo de Poisson com taxa 10 por hora.\n\nDestas chamadas, 8% são trotes. Encontre a média e a variância do número de trotes recebidos pela central em 10 horas de trabalho.\nQual é o tempo esperado entre duas ligações quaisquer? E qual é o tempo esperado entre dois trotes?\nQual é a probabilidade de que a próxima ligação seja um trote?\nOcorreu um trote as 14h. Qual a probabilidade de que o segundo trote ocorra as 14:30h?\nA probabilidade de que exista um policial disponível para cada ligação é \\(p\\). Se houver um policial disponível, ele irá até o local solicitado. Caso contrário, a solicitação não será atendida. Qual é o número esperado de solicitações não atendidas em 10 horas?\nEm 10 horas, qual é o número esperado de vezes que polícia perde tempo atendendo solicitações provenientes de trotes?\nEm um dia foram recebidas 100 ligações. Qual é a probabilidade de que tenha ocorrido 50 trotes (basta escrever a expressão, não é necessário fazer toda a conta).\n\n\n\n\n\nSeção 2.6\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.14 A cada trimestre uma rede de lojas classifica seus clientes em duas categorias: A e B. Os clientes do tipo A são aqueles que gastaram, em média, mais de R$ 1.000,00 em compras naquele trimestre e os clientes do tipo B são os que gastaram, em média, menos que R$ 1.000,00. Mário visita uma das lojas da rede segundo um processo de Poisson com taxa 2 vezes por semana. A cada visita, ele gasta um valor normalmente distribuído com média R$ 40,00 e desvio padrão R$ 5,00. Suponha que o dinheiro gasto em cada visita é independente das visitas anteriores (suponha também que cada mês possui quatro semanas).\n\nEm geral, qual é a classificação esperada de Mário?\nDado que no primeiro trimestre Mário foi 25 vezes à loja, qual a distribuição do dinheiro gasto por Mário na loja naquele período? Qual a probabilidade dele ter sido classificado como cliente do tipo A?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.15 Um sistema tem um número aleatório de falhas que iremos supor ter distribuição Poisson com média \\(c\\). Cada uma dessas falhas irá, independentemente, causar a falha do sistema em um tempo aleatório com distribuição \\(G\\). Quando uma falha do sistema ocorre, suponha que o sistema é imediatamente reparado.\n\nQual é a distribuição do número de falhas até o tempo \\(t\\)?\nQual é a distribuição do número de falhas que ainda estão no sistema até o tempo \\(t\\)?\nAs variáveis aleatórias em (1) e (2) são dependentes ou independentes? Justifique.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.16 Eventos ocorrem segundo um processo de Poisson não homogêneo cuja função de valor médio é dada por \\[m(t)=t^2 +2t,\\quad   t\\geq 0.\\] Qual é a probabilidade de que \\(n\\) eventos ocorram entre os tempos \\(t=4\\) e \\(t=5\\)?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.17 Uma loja abre às 8. De 8h às 10h os clientes chegam segundo um processo de Poisson com taxa 4 por hora. Entre 10h e 12h eles chegam segundo um processo de Poisson com taxa 8 por hora. De 12h às 14h eles chegam segundo uma taxa crescente de oito por hora às 12h até dez por hora às 14h. Das 14h às 17h a taxa cai de dez por horas às 14h até quatro por hora as 17h. Determine a distribuição de probabilidade do número de clientes que entram na loja em um determinado dia.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.18 Uma companhia de seguro paga apólices de seguro de vida segundo um processo de Poisson com taxa 5 por semana. Se a quantidade de dinheiro paga por cada apólice tem distribuição exponencial com média R$ 2.000 qual é a média e a variância da quantidade de dinheiro paga pela agencia de seguro após 4 semanas? Faça as suposições necessárias.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.19 Um restaurante universitário (RU) funciona das 11:30h até 14:30h. Alunos chegam ao RU segundo um processo de Poisson não-homogêneo com taxa:\n\nconstante, igual a 50 alunos/hora, das 11:30 as 12h;\nlinearmente crescente, sendo igual a 50 alunos/hora as 12h e chegando a 150 alunos/hora as 13h;\nlinearmente decrescente, sendo igual a 150 alunos/hora as 13h e chegando a 40 alunos/hora as 14h;\nconstante, igual a 40 alunos/hora, das 14h as 14:30h.\n\nEncontre o número médio de alunos que frequentam o RU.\n\n\n\n\n\n\n\n\n\nExercício 2.20\n\n\n\n\nExercício 2.20 Passageiros embarcam no aeroporto Eduardo Gomes segundo um processo de Poisson com taxa 100 por hora. Seja \\(B_i\\) o peso (em quilos) da bagagem do \\(i\\)-ésimo passageiro, assumindo \\(B_1,B_2,\\ldots,\\) independentes com \\(B_i\\sim \\hbox{Uniforme}(10,30)\\).\n\nSeja \\(Z\\) peso total da bagagem embarcada em 2 horas no aeroporto. Encontre \\(E(Z)\\) e \\(Var(Z)\\).\nO passageiro pagará excesso de bagagem se \\(B>22Kg\\). Mostre que o número de passageiros que pagam excesso é um processo de Poisson (basta explicar) e calcule a sua taxa.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.21 Um restaurante funciona das 19h as 23h. Clientes chegam segundo um processo de Poisson não homogêneo com as seguintes taxas:\n\nEntre as 19h e 20h, a taxa permanece constante em 10 clientes.\nEntre as 20h e 22h, a taxa é \\(\\lambda(t)=-t^2+42t -430.\\).\nAs 22h a taxa é de 10 clientes, decrescendo linearmente até a taxa de 5 clientes as 23h.\n\nCom base no que foi enunciado, responda:\n\nQual o número esperado de clientes neste restaurante em um dia de funcionamento?\nQual a probabilidade de que o restaurante não tenha clientes entre as 19h e 20h?\nQual o número médio de clientes entre as 19h e 20h30min?\nA média e a variância do gasto de cada cliente são 20 reais e 500 reais\\(^2\\), respectivamente. Encontre a média e a variância do ganho esperado do restaurante em um dia de trabalho.\n\n\n\n\n\nExercícios Computacionais\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.22 A abaixo mostra o número de homicídios dolosos ocorridos em Manaus nos anos de 2008 e 2009.\n\n\n\nMês/Ano\n2008\n2009\n\n\n\n\nJaneiro\n44\n62\n\n\nFevereiro\n41\n46\n\n\nMarço\n53\n64\n\n\nAbril\n37\n51\n\n\nMaio\n40\n59\n\n\nJunho\n43\n48\n\n\nJulho\n49\n57\n\n\nAgosto\n51\n47\n\n\nSetembro\n45\n55\n\n\nOutubro\n57\n64\n\n\nNovembro\n55\n59\n\n\nDezembro\n54\n45\n\n\nTotal\n569\n657\n\n\n\n\nFonte: Secretaria de Segurança Pública do Amazonas\n\n\n\nMostre que existem evidências para supor que o número de homicídios dolosos mensais é um processo de Poisson.\nConstrua um intervalo de confiança assintótico, com 95% de confiança, para estes dados.\nConstrua um estudo de simulação, mostrando que esse intervalo de confiança é apropriado para esta situação.\n\n\n\n\n\nMiscelânea\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.23 Clientes chegam em uma loja 24h segundo um processo de Poisson com taxa \\(10\\) clientes por hora. A probabilidade de que algum destes clientes compre algo é de \\(4/5\\).\n\nQual o número esperado de clientes em um dia? Em média, quantos clientes não compraram nada durante um dia?\nQual é a distribuição do número de clientes que realmente gastam?\nDois clientes entraram na loja durante a primeira hora. Qual é a probabilidade de que nenhum cliente entre na loja na próxima hora?\nDez clientes entraram na loja. Qual é a probabilidade de que nenhum deles realize uma compra?"
  },
  {
    "objectID": "cap_3_renovacao.html#definição-e-propriedades",
    "href": "cap_3_renovacao.html#definição-e-propriedades",
    "title": "3  Processos de Renovação",
    "section": "3.1 Definição e Propriedades",
    "text": "3.1 Definição e Propriedades\nNo Capítulo 2 vimos o processo de Poisson como um caso particular dentre os processos de contagem. Neste capítulo estenderemos a discussão para outras distribuições.\nConsidere o processo de contagem \\(\\{N(t),t\\in \\mathcal{T}\\}\\) e sejam \\(T_1,\\ldots,T_n\\) variáveis aleatórias independentes e identicamente distribuídas com função de distribuição \\(F\\) com \\(E(T_1)=\\mu\\).\nDizemos que \\(T_i\\) é o \\(i\\)-ésimo tempo de chegada se ele representa o tempo decorrido entre a \\((i-1)\\) e a \\(i\\)-ésima ocorrência do evento de interesse.\nDe modo análogo, definimos \\(S_n=T_1+\\cdots+T_n\\) como o \\(n\\)-ésimo tempo de espera, ou seja, o tempo transcorrido desde de o começo do processo até a ocorrência o \\(n\\)-ésimo evento.\nDenotaremos a função de distribuição de \\(S_n\\) por \\(F^{(n)}\\). Naturalmente, \\(E(S_n)=n\\mu\\).\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 3.1 Um processo de contagem com tempos entre chegadas independentes e identicamente distribuídos é denominado Processo de Renovação (PR).\n\n\n\nO termo renovação está relacionado com o fato de que os tempos entre as chegadas são independentes e identicamente distribuídos. Talvez seja interessante ter o seguinte exemplo em mente.\n\n\n\n\n\n\nExemplo\n\n\n\n\nExemplo 3.1 Um processo de renovação pode ser ilustrado pela ideia de se ter que trocar uma lâmpada sempre que esta queima. Supondo que a troca é instantânea e que o tempo de vida das lâmpadas é identicamente distribuído pode-se imaginar que o processo se renova cada vez que uma nova lâmpada é instalada. Neste caso, o processo \\(N(t)\\) estaria contando o número de lâmpadas queimadas até o tempo \\(t\\) (ou o número de renovações de lâmpadas).\n\n\n\n\n\n\n\n\n\nExemplo\n\n\n\n\nExemplo 3.2 O PP possui tempos de chegada independentes com distribuição Exponencial(\\(\\lambda\\)) sendo, portanto, um processo de renovação.\n\n\n\nDiferente do PP, o conjunto de índices de um PR não precisa ser contínuo."
  },
  {
    "objectID": "cap_3_renovacao.html#a-distribuição-de-nt",
    "href": "cap_3_renovacao.html#a-distribuição-de-nt",
    "title": "3  Processos de Renovação",
    "section": "3.2 A Distribuição de \\(N(t)\\)",
    "text": "3.2 A Distribuição de \\(N(t)\\)\nNesta seção, mostraremos que existe uma correspondência biunívoca entre os tempos de chegada e seu respectivo processo de contagem.\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 3.1 Não podem ocorrer infinitos eventos em um tempo finito.\nDemonstração:\nSuponha que infinitos eventos podem ocorrer em um tempo finito. Isto pode ser escrito da seguinte forma: existe \\(t<\\infty\\) tal que \\(S_n\\leq t\\) para todo \\(n=0,1,2,\\ldots\\). Se isto fosse verdade, então \\[0\\leq S_n< t \\Rightarrow 0\\leq \\frac{S_n}{n}<\\frac{t}{n}.\\] Fazendo \\(n\\rightarrow \\infty\\), teríamos que \\(0\\leq S_n/n\\rightarrow 0\\). Mas isso é absurdo, pois, pela Lei Forte dos Grandes Números \\[\\frac{S_n}{n}=\\frac{T_1+\\cdots +T_n}{n}\\rightarrow E(T_1)=\\mu>0.\\] Portanto, provamos por absurdo que infinitos eventos não podem ocorrer em um tempo finito.\n\n\n\nA proposição acima tem uma importante implicação: deve existir um valor \\(n_0\\) tal que \\(S_{n_0}>t\\). Ora, se o tempo de espera do \\(n_0\\)-ésimo evento é maior que \\(t\\), então \\(S_n>t\\) para qualquer \\(n>n_0\\). Com isto, podemos enunciar o seguinte corolário.\n\n\n\n\n\n\nCorolário\n\n\n\n\nCorolário 3.1 Para um PR qualquer, é verdade que \\(N(t)= \\max\\{n:S_n\\leq t\\}\\).\nDemonstração:\nDa proposição anterior sabemos que \\(N(t)\\) não pode ser infinito. Assim, existe o maior valor de \\(n\\) que satisfaz \\(S_n\\leq t\\).\n\n\n\nPodemos então estabelecer a seguinte relação entre \\(N(t)\\) e \\(S_n\\).\n\n\n\n\n\n\nCorolário\n\n\n\n\nCorolário 3.2 Para qualquer processo de renovação, \\(S_n \\leq t \\Leftrightarrow N(t)\\geq n\\)\nDemonstração: Se \\(S_n\\leq t\\), então o tempo de espera do \\(n\\)-ésimo evento é maior ou igual a \\(t\\), o que implica que até o tempo \\(t\\) podem ter ocorrido no máximo \\(n\\) eventos. Portanto \\(S_n \\leq t \\Rightarrow N(t)\\geq n\\). A outra implicação é análoga, sendo deixada como exercício ao leitor interessado.\nEm outras palavras, temos que \\(F^{(n)}(t)=P(N(t)\\geq n)\\). Assim, a função de distribuição de \\(N(t)\\) pode ser obtida via \\(S_n\\) e vice-e-versa. Além disso, notemos que \\[\\begin{align*}\nP(N(t)=n)&= P(n\\leq N(t)< n+1) = P(N(t)< n+1) - P(N(t)< n)\\\\\n&=\\left(1-P(N(t)\\geq n+1)\\right) - \\left(1-P(N(t)\\geq )\\right)\\\\\n&=P(S_n\\leq t) -P(S_{n+1}\\leq t)=F^{(n)}(t)-F^{(n+1)}(t)\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nExemplo\n\n\n\n\nExemplo 3.3 Considere um PR com \\(T_i\\sim\\hbox{Gama}(\\mu,1)\\). Então, \\[S_n=\\sum_{i=1}^nT_i\\sim\\hbox{Gama}(n\\mu,1)\\] e \\[\\begin{align*}\n    P(N(t)=n)&=P(S_n \\leq t) -P(S_{n+1}\\leq t)\\\\\n    &=\\int_0^t \\left( \\frac{1}{\\Gamma(n\\mu)}-\\frac{s^\\mu}{\\Gamma(n\\mu+\\mu)}\\right)s^{n\\mu-1}e^{-s}ds\n    \\end{align*}\\]"
  },
  {
    "objectID": "cap_3_renovacao.html#algumas-definições-e-resultados",
    "href": "cap_3_renovacao.html#algumas-definições-e-resultados",
    "title": "3  Processos de Renovação",
    "section": "3.3 Algumas definições e resultados",
    "text": "3.3 Algumas definições e resultados\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 3.2 O número esperado de renovações no intervalo \\((0,t]\\) é dado por \\[\\begin{equation}\nm(t)=E(N(t)).\n\\end{equation}\\] e é denominado função de renovação.\n\n\n\nPela relação \\(N(t)\\geq n\\Leftrightarrow S_n\\leq t\\), teremos que\n\\[\\begin{equation}\nm(t)=E(N(t))=\\sum_{n=1}^\\infty P(N(t)\\geq n)=\\sum_{n=1}^\\infty P(S_n\\leq t).\n\\end{equation}\\]\nPodemos também avaliar o tempo médio de espera para \\(S_{N(t)+1}\\), conforme a proposição abaixo.\n\n\n\n\n\n\nProposição: Equação de Wald\n\n\n\n\nProposição 3.2 Para qualquer PR, \\[E(S_{N(t)+1})=\\mu\\left(m(t)+1\\right).\\]\nDemonstração:\nVamos utilizar o fato de que \\[N(t)\\geq j-1 \\Leftrightarrow S_{j-1}\\leq t.\\] Isto é o mesmo que escrever \\[\\textbf{I}(N(t)\\geq j-1)=\\textbf{I}(S_{j-1}\\leq t),\\] onde \\(\\textbf{I}(.)\\) é a função indicadora. Note que \\(T_j\\) é independente de \\(S_{j-1}\\). Portanto,\n\\[E\\left(T_j\\textbf{I}(S_{j-1}\\leq t)\\right)=E(T_j)E(\\textbf{I}(S_{j-1}\\leq t))=\\mu P(S_{j-1}\\leq t)=\\mu\\]\nAssim,\n\\[\\begin{align*}\nE(S_{N(t)+1})&=E(T_1)+E\\left(\\sum_{j=2}^{N(t)+1}T_j\\right)=E(T_1)+E\\left(\\sum_{j=2}^{\\infty}T_j\\textbf{I}(N(t)+1\\geq j)\\right)\\\\\n&=E(T_1)+E\\left(\\sum_{j=2}^{\\infty}T_j\\textbf{I}(S_{j-1}\\leq t)\\right)=\nE(T_1)+\\sum_{j=2}^{\\infty}E\\left(T_j\\textbf{I}(S_{j-1}\\leq t)\\right)\\\\\n&=E(T_1)+E(T_1)\\sum_{j=2}^\\infty P(S_{j-1}\\leq t)=E(T_1)\\left(1+\\sum_{j=1}^\\infty P(S_{j}\\leq t)\\right)\\\\\n&=\\mu\\left(1+m(t)\\right)\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 3.3 As variáveis aleatórias \\[\\begin{align}\n\\gamma_t &= S_{N(t)+1}-t,\\\\\n\\delta_t &= t- S_{N(t)},\\\\\n\\beta_t  &= \\gamma_t + \\delta_t,\n\\end{align}\\] são denominadas, excesso de vida (ou tempo de vida residual), vida (ou idade) corrente e vida total, respectivamente."
  },
  {
    "objectID": "cap_3_renovacao.html#resultados-assintóticos",
    "href": "cap_3_renovacao.html#resultados-assintóticos",
    "title": "3  Processos de Renovação",
    "section": "3.4 Resultados assintóticos",
    "text": "3.4 Resultados assintóticos\nO PP é o único processo de renovação no qual \\(m(t)\\) é uma função linear. Entretanto, para \\(t\\) suficientemente grande, teremos que \\(m(t)\\) é aproximadamente linear para qualquer PR. Este resultado é conhecido como Teorema Elementar dos Processos de Renovação1.\n\n\n\n\n\n\nTeorema: Teorema Elementar\n\n\n\n\nTeorema 3.1 \n\n\\(m(t)/t\\rightarrow 1/\\mu\\) quando \\(t\\rightarrow\\infty\\)\n\nDemonstração:\nPrimeiro, pela Equação de Wald, temos que \\[E(S_{N(t)+1})=\\mu[m(t)+1].\\] Uma vez que \\(E(S_{N(t)+1})\\) deve ser maior ou igual a \\(t\\), teremos que \\[\\mu[m(t)+1]\\geq t\\Rightarrow \\frac{m(t)}{t}\\geq \\frac{1}{\\mu}-\\frac{1}{t}.\\]\nPor outro lado, para qualquer \\(a>0\\) podemos definir um novo processo com os seguintes tempos entre chegadas: \\[Z_{n}=\\left\\{\\begin{array}{ll}\n    T_n,&\\hbox{ se }T_n\\leq a,\\\\\n    a,&\\hbox{ caso contrário }.\n    \\end{array}\\right.\\]\nNeste caso, existe um processo de contagem \\(N_a(t)\\) e uma função de renovação \\(m_a(t)\\) associados aos tempos de chegada \\(Z_{n}\\), e, pela Equação de Wald, \\[E(S_{N_a(t)+1,a})=\\mu_a[m_a(t)+1],\\] onde \\(\\mu_a\\) é a média dos tempos entre chegadas do processo \\(\\{N_a(t),t\\geq 0\\}\\). Note que, necessariamente, \\[E(Z_{N_a(t)+1})< a+t\\Rightarrow \\mu_a[m_a(t)+1]<a+t\\Rightarrow \\frac{m_a(t)}{t}< \\frac{a}{t\\mu_a}+\\frac{1}{\\mu_a}-\\frac{1}{t}.\\] Além disso, como os tempos de espera do processo \\(\\{N_a(t)\\}\\) são menores ou iguais aos do processo \\(\\{N(t)\\}\\), teremos \\[\\frac{m(t)}{t}\\leq \\frac{m_a(t)}{t} < \\frac{a}{t\\mu_a}+\\frac{1}{\\mu_a}-\\frac{1}{t}.\\] Portanto, temos as seguintes desigualdades, \\[\\frac{1}{\\mu}-\\frac{1}{t}\\leq \\frac{m(t)}{t}\\leq\\frac{a}{t\\mu_a}+\\frac{1}{\\mu_a}-\\frac{1}{t}\\] e fazendo \\(t\\rightarrow\\infty,\\) teremos que \\[\\frac{1}{\\mu}\\leq \\frac{m(t)}{t}\\leq \\frac{1}{\\mu_a}\\] e, como \\(\\mu_a\\rightarrow\\mu\\) quando \\(a\\rightarrow\\infty,\\) teremos que \\[\\frac{m(t)}{t}\\rightarrow   \\frac{1}{\\mu},\\] quando \\(t\\rightarrow\\infty\\)\n\n\n\n\n\n\n\n\n\nExemplo\n\n\n\n\nExemplo 3.4 Considere um PR com tempos entre chegadas com distribuição Gama\\((2,1)\\). Então \\(\\mu = 2\\) e \\(S_n\\sim\\hbox{Gama}(2n,1)\\). Teremos que \\[\\begin{align*}\n    m(t)&=\\sum_{n=1}^\\infty P(S_n\\leq t)=\n    \\sum_{n=1}^\\infty \\int_0^t  \\frac{1}{(2n-1)!}s^{2n-1}e^{-s}ds\\\\\n    &= \\int_0^t  \\sum_{n=1}^\\infty\\frac{1}{(2n-1)!}s^{2n-1}e^{-s}ds, \\;\\;\\left( \\hbox{fazendo $n=k+1$,}\\right)\\\\\n    &= \\int_0^t  \\sum_{k=0}^\\infty\\frac{1}{(2k+1)!}s^{2k+1}e^{-s}ds\\\\\n    &=\\int_0^t \\frac{1}{2}(1-e^{-2s})ds=\\frac{t}{2}-\\frac{1}{4}+\\frac{e^{-2t}}{4},\n    \\end{align*}\\] e, conforme o esperado, \\(m(t)\\) não é linear em \\(t\\). Entretanto, \\[\\frac{m(t)}{t}=\\frac{1}{2}-\\frac{1}{4t}+\\frac{e^{-2t}}{4t}\\rightarrow \\frac{1}{2}=\\frac{1}{\\mu},\\] quando \\(t\\rightarrow\\infty\\). Portanto, \\[m(t)\\approx \\frac{t}{2},\\] para \\(t\\) suficientemente grande.\n\n\n\nSeja \\(\\sigma^2\\) a variância dos tempos entre chegadas. Então, se \\(\\sigma<\\infty\\), pode-se mostrar que\n\\[\\begin{equation}\n\\frac{N(t)-t/\\mu}{\\sqrt{t \\sigma^2/\\mu^3}}\\rightarrow Normal(0,1),\n\\end{equation}\\] quando \\(t\\rightarrow\\infty\\). Deste modo, podemos ao menos ter uma distribuição aproximada para o processo de contagem.\n\n\n\n\n\n\nExemplo\n\n\n\n\nExemplo 3.5 Considere um PR cujo os tempos entre chegadas possuem distribuição Gama(2,1). Então, \\[E(T)=2,\\;\\;Var(T)=2.\\] Assim, para \\(t\\) suficientemente grande \\[N(t)\\approx Normal\\left( \\frac{t}{2},\\frac{t}{4}\\right).\\]\nNote que a distribuição de \\(N(t)\\) foi obtida no Exemplo 3.3, sendo dada por \\[P(N(t)=n)=\n\\int_0^t \\left( \\frac{1}{\\Gamma(2n)}-\\frac{s^2}{\\Gamma(2n+2)}\\right)s^{2n-1}e^{-s}ds\\]\nO código abaixo mostra a implementação dessa função de probabilidade no R:\n\nPNt <- function(n,t){\n\naux <- function(x) (1 / gamma(n*2) - x^2 / gamma(n*2 + 2)) * x^(2*n-1) * exp( - x)\n    \nintegrate(aux,0,t)[[1]]\n}\n\nA Figura 3.1 mostra \\(P(N(t)=n)\\) e a respectiva aproximação para alguns valores de \\(t\\)."
  },
  {
    "objectID": "cap_3_renovacao.html#políticas-de-trocas-por-idade",
    "href": "cap_3_renovacao.html#políticas-de-trocas-por-idade",
    "title": "3  Processos de Renovação",
    "section": "3.5 Políticas de trocas por idade",
    "text": "3.5 Políticas de trocas por idade\nSejam \\(T_1,T_2,\\ldots\\) os tempos de vida de itens (como lâmpadas) que são sucessivamente substituídos. Sabemos pelo Teorema Elementar da Renovação que os itens vão falhar com taxa \\(1/\\mu\\) por unidade de tempo.\nContudo, pode existir um custo em esperar que o item falhe. Nestes casos, adota-se uma política de trocas por idade, que consiste em trocar o item se ele falhar ou se atingir a idade \\(k\\).\nEm uma política de trocas por idade os tempos entre renovações tem distribuição\n\\[F_k(t)=\\left\\{\\begin{array}{ll}\nF(x),&\\;\\;se\\;\\;x< k,\\\\\n1,&\\;\\;\\hbox{caso contrário.}\n\\end{array}\\right.\\]\nNeste caso, a média dos tempos entre renovações com a política será2\n\\[\\mu_k=\\int_0^\\infty [1-F_k(x)]dx=\\int_0^k [1-F(x)]dx<\\mu\\]\nConsiderando um processo com política de trocas, sejam \\(Y_1,Y_2,\\ldots,\\) o tempo decorridos entre falhas. Fazendo \\(Z\\) ser o número de vezes que houveram trocas por idade antes de uma falha e \\(U_i\\) o tempo de falha que ocorre antes de \\(k\\), teremos que \\(Y_i = Zk + U_i\\). Como \\[\\begin{align*}\nP(Z=z)&=P(\\{\\hbox{z substituições por idade antes de uma falha}\\})\\\\\n&=P(T_1\\leq z)P(T_1>k)^z,\\;\\;z=0,1,2,\\ldots,\n\\end{align*}\\] e \\[\\begin{align*}\nF_U(u)=P(U_i\\leq u)=\\left\\{\\begin{array}{ll}\\frac{F(u)}{F(k)},&\\hbox{ se $0<u<k,$},\\\\\n0,&\\hbox{ caso contrário}\n\\end{array}\\right.\n\\end{align*}\\] teremos que \\[\\begin{align*}\nE(Y_i)&=E(kZ + U_i)=k\\frac{P(T_1>k)}{F(k)} +E(U_i)\n=k\\frac{P(T_1>k)}{F(k)} + \\int_0^k 1-F_U(u)du\\\\\n&=k\\frac{P(T_1>k)}{F(k)}+\\int_0^k 1-\\frac{F(u)}{F(k)}du=\\frac{1}{F(k)}\\left[kP(T_1>k)+\\int_0^k F(k)-F(u)du\\right]\\\\\n&=\\frac{1}{F(k)}\\left[kP(T_1>k)+\\int_0^k (F(k)-1)+1-F(u)du\\right]\\\\\n&=\\frac{1}{F(k)}\\left[kP(T_1>k)-kP(T_1<k)+\\int_0^k 1-F(u)du\\right]=\\frac{\\mu_k}{F(k)}.\n\\end{align*}\\] Portanto, os itens são substituídos por falha a uma taxa de \\(F(k)/\\mu_k\\) por unidade de tempo.\nAgora, suponha que o custo de substituir um item por idade é \\(c_1\\) e o custo para substituir um item que falhou é \\(c_2\\) (em geral, \\(c_2>c_1\\)). Então, o custo médio total pode ser escrito como\n\\[C(k)=\\frac{c_1}{\\mu_k}+\\frac{c_2F(k)}{\\mu_k}=\\frac{c_1+c_2F(k)}{\\mu_k}.\\]\nDeste modo, podemos encontrar qual é a idade \\(k\\) necessária para que a política de troca por idade tenha custo médio mínimo.\n\n\n\n\n\n\nExemplo\n\n\n\n\nExemplo 3.6 Considere um PR com os tempos de falha com distribuição Uniforme(0,1). Considere ainda que o custo de se trocar o item ainda funcionando é de $1 e de trocar após uma falha é $2. Vamos determinar o tempo ótimo para realizar a troca. A função de custo médio será\n\\[C(k)=\\frac{1+2k}{\\int_0^k (1-x)dx}=2\\frac{1+2k}{k-k^2}.\\]\nDerivando a função acima em \\(k\\), podemos mostrar que \\(k=1/3\\) é um ponto de mínimo global. Portanto, o custo médio é minimizado utilizando a política de trocar se o item queimar ou se seu tempo de vida passar de 1/3."
  },
  {
    "objectID": "cap_3_renovacao.html#exercícios",
    "href": "cap_3_renovacao.html#exercícios",
    "title": "3  Processos de Renovação",
    "section": "3.6 Exercícios",
    "text": "3.6 Exercícios\n\n\n\n\n\n\n\n\n\n\n\nExercício 3.1 Considere um PR com tempos entre chegadas com distribuição \\[P(T_i=t)=\\theta^t(1-\\theta)^{1-t},\\] com \\(t=0,1\\) e \\(\\theta\\in(0,1)\\). \\begin{enumerate}[a)] a. Encontre \\(P(S_n=s)\\) e mostre que \\[P(N(t)=n)=\\sum_{s=0}^tP(S_n=s)\\left[\\frac{(n+1)\\theta -s}{n+1-s}\\right]\\]. b. Mostre que \\(m(t)=(t+1)\\theta^{-1}\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 3.2 Verifique a seguinte equivalência: \\[\\gamma_t>x\\Leftrightarrow N(t+x)-N(t)=0.\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 3.3 Considere um PR onde \\(T_i\\) é uma variável aleatória contínua. Mostre que \\[P(N(t)=n)=\\int_0^t P(T_{n+2}>t-s)f_{S_n}(s)ds,\\] onde \\(f_{S_n}\\) é a função densidade de \\(S_n\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 3.4 Prove que a média do excesso de vida é dada por \\[E(\\gamma_t)=\\mu(1+m(t))-t.\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 3.5 Prove que \\[P(\\delta_t\\leq x,\\gamma_t>y)=P(N(y+t)=N(t-x))=1-F(x+y)\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 3.6 Considere um PR com tempos entre renovações dado por \\(f(x)=2x,\\) com \\(x\\in(0,1)\\). Encontre uma distribuição aproximada para \\(N(t)\\) quando \\(t\\rightarrow\\infty\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 3.7 O tempo de vida de certo aparelho é dado por \\(f(x)=2x,\\) com \\(x\\in(0,1)\\) (tempo em anos). O custo para substituir o aparelho ainda funcionando por um novo é de R$500,00. Entretanto, o custo para substituir um aparelho com defeito por é de R$1.000. Encontre uma política de troca por idade que minimize o custo médio das renovações."
  },
  {
    "objectID": "cap_4_cmtd.html#introdução",
    "href": "cap_4_cmtd.html#introdução",
    "title": "4  Cadeias de Markov a Tempo Discreto",
    "section": "4.1 Introdução",
    "text": "4.1 Introdução\nConsidere um processo estocástico \\(\\{X_n,n=0,1,2,\\ldots\\}\\), com \\(X_n\\in \\mathcal{X}\\) para todo \\(n\\) onde \\(\\mathcal{X}\\) é um conjunto discreto dos estados. Neste capítulo, o conjunto de índices deste processo será interpretado como os tempos de ocorrência do processo (por exemplo, o evento \\(\\{X_n=x\\}\\) implica que no tempo \\(n\\) o processo apresentou o valor \\(x\\)). A probabilidade do processo estar no estado \\(j\\) no tempo \\(n\\) será denotada por \\(P(X_n =j)\\).\n\n\n\n\n\n\nExemplo: De volta ao lago…\n\n\n\n\nExemplo 4.1 Lembremos do sapo que vivia em um lago e que se movimentava exclusivamente saltando entre uma vitória régia para outra (Exercício 6.33). No tempo \\(n\\), ele faz um deslocamento no tempo \\(n+1\\) para uma das plantas vizinhas, nunca saltando na diagonal. Rotularemos as vitórias régias do lago pelos números \\(1,2,\\ldots,9\\), gerando o grafo abaixo:\n\n\n\n\n\n\n\n\n\nSe a escolha do destino é feita segundo algum mecanismo aleatório, podemos considerar o processo \\(\\{X_n,n=0,1,2,\\ldots\\}\\) como sendo a planta (estado) no qual o sapo está o tempo \\(n\\). A mudança de estado, do tempo \\(t\\) para o tempo \\(t+1\\) é denominada passo. Por exemplo, se \\(X_2=1\\), os possíveis lugares que o sapo estará no seu próximo movimento (passo) são os estados 2 e 4. Voltaremos a este exemplo mais adiante.\n\n\n\nConsidere que foram observados os estados \\(x_0,\\ldots,x_{n-1}\\). A probabilidade de que \\(X_{n}=j\\) é expressada por \\[\\begin{equation}\nP(X_{n}=j|X_{0}=x_{0},X_1=x_1,\\ldots,X_{n-1}=x_{n-1}).\n\\end{equation}\\]\nDizemos que um processo estocástico possui a propriedade de Markov se a probabilidade acima depende apenas do último estado observado, ou seja \\[\\begin{equation}\nP(X_{n}=j|X_{0}=x_{0},X_1=x_1,\\ldots,X_{n-1}=x_{n-1})=P(X_{n}=j|X_{n-1} = x_{n-1}).\n\\end{equation}\\] para qualquer \\(n>0\\).\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 4.1 Um processo estocástico \\(\\{X_n,n=0,1,\\ldots\\}\\) cujo espaço dos estados é discreto e que possui a propriedade de Markov é denominado Cadeia de Markov a tempo discreto (CMTD).\n\n\n\nComo a cadeia é definido para todo \\(n=0,1,\\ldots\\), dizemos que o tempo se desloca em passos. Embora isto soe um pouco coloquial, este jargão é muito comum na literatura. Por exemplo, estando no tempo \\(n\\), a mudança para o tempo \\(n+1\\) é denominada um passo a frente e, de modo geral, “\\(k\\) passos a frente” implica na mudança para o tempo \\(n+k\\).\nEm cada passo, o processo pode (ou não) mudar de estado. Essa mudança é denominada transição.\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 4.2 No tempo \\(n\\), a probabilidade do processo fazer uma transição do estado \\(i\\) para o estado \\(j\\) será denotada por \\[\\begin{equation}\np_{ij}(n)=P(X_{n+1}=j|X_n = i),\n\\end{equation}\\] e será denominada probabilidade de transição.\n\n\n\nÉ imediato que\n\n\\(0\\leq p_{ij}(n)\\leq 1\\) para todo \\(i,j\\) em \\(\\mathcal{X}\\) e \\(n\\in \\mathbb{Z}^+\\);\n\\(\\sum_{j\\in\\mathcal{X}}p_{ij}(n)=1\\).\n\nA probabilidade de transição pode, ou não, depender de \\(n\\). Se \\(p_{ij}(n)\\) é constante para todo \\(n\\geq 0\\), dizemos que a e denotamos tal probabilidade por \\(p_{ij}\\). Em caso contrário, dizemos que a CM é não-homogênea. Neste capítulo, estamos interessados apenas nas CM homogêneas. Algumas características dos processos não-homogêneos serão exploradas nos exercícios no fim do capítulo.\n\n\n\n\n\n\nExemplo: De volta ao lago II\n\n\n\n\nExemplo 4.2 Lembremos do exemplo do sapo dado no começo deste capítulo, onde o processo \\(\\{X_n,n=0,1,2,\\}\\) que denota a planta na qual o sapo está no instante \\(n\\). Se a escolha do próximo destino depender apenas da planta atual, este processo será uma CMTD. Isto implica que:\n\nNão importa quantas vezes o sapo esteve na planta \\(i\\). A probabilidade dele escolher outra planta a partir de \\(i\\) sempre será a mesma.\nIndependente do valor de \\(n\\), o sapo sempre fará as transições do estado \\(i\\) para o \\(j\\) segundo a mesma distribuição."
  },
  {
    "objectID": "cap_4_cmtd.html#grafo-de-uma-cadeia-de-markov",
    "href": "cap_4_cmtd.html#grafo-de-uma-cadeia-de-markov",
    "title": "4  Cadeias de Markov a Tempo Discreto",
    "section": "4.2 Grafo de uma Cadeia de Markov",
    "text": "4.2 Grafo de uma Cadeia de Markov\nA matriz \\({\\bf P}=\\{p_{ij}\\}\\) é denominada matriz de transição em um passo, ou simplesmente matriz de transição. Podemos fazer a seguinte analogia entre as matrizes de adjacência e de transição:\n\nNa matriz de transição, se \\(p_{ij}=0\\) então é impossível fazer uma transição de \\(i\\) para \\(j\\) em um passo.\nNa matriz de adjacências, se \\(p_{ij}=0\\) então não existe um arco saindo de \\(i\\) e chegando em \\(j\\).\n\nCom a analogia acima, podemos construir um grafo a partir de uma cadeia de Markov como segue:\n\nCada estado da cadeia será um vértice do grafo.\nAdicione um arco saindo de \\(i\\) para \\(j\\) se \\(p_{ij}>0\\).\nAdicione um arco saindo e voltando para \\(i\\) se \\(p_{ii}>0\\) (esse arco é denominado laço).\nColoque o valor de \\(p_{ij}\\) no arco de \\((i,j)\\).\n\n\n\n\n\n\n\nExemplo\n\n\n\n\nExemplo 4.3 Considere a seguinte matriz de transição para uma cadeia de Markov:\n\n\n\n\n\n\n\n\n\nO diagrama do grafo desta cadeia é dado a seguir\n\n\n\n\n\n\n\n\n\nÉ fácil notar algumas particularidades:\n\nÉ impossível sair dos estados 0, 1, 2 ou 3 e alcançar os estados 4 ou 5. O contrário também é verdadeiro.\nDo estado 2 o processo só pode chegar ao estado 0.\nUma vez que o processo alcança o estado 3 ele permanece nesse estado para sempre."
  },
  {
    "objectID": "cap_4_cmtd.html#exemplos-de-cadeias-de-markov",
    "href": "cap_4_cmtd.html#exemplos-de-cadeias-de-markov",
    "title": "4  Cadeias de Markov a Tempo Discreto",
    "section": "4.3 Exemplos de Cadeias de Markov",
    "text": "4.3 Exemplos de Cadeias de Markov\n\n\n\n\n\n\nExemplo: Chuva\n\n\n\n\nExemplo 4.4 Suponha que a probabilidade de chover ou não amanhã dependa apenas do fato de que choveu ou não hoje. Se choveu hoje, choverá amanhã com probabilidade \\(\\alpha\\). Se não choveu hoje, choverá amanhã com probabilidade \\(\\beta\\). Seja \\({X_n,n=0,1,\\ldots}\\) o processo estocástico com espaço dos estados \\(\\mathcal{X}=\\{0,1\\}\\), onde \\(X_n=0\\) representa o evento **“não chove no dia** \\(n\\)” e 1 representa seu complementar. Explique porquê este processo é uma CMTD, encontre a sua matriz de transição e esboce o grafo da cadeia.\nResolução:\nPelo enunciado, temos que\n\n\\(P(X_n=1|X_{n-1}=1)=\\alpha\\)\n\\(P(X_n=1|X_{n-1}=0)=\\beta\\)\n\nComo a informação do dia no tempo \\(n\\) é suficiente para determinar a probabilidade de chover no dia \\(n+1\\), temos que este processo é uma CMTD. A matriz de transição é dada por\n\n\n\n\n\n\n\n\n\ne o diagrama do grafo desta cadeia é dado por\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExemplo: Passeio Aleatório\n\n\n\n\nExemplo 4.5 Seja \\(\\mathcal{X}\\subseteq\\mathbb{Z}\\). Uma CMTD será um passeio aleatório se, para algum \\(0<p<1\\) \\[p_{i,i+1}=p=1-p_{i,i-1}.\\] Assim, a cadeia só pode fazer transições de um estado para os seus estados vizinhos. Um exemplo simples é dado pelo processo \\({X_n,n=0,1,2,\\ldots}\\), onde \\(n\\) representa o número de lançamentos de uma moeda com probabilidade de dar cara igual a \\(p\\) e \\(X_n\\) representa a diferença entre o número de caras e coroas que saíram até o \\(n\\)-ésimo lançamento. Começando com \\(X_0=0\\), teremos que\n\n\\(P(X_n=i+1|X_{n-1}=i)=P(\\hbox{Sair um resultado cara})=p.\\)\n\\(P(X_n=i-1|X_{n-1}=i)=P(\\hbox{Sair um resultado coroa})=1-p.\\)\n\nA representação gráfica desta cadeia é dada abaixo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExemplo: A ruína do jogador\n\n\n\n\nExemplo 4.6 Considere um jogador que, a cada rodada, ou ganha R$ 1,00 com probabilidade \\(p\\) ou perde R$ 1,00 com probabilidade \\(1-p\\). Suponha que o jogador só abandona o jogo se ele perde todo seu dinheiro ou se ele atinge a quantidade R$ \\(N\\). Seja \\(\\{X_n,n=0,1,2,\\ldots\\}\\) o processo estocástico que representa a fortuna do jogador, cujo espaço dos estados é \\(\\mathcal{X}=\\{0,1,2,\\ldots,N\\}\\). Mostre que este processo é uma CMTD, encontre sua matriz de transição e esboce o diagrama do grafo correspondente.\nResolução:\nA quantidade de dinheiro que ele vai na próxima rodada depende unicamente de quanto ele possui na rodada atual, logo o processo representa uma cadeia de Markov com as seguintes probabilidades de transição:\n\n\\(p_{i,i+1}=p=1-p_{i,i-1}\\) para todo \\(i=1,2,\\ldots, N-1,\\)\n\\(p_{00}=p_{NN}=1,\\)\n\\(p_{ij}=0\\), caso contrário.\n\nO grafo será dado por\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExemplo: Sequência de somas de v.a.i.id\n\n\n\n\nExemplo 4.7 Sejam \\(Y_1,\\ldots,Y_n\\) variáveis aleatórias independentes e identicamente distribuídas, com \\[P(Y_n=k)=a_k,\\quad k=0,1,2,\\ldots .\\] Considere a variável \\(X_n=Y_1 + \\cdots +Y_n\\). Notemos que \\[X_n = \\sum_{i=1}^{n}Y_i=Y_n + \\sum_{i=1}^{n-1}Y_i=Y_n+X_{n-1},\\] logo \\(X_n\\) depende apenas de \\(X_{n-1}\\). Como \\(Y_n\\) é independente de \\(X_{n-1}\\), temos que, para \\(j\\geq i\\), \\[\\begin{align*}\nP(X_n=j|X_{n-1}=i)&=P(X_{n-1}+Y_n=j|X_{n-1}=i)\\\\\n&=P(Y_n=j-i|X_{n-1}=i)\\\\\n&=P(Y_n=j-i)=a_{j-i}.\n\\end{align*}\\] e, para \\(j<i\\), \\[P(X_n=j|X_{n-1}=i)=0.\\] Portanto, o processo de contagem em tempo discreto de variáveis aleatórias discretas, independentes e identicamente distribuídas é uma cadeia de Markov.\n\n\n\n\n\n\n\n\n\nExemplo: Inventário\n\n\n\n\nExemplo 4.8 Considere um intervalo pré-fixado de tempo (como um mês, um semestre, etc). Suponha que a demanda \\(Y_n\\) por certo produto no \\(n\\)-ésimo intervalo de tempo é independente do tempo e identicamente distribuída com \\[P(Y_n = k)=a_k,\\quad k=0,1,\\ldots.\\] Uma loja estoca este produto. Seja \\(X_n\\) o número destes produtos em estoque no final do intervalo de tempo \\(n\\) e seja \\(C\\) o número máximo de itens a serem estocados. No início do \\(n\\)-ésimo período o estoque é examinado e a seguinte política de renovação é adotada:\n\nSe \\(X_n\\leq s\\), o estoque é imediatamente completado até atingir a quantidade \\(C\\).\nSe \\(X_n>s\\), nada é feito.\n\nNotemos que \\(X_n\\) depende apenas de \\(X_{n-1}\\), pois:\n\nSe \\(X_{n-1}\\leq s\\), o estoque é renovado. Como demanda levará \\(Y\\) unidades, teremos \\(X_{n}=C-Y\\).\nSe \\(X_{n-1}>s\\), a demanda no tempo \\(n\\) levará \\(Y\\) unidades do estoque e \\(X_n = X_{n-1}-Y.\\)\n\nAssim, temos que \\(X_n\\) é uma CMTD com as seguintes probabilidades de transição: \\[\\begin{align*}\n&P(X_n=j|X_{n-1}=i,i\\leq s)=P(Y=C-j)=a_{C-j}\\\\\n&P(X_n=j|X_{n-1}=i,i> s)=P(Y=i-j)=a_{i-j}.\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nExemplo: PageRank\n\n\n\n\nExemplo 4.9 Páginas de pesquisa da web, como o Google, utilizam uma CMTD para mostrar as páginas com maior relevância. Suponha que existem \\(N\\) páginas conhecidas. Suponha ainda que a \\(i\\)-ésima página possui \\(k_i\\) links. Seja \\(H\\) o evento no qual um usuário utiliza os links para navegar, com \\(P(H)=\\alpha\\) e seja \\(X_n\\) a página na qual o indivíduo se encontra no tempo \\(n\\). Estando na página \\(i\\) considere que:\n\no usuário escolhe um link ao acaso. Neste caso, \\[P(X_n =j|X_{n-1}=i, H)=\\frac{1}{k_i},\\] quando existe um link na página \\(i\\) para a página \\(j\\).\no usuário não utiliza um link. Neste caso, ele escolhe ao acaso entre todas as páginas \\[P(X_n= j|X_{n-1}=i,H^c)=\\frac{1}{N},\\] onde \\(N\\) é o número de páginas disponíveis (essa probabilidade inclui a possibilidade do indivíduo entrar na mesma página outra vez).\n\nAssim, se existe um link para a página \\(j\\) a partir da página \\(i\\), a probabilidade desta transição é dada por \\[\\begin{align*}\np_{ij}&=P(X_n=j|X_{n-1}=i)\\\\&=P(X_n=j,H|X_{n-1}=i)+P(X_n=j,H^c|X_{n-1}=i)\\\\&=P(X_n=j|X_{n-1}=i,H)P(H)+P(X_{n}=j|X_{n-1}=i,H^c)P(H^c)\\\\\n&=\\frac{\\alpha}{k_i}+\\frac{1-\\alpha}{N},\n\\end{align*}\\] e, se \\(k_i=0\\), ou se \\(j=i\\), então utiliza-se a seguinte expressão: \\[\\begin{align*}\np_{ij}=\\frac{1-\\alpha}{N}.\n\\end{align*}\\] Podemos calcular a probabilidade de que \\[\\lim_{n\\rightarrow\\infty}P(X_n=i),\\] o que, intuitivamente, implica em calcular a probabilidade de se estar no site \\(i\\) após muito tempo de navegação. Organizando estas últimas probabilidades em ordem decrescente, temos o ranqueamento das páginas por ordem de relevância. Este método é conhecido como PageRank. Mais detalhes serão dados posteriormente."
  },
  {
    "objectID": "cap_4_cmtd.html#as-equações-de-chapman-kolmogorov",
    "href": "cap_4_cmtd.html#as-equações-de-chapman-kolmogorov",
    "title": "4  Cadeias de Markov a Tempo Discreto",
    "section": "4.4 As Equações de Chapman-Kolmogorov",
    "text": "4.4 As Equações de Chapman-Kolmogorov\nNo estudo de uma CMTD, é interessante saber qual a probabilidade do processo, saindo do estado \\(i\\), estar em \\(j\\) após \\(n\\) passos, ou seja \\(P(X_{n}=j|X_0 = i)\\). Tal probabilidade é denominada transição \\(n\\) passos a frente, e é denotada por \\(p_{ij}^{(n)}\\). A partir desta definição, pode-se enunciar a seguinte proposição.\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 4.1 Para uma CMTD, \\[\\begin{align}\nP(X_{n+m}=j|X_n=i,X_{n-1}=i_{n-1},\\ldots,X_0=i_0)=p_{ij}^{(m)}\n\\end{align}\\]\nDemonstração:\nA prova pode ser feita por indução. Note que a proposição é verdadeira para \\(m=1\\), pois pela propriedade de Markov, \\[P(X_{n+1}=j|X_{n}=i,X_{n-1}=i_{n-1},\\ldots,X_0=i_0)=p_{ij}=p_{ij}^{(1)}.\\] Para \\(m>2\\), suponha que \\[P(X_{n+m-1}=j|X_{n}=i,Y_{n-1})=P(X_{n+m-1}=j|X_{n}=i)=p_{ij}^{(m-1)},\\] onde \\(Y_{n-1} = \\{X_{n-1}=x_{n-1},\\ldots,X_0=x_0\\}\\). Então, \\[\\begin{align*}\nP(X_{n+m}=j|X_{n}=i, Y_{n-1})&=\\sum_{x=0}^{\\infty} P(X_{n+m}=j,X_{n+m-1}=x|X_{n}=i, Y_{n-1})\\\\\n&=\\sum_{x=}^{\\infty} P(X_{n+m}=j|X_{n+m-1}=x,X_{n}=i,Y_{n-1})\\\\\n&\\times P(X_{n+m-1}=x|X_{n}=i,Y_{n-1})\\\\\n&=\\sum_{x=0}^{\\infty}P(X_{n+m}=j|X_{n+m-1}=x)P(X_{n+m-1}=x|X_{n}=i)\\\\\n&=\\sum_{x=0}^\\infty P(X_{n+m}=i,X_{n+m-1}=x|X_{n}=i)\\\\\n&=P(X_{n+m}=j|X_n=i)=p_{ij}^{(m)}.\n\\end{align*}\\]\nPortanto, a propriedade de Markov continua válida para um número de passos maior que um.\n\n\n\n\n\n\n\n\n\nExemplo\n\n\n\n\nExemplo 4.10 A CMTD abaixo foi apresentada no Exemplo 4.3.\n\n\n\n\n\n\n\n\n\nMas, note que \\(p_{0i}p_{ij}\\) é o produto do valor do arco \\((0,i)\\) com o valor do arco \\((i,j)\\). Assim, calcular a probabilidade de sair de \\(0\\) e chegar em \\(j\\) em dois passos é equivalente a colocar uma caneta no estado zero e encontrar todos os caminhos em dois passos até \\(j\\), multiplicar os valores dos arcos em cada caminho e somar o resultado final. Continuando com o exemplo, temos os seguintes caminhos com suas respectivas probabilidades:\n\n\n\n\n\n\n\n\n\n\n\nEstado de destino(\\(j\\))\n\n\nCaminhos em dois passos\n\\(p_{0i}p_{ij}\\)\n\\(p_{0j}^{(2)}\\)\n\n\n\n\n0\n\n\n\\(0\\rightarrow 0\\rightarrow 0\\)  \\(0\\rightarrow 2\\rightarrow 0\\)\n\\(p_{00}p_{00}=\\frac{1}{9}\\)  \\(p_{02}p_{20}=\\frac{1}{3}\\)\n\\(p_{00}^{(2)}=\\frac{1}{9}+\\frac{1}{3}=\\frac{4}{9}\\)\n\n\n1\n\n\n\\(0\\rightarrow 0\\rightarrow 1\\)\n\\(p_{00}p_{01}=\\frac{1}{9}\\)\n\\(p_{01}^{(2)}=1/9\\)\n\n\n2\n\n\n\\(0\\rightarrow 0\\rightarrow 2\\)  \\(0\\rightarrow 1\\rightarrow 2\\)\n\\(p_{00}p_{02}=\\frac{1}{9}\\)  \\(p_{00}p_{02}=\\frac{1}{9}\\)\n\\(p_{02}^{(2)}=2/9\\)\n\n\n3\n\n\n\\(0\\rightarrow 1\\rightarrow 3\\)\n\\(p_{01}p_{13}=\\frac{2}{9}\\)\n\\(p_{03}^{(2)}=2/9\\)\n\n\n\nAssim, estando em \\(0\\), a probabilidade de que o estado esteja em 0 em dois passos é de 4/9. Agora, para calcular as probabilidades \\(p_{0j}^{(3)}\\), note primeiro que nós já conhecemos essas probabilidades em dois passos. Assim, \\[\\begin{align}\np_{0j}^{(3)}&=P(X_3=j|X_0=0)=\\sum_{i=0}^{5}P(X_3=j,X_2=i|X_0=0)\\notag\\\\\n&=\\sum_{i=0}^{5}P(X_3=j|X_2=i,X_0=0)P(X_2=i|X_0=0)\\notag\\\\\n&=\\sum_{i=0}^{5}P(X_3=j|X_2=i)P(X_2=i|X_0=0) \\\\\n&=\\sum_{i=0}^5 p_{0i}p_{ij}^{(2)}.\n\\end{align}\\] Como no caso anterior, o cálculo de \\(p_{0j}^{(3)}\\) depende do produto \\(p_{0i}p_{ij}^{(2)}\\). Entretanto, \\[p_{0i}p_{ij}^{(2)}=p_{0i}\\sum_{k=0}^{5}p_{ik}p_{kj}.\\] Portanto, a probabilidade de \\(p_{0j}^{(3)}\\) é obtida pela soma dos produtos \\(p_{0i}p_{ik}p_{kj}\\). Novamente, poderíamos colocar uma caneta no estado 0 e traçar todos os caminhos que saem de 0 e chegam em \\(j\\) em três passos, calcular o produto dos valores dos arcos de cada caminho e somar os resultados. Contudo, como já conhecemos \\(p_{0i}^{(2)}\\), podemos simplificar nosso trabalho com utilizando a expressão acima. A tabela abaixo mostra os cálculos.\n\n\n\n\n\n\n\n\n\nEstado de destino(\\(j\\))\nCaminhos em dois passos (i)\n\\(p_{0i}^{(2)}p_{ij}\\)\n\\(p_{0j}^{(3)}\\)\n\n\n\n\n0\n0123\n\\(p_{00}^{(2)}p_{00}=\\frac{4}{27}\\)  \\(p_{01}^{(2)}p_{10}=0\\)  \\(p_{02}^{(2)}p_{20}=\\frac{6}{27}\\)  \\(p_{03}^{(2)}p_{30}=0\\)\n \\(p_{00}^{(3)}=\\frac{10}{27}\\)\n\n\n1\n0123\n\\(p_{00}^{(2)}p_{01}=\\frac{4}{27}\\)  \\(p_{01}^{(2)}p_{11}=0\\)  \\(p_{02}^{(2)}p_{21}=0\\)  \\(p_{03}^{(2)}p_{31}=0\\)\n \\(p_{01}^{(3)}=\\frac{4}{27}\\)\n\n\n2\n0123\n\\(p_{00}^{(2)}p_{02}=\\frac{4}{27}\\)  \\(p_{01}^{(2)}p_{12}=\\frac{1}{27}\\)  \\(p_{02}^{(2)}p_{22}=0\\)  \\(p_{03}^{(2)}p_{32}=0\\)\n \\(p_{02}^{(3)}=\\frac{5}{27}\\)\n\n\n3\n0123\n\\(p_{00}^{(2)}p_{03}=0\\)  \\(p_{01}^{(2)}p_{13}=\\frac{2}{27}\\)  \\(p_{02}^{(2)}p_{23}=0\\)  \\(p_{03}^{(2)}p_{33}=\\frac{2}{9}\\)\n \\(p_{03}^{(3)}=\\frac{8}{27}\\)\n\n\n\nO exemplo anterior nos mostrou que as probabilidades de transição em dois passos podem ser utilizadas para encontrar as probabilidades em três passos. Esse resultado pode ser generalizado. Primeiro, supondo-se que \\(p_{ij}^{(m-n)}\\) é conhecida, pela homogeneidade da CMTD, é intuitivo que para calcular \\(p_{ij}^{(m)}\\) basta conhecer a probabilidade dos \\(n\\) passos restantes, ou seja \\(p_{ij}^{(n)}\\). Esta relação é verdadeira, como mostra a proposição a seguir.\n\n\n\n\n\n\n\n\n\nProposição: Chapman-Kolmogorov\n\n\n\n\nProposição 4.2 Para \\(m> n\\), \\[p_{ij}^{(m)}=\\sum_{k=0}^{\\infty}p_{ik}^{(n)}p_{kj}^{(m-n)}.\\] Esse conjunto de equações1 é denominado Equações de Chapman-Kolmogorov (CK).\nDemontração:\n\\[\\begin{align*}\np_{ij}^{(m)}&=P(X_{m}=j|X_0 = i)= \\sum_{k=0}^{\\infty}P(X_{m}=j, X_n = k|X_0 = i) \\\\\n&=\\sum_{k=0}^{\\infty}P(X_{m}=j | X_n = k, X_0 = i) P(X_n = k| X_0 = i)\\\\\n&= \\sum_{k=0}^{\\infty}P(X_{m}=j | X_n = k)P(X_n = k| X_0 = i)=\\sum_{k=0}^{\\infty}p_{ik}^{(n)}p_{kj}^{(m-n)}\n\\end{align*}\\]\nPortanto, a partir das probabilidades de transição em \\(m\\) passos pode-se definir a matriz de transição em \\(m\\) passos, denotada por \\({\\bf P}^{(m)}\\). Novamente, tem-se que \\(p_{ij}^{(m)}\\) estará no cruzamento entre a \\(i\\)-ésima linha com a \\(j\\)-ésima coluna de \\({\\bf P}^{(m)}\\).\nExiste uma relação direta entre as matrizes \\({\\bf P}\\) e \\({\\bf P}^{(m)}\\). Considerando-se a \\({\\bf A}=\\{a_{i,j},i,j=0,\\ldots,n\\}\\), tem-se que \\({\\bf A}^2=\\{b_{ij}=\\sum_{k=0}^{n}a_{ik}a_{kj}\\}\\) (a regra ainda é válida para \\(n=\\infty\\)). Se tomarmos \\({\\bf A}={\\bf P}\\), teremos que \\[{\\bf P}^{2}=\\{ q_{ij}=\\sum_{k=0}^{n}p_{ik}p_{kj},i,j=0,1,\\ldots,n\\}.\\] Mas, por CK, temos que \\(q_{ij}=p_{ij}^{(2)}\\). Assim, \\({\\bf P}^{(2)}={\\bf P}^2\\). É deixado como exercício para o leitor mostrar a seguinte proposição.\n\n\n\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 4.3 Seja \\(\\bf{P}\\) a matriz de transição de uma CMTD e seja \\({\\bf P}^{(n)}\\) sua respectiva matriz de transição \\(n\\) passos a frente. Então \\({\\bf P}^{(m)}={\\bf P}^m\\).\n\n\n\n\n\n\n\n\n\nExemplo: Chuva revisitado\n\n\n\n\nExemplo 4.11 No Exemplo 4.4 foi apresentado o processo \\(\\{X_n,n=0,1,\\ldots\\}\\) sendo que \\(X_{n}=I(\\text{Chove no dia n})\\). Suponha que \\({\\bf P}\\) é dada por:\n\n\n\n\n\n\n\n\n\nA matriz de transição dois passos a frente é\n\n\n\n\n\n\n\n\n\nPor exemplo, se não chove hoje, a probabilidade de chover daqui a dois dias é de 65,4%. Podem ser feitas previsões para horizontes maiores. Por exemplo, as matrizes de transição para 3 e 10 passos a frente são\n\n\n\n\n\n\n\n\n\ne\n\n\n\n\n\n\n\n\n\nEntretanto, as linhas destas matriz parecem ficar cada vez mais próximas na medida em que o número de passos as frente aumenta. Isso implica em dizer que o último estado conhecido não tem influência quando o número de passos aumenta. Assumir que isto é verdade implica em assumir que existem constantes \\(\\pi_j\\), \\(j=0,1\\) tais que \\[\\lim_{n\\rightarrow\\infty}p_{ij}^{(n)}=\\pi_j,\\] Neste exemplo em especial, \\(\\pi_0\\approx.3478\\) e \\(\\pi_1\\approx.652\\), o que implicaria que, após observar o processo por um tempo suficiente, a probabilidade de se observar um dia chuvoso é de aproximadamente 65%. Entretanto, não temos (ainda!) garantias da existência desse limite. Este assunto é discutido na Seção 4.6."
  },
  {
    "objectID": "cap_4_cmtd.html#classificação-de-estados",
    "href": "cap_4_cmtd.html#classificação-de-estados",
    "title": "4  Cadeias de Markov a Tempo Discreto",
    "section": "4.5 Classificação de Estados",
    "text": "4.5 Classificação de Estados\n\n4.5.1 Comunicação entre Estados\nÉ dito que \\(j\\) é acessível a partir de \\(i\\) se existe a probabilidade de que o processo saia de \\(i\\) e entre em \\(j\\) em algum momento. Na representação do grafo, \\(j\\) é acessível a partir de \\(i\\) se existe um arco orientado saindo de \\(i\\) e chegando em \\(j\\). Formalmente:\n\n\n\n\n\n\nDefinição: Acessibilidade\n\n\n\n\nDefinição 4.3 É dito que o estado \\(j\\) é acessível a partir de \\(i\\), se existe pelo menos um \\(n\\) tal que \\(p_{ij}^{(n)}>0\\). Notação: \\(i\\rightarrow j\\).\n\n\n\n\n\n\n\n\n\nDefinição: Comunicabilidade\n\n\n\n\nDefinição 4.4 É dito que \\(i\\) se comunica com \\(j\\) se \\(i\\rightarrow j\\) e \\(j\\rightarrow i\\). Notação: \\(i\\leftrightarrow j\\).\n\n\n\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 4.5 É dito que os estados \\(i\\) e \\(j\\) estão na mesma classe se \\(i\\leftrightarrow j\\).\n\n\n\nEm um grafo, dois estado comunicam-se se existem caminhos orientados que ligam os estados nos dois sentidos.\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 4.4 Para dois estados \\(i\\) e \\(j\\) quaisquer:\n\n\\(i\\leftrightarrow i\\).\nSe \\(i\\leftrightarrow j\\) então \\(j\\leftrightarrow i\\) (propriedade reflexiva).\nSe \\(i\\leftrightarrow k\\) e \\(k\\leftrightarrow j\\), então \\(i\\leftrightarrow j\\).\n\nDemontração:\nTemos que:\n\nComo \\(p_{ii}^{(0)}=1\\), temos que \\(i\\rightarrow i\\), logo \\(i\\leftrightarrow i\\).\nSe \\(i\\leftrightarrow j\\), então existem \\(i\\rightarrow j\\) e \\(j\\rightarrow i\\). Logo, existe \\(j\\leftrightarrow i\\).\nSe \\(i\\leftrightarrow k\\) e \\(k\\leftrightarrow j\\), então \\(i\\rightarrow j\\) (pois existe uma sequência de arcos orientados saindo de \\(i\\) e chegando em \\(k\\), outra sequência saindo de \\(k\\) e chegando em \\(j\\)). De maneira análoga \\(j\\rightarrow i\\), logo \\(i\\leftrightarrow j\\).\n\n\n\n\nPor último, existem estados que não podem acessar nenhum outro, ou seja, para todo \\(j\\neq i\\) e qualquer \\(n\\) teremos \\(p_{ij}^{n}=0\\). Neste caso, teremos que \\(p_{ii}^{(n)}=1\\) para qualquer \\(n\\). Um estado com essa característica é denominado estado absorvente.\n\n\n\n\n\n\nExemplo\n\n\n\n\nExemplo 4.12 A CMTD abaixo foi apresentada no Exemplo 4.3.\n\n\n\n\n\n\n\n\n\nSobre a acessibilidade, podemos dizer que:\n\nOs estados 1,2 e 3 são acessíveis a partir de 0. Note que podemos sair de 0 e chegar em 1 e 2 com apenas um passos, enquanto que serão necessários pelo menos dois passos para chegar no estado 3. Assim \\(0\\rightarrow 1\\),\\(0\\rightarrow 2\\) e \\(0\\rightarrow 3\\), mas \\(0\\nrightarrow 4\\) e \\(0\\nrightarrow 5\\).\nOs estados 0, 2 e 3 são acessíveis a partir de 1. Assim, \\(1\\rightarrow 0\\), \\(1\\rightarrow 2\\) e \\(1\\rightarrow 3\\), mas \\(1\\nrightarrow 4\\) e \\(1\\nrightarrow 5\\).\nNenhum estado é acessível a partir de 3. Assim \\(3\\nrightarrow j\\) para todo \\(j\\neq 3\\).\nPor último \\(4\\nrightarrow 5\\) e \\(5\\nrightarrow 4\\).\n\nSobre a comunicabilidade, podemos dizer que\n\n\\(0\\leftrightarrow 1\\) e \\(0\\leftrightarrow 2\\), pois podemos sair de 0, chegar nestes estados e voltar.\n\\(1\\leftrightarrow 0\\) e \\(1\\leftrightarrow 2\\), pois podemos sair de 1, chegar nestes estados e voltar.\n\\(2\\leftrightarrow 0\\) e \\(2\\leftrightarrow 1\\), pois podemos sair de 2, chegar nestes estados e voltar.\n\\(4\\leftrightarrow 5\\).\n\nDisto, temos as seguintes classes de estados: \\(\\{0,1,2\\}, \\{3\\} \\text{ e } \\{4,5\\}\\). Por último, note que o estado 3 é absorvente.\nPor último, dizemos que uma CMTD é irredutível se ela possui uma única classe.\n\n\n\n\n\n\n\n\n\n4.13 Exemplo (Chuva revisitado)\n\n\n\n\nExemplo 4.13 A CMTD do Exemplo 4.4 é irredutível.\n\n\n\n\n\n4.5.2 Classes Transientes e Recorrentes\nConsidere o grafo da seguinte CMDT\n\n\n\n\n\n\n\n\n\nExistem duas classes nessa cadeia: \\(C_1=\\{0,1,2\\}\\) e \\(C_2\\{3\\}\\). Se o processo começar no estado 3, ele nunca mais sairá destes (ele é absorvente). Então, considere que o processo começou em outro estado da classe \\(C_1\\). Toda vez que o processo passar pelo estado 2, existe a chance ele ir para a classe \\(C_2\\) - e, portanto, de nunca voltar para \\(C_1\\). Considere agora o grafo abaixo\n\n\n\n\n\n\n\n\n\nPodemos notar que existem duas classes: \\(C_1=\\{0,1,2\\}\\) e \\(C_2=\\{3,4\\}\\). Começando na classe \\(C_2\\), não é como o processo chegar até a classe \\(C_1\\). Entretanto, estando em \\(C_1\\), sempre existe a probabilidade do processo fazer uma transição do estado 2 para o 3 e nunca mais voltar para \\(C_1\\).\nos dois exemplos acima vimos dois tipos de classes: aquelas que o processo pode abandonar e as que o processo nunca abandona. Esses tipos são denominados transiente e recorrente, respectivamente. Antes de definirmos formalmente estes tipos de classes, é conveniente primeiro definir estados recorrentes e transientes.\nSeja \\(f_{ij}^{(n)}\\) a probabilidade do processo sair do estado \\(i\\) e chegar, pela primeira vez em \\(j\\), em exatos \\(n\\) passos, ou seja \\[\\begin{equation}\nf_{ij}^{(n)}=P(X_n=j,X_{n-1}\\neq j,\\ldots, X_1\\neq j|X_0 =i).\n\\end{equation}\\]\nA probabilidade de que o processo saia de \\(i\\) e chegue em \\(j\\) em algum momento é dada por \\[\\begin{align*}\nf_{ij}&=P(\\hbox{$\\cup_{n=1}^\\infty$\\{chegar em $j$ em exatos $n$ passos\\}})\\\\\n&=\\sum_{n=1}^{\\infty}P(\\hbox{ \\{chegar em $j$ em exatos $n$ passos\\}})\\\\\n&=\\sum_{n=1}^{\\infty}f_{ij}^{(n)}.\n\\end{align*}\\]\nCom isso, podemos definir estados transientes e recorrentes.\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 4.6 Dizemos que o estado \\(i\\) é recorrente se \\(f_{ii}=1\\) e dizemos que ele é transiente se \\(f_{ii}<1\\).\n\n\n\nAssim, ao sair de um estado recorrente, o processo retornará com probabilidade um (ele retornará certamente). Por outro lado, ao sair de um estado transiente, sempre haverá a possibilidade de o processo não voltar para este estado. De fato, podemos mostrar que um estado transiente só pode ser visitado um número finito de vezes.\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 4.5 eja \\(i\\) um estado transiente. Então, se o processo passar por \\(i\\), esse estado será visitado um número finito de vezes.\nDemontração:\nSeja \\(i\\) um estado transiente e, sem perda de generalidade, assuma que \\(X_0=i\\). Seja \\(A_k\\) o evento no qual o processo saiu de \\(i\\) e voltou pela \\(k\\)-ésima vez. Temos que os eventos \\(A_k\\), \\(k=1,2,\\ldots,\\) são independentes (pela propriedade de Markov, uma vez estando no estado \\(i\\), todo o caminho já percorrido é irrelevante). Temos ainda que \\(P(A_k)=f_{ii}\\). Notemos que, se ocorrer \\(A_{k}^c\\), o processo nunca mais retornará para \\(i\\). Seja \\(M\\) o número de vezes que o processo voltou para \\(i\\). Temos que \\(M\\) terá distribuição geométrica, ou seja \\[P(M=m)=f_{ii}^{m}(1-f_{ii}),\\quad n=0,1,2,\\ldots.\\]\n\n\n\n\n\n\n\n\n\nCorolário\n\n\n\n\nCorolário 4.1 eja \\(i\\) um estado transiente e seja \\(M\\) de vezes que o processo voltou para \\(i\\). Então \\[E(M)=\\frac{f_{ii}}{1-f_{ii}}<\\infty.\\]\n\n\n\nPara mostrar que um estado \\(i\\) é transiente (ou recorrente) diretamente pela Definição 4.10, é necessário calcular a probabilidade \\(f_{ii}\\). A seguinte proposição mostra que isto também é possível utilizando diretamente as probabilidades de transição em \\(n\\) passos.\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 4.6 O estado \\(i\\) é transiente se e somente se \\(\\sum_{n=1}^{\\infty}p_{ii}^{(n)}<\\infty\\).\nDemonstração:\nSeja \\(M=\\sum_{n=1}^{\\infty}I(X_n=i)\\) (i.é, \\(M\\) é o número de vezes que o processo retorna a \\(i\\)). Então \\[\\begin{align*}\nE(M|X_0=i)&= E[\\sum_{n=1}^{\\infty}I(X_n=i)|X_0=i]=\\sum_{n=1}^{\\infty} E[I(X_n=i)|X_0=i]\\\\\n&=\\sum_{n=1}^\\infty P(X_n =i | X_0 = i)=\\sum_{n=1}^\\infty p_{ii}^{(n)}.\n\\end{align*}\\] Se \\(i\\) é transiente, então \\(E(M|X_0=i)\\) deve ser finito, o que implica em \\(\\sum_{n=1}^\\infty p_{ii}^{(n)}<\\infty\\). Se \\(\\sum_{n=1}^{(n)}p_{ij}^{(n)}<\\infty\\), então \\(E(M|X_0)\\) é finito e o estado \\(i\\) é visitado apenas um número finito de vezes, o que implica que \\(i\\) é transiente.\n\n\n\n\n\n\n\n\n\nCorolário\n\n\n\n\nCorolário 4.2 estado \\(j\\) é recorrente se e somente se \\(\\sum_{n=1}^{\\infty}p_{jj}^{(n)}=\\infty\\).\nAgora, mostraremos que se existe um estado transiente(recorrente) em uma classe, então, todos os estados da classes também serão transientes (recorrentes).\n\n\n\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 4.7 Se \\(i\\leftrightarrow j\\) e \\(i\\) é transiente, então \\(j\\) é transiente. Além disso, se \\(i\\leftrightarrow j\\) e \\(i\\) é recorrente, então \\(j\\) é recorrente.\nComo \\(i\\leftrightarrow j\\), então existe um número de passos \\(n\\) tal que é possível sair de \\(i\\) e chegar em \\(j\\) e um número de passos \\(m\\) tal que é possível sair de \\(j\\) e chegar em \\(i\\), logo \\(p_{ij}^{(n)}>0\\) e \\(p_{ji}^{(m)}>0\\). Notemos que \\[\\begin{align*}\n\\sum_{v=0}^{\\infty}p_{jj}^{(m+n+v)}&=\n\\sum_{v=0}^{\\infty}\\sum_{u=0}^{\\infty}\\sum_{s=0}^{\\infty}p_{ju}^{(m)}p_{us}^{(v)}p_{sj}^{(n)}\n\\geq \\sum_{v=0}^{\\infty}p_{ji}^{(m)}p_{ii}^{(v)}p_{ij}^{(n)}\\\\&=p_{ji}^{(m)}p_{ij}^{(n)}\\sum_{v=0}^{\\infty}p_{ii}^{(v)}\n\\end{align*}\\] Notando que \\(\\sum_{v=0}^{\\infty} p_{jj}^{(m+n+v)}=\\sum_{v^\\star=m+n}^{\\infty}p_{jj}^{(v^\\star)}\\), teremos \\[\\sum_{v^\\star=0}^\\infty p_{jj}^{(v^\\star)}>\\textcolor{blue}{\\sum_{v^\\star=m+n}^\\infty p_{jj}^{(v^\\star)}}\\geq p_{ji}^{(m)}p_{ij}^{(n)}\\sum_{v=0}^{\\infty}p_{ii}^{(v)}\\]\nAssim, se \\(j\\) for transiente, teremos que \\(\\sum_{v=0}^{\\infty}p_{jj}^{(v)}<\\infty\\) e, portanto \\(\\sum_{v=0}^{\\infty}p_{ii}^{ (v)}<\\infty\\) o que implica em \\(i\\) ser transiente. Além disso, podemos seguir os mesmos passos e mostrar que \\[\\sum_{v^\\star=0}^\\infty p_{ii}^{(v^\\star)}\\geq p_{ji}^{(n)}p_{ji}^{(m)}\\sum_{v=0}^{\\infty}p_{jj}^{(v)},\\] logo, \\(i\\) transiente implica em \\(j\\) transiente. Por último, se um dos dois estados for recorrente, o outro deve ser recorrente também.\n\n\n\n\n\n\n\n\n\nCorolário\n\n\n\n\nCorolário 4.3 Seja \\(C\\) uma classe de estados. Se \\(i\\in C\\) e \\(i\\) é transiente(recorrente), então todos os estados de \\(C\\) serão transientes(recorrentes).\n\n\n\nAgora, seja um estado \\(i\\) recorrente. Já é conhecido que, partindo de \\(i\\), o processo visitará \\(i\\) infinitas vezes. Entretanto, existem estados recorrentes cujo tempo médio de retorno não é finito. Para explicar melhor esse fenômeno, recorde que, se \\(i\\) é recorrente, então \\(f_{ii}=\\sum_{n=1}^{\\infty}f_{ii}^{(n)}=1\\). Deste modo, \\(f_{ii}^{(n)}\\) é função de probabilidade de uma variável \\(N\\) que representa o número de passos necessários para o processo sair de \\(i\\) e voltar pela primeira vez para \\(i\\). Assim, defina \\[\\begin{equation}\n\\mu_{ii}=\\sum_{n=1}^\\infty n f_{ii}^{(n)},\n\\end{equation}\\] como sendo o tempo médio da recorrência e considere a CMTD abaixo:\n\n\n\n\n\n\n\n\n\nÉ fácil notar que a CMTD acima é irredutível e sua única classe é recorrente. Tomando o estado 0, notemos que:\n\n\\(f_{00}^{(1)}=0\\), pois é impossível chegar em zero em um passo.\n\\(f_{00}^{(2)}=1\\), pois sempre chegaremos em zero em dois passos.\n\\(f_{00}^{(k)}=0\\), \\(k>2\\), pois não é possível partir de zero e chegar em zero pela primeira vez em um número de passos maior que 2.\n\nPortanto, \\[\\begin{equation}\n\\mu_{00}=\\sum_{n=1}^{\\infty}nf_{00}^{(n)}=1\\times f_{00}^{(1)} + 2\\times f_{00}^{(2)} =2\n\\end{equation}\\] Como a \\(\\mu_{00}=2<\\infty\\), esperamos que o processo volte para 0 em um tempo finito. Indo para o outro extremo, considere a CMDT com as seguintes probabilidades de transição: \\[p_{01}=1,p_{i,i+1}=\\frac{i}{i+1},p_{i0}=\\frac{1}{i+1},\\] com \\(i=1,2,\\ldots\\), cujo grafo está esboçado abaixo:\n\n\n\n\n\n\n\n\n\nComo existe a probabilidade do processo chegar em qualquer estado e depois voltar para zero, a CMDT acima é irredutível. Para mostrar que a cadeia é recorrente, note que:\n\n\\(f_{00}^{(1)}=0\\);\n\\(f_{00}^{(2)}=\\frac{1}{1}\\frac{1}{2}\\);\n\\(f_{00}^{(3)}=\\frac{1}{2}\\frac{1}{3}\\)\n\\(f_{00}^{(4)}=\\frac{1}{2}\\frac{2}{3}\\frac{1}{4}=\\frac{1}{3}\\frac{1}{4}\\)\n\\(\\vdots\\)\n\\(f_{00}^{(n)}=\\frac{1}{n(n-1)}\\)\n\nAssim, \\[f_{00}=\\sum_{n=2}^{\\infty}\\frac{1}{n(n-1)}=\\lim_{k\\rightarrow\\infty}\\sum_{n=2}^{k}\\frac{1}{n(n-1)}=\\lim_{k\\rightarrow\\infty}\\frac{k-1}{k}=1,\\] logo 0 é recorrente. Além disso, \\[\\mu_{00}=\\sum_{n=1}^{\\infty}nf_{00}^{(n)}=\\sum_{n=2}^{\\infty}\\frac{1}{n-1}=\\infty,\\] sendo que o tempo médio de recorrência para o estado 0 não é finito. Portanto, os estados recorrentes podem ser classificados em dois tipos, segundo a definição abaixo.\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 4.7 Seja \\(i\\) um estado recorrente. Dizemos que \\(i\\) é recorrente positivo se \\(\\mu_{ii}<\\infty\\) e dizemos que \\(i\\) é recorrente nulo se \\(\\mu_{ii}=\\infty\\).\n\n\n\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 4.8 Recorrência positiva(nula) são propriedades de classe.\nDemonstração: Considere uma classe recorrente contendo os estados \\(i\\) e \\(j\\). Se \\(i\\) é recorrente positivo, então o processo consegue se deslocar de \\(i\\) para \\(j\\) e depois voltar para \\(i\\) em um tempo finito. Isto implica que o processo consegue sair de \\(j\\), chegar em \\(i\\) e voltar para \\(j\\) em um tempo finito. Assim, \\(j\\) deve ser recorrente positivo e, recorrência positiva é propriedade de classe.\nAgora, se um dos estados de uma classe for recorrente nulo, os outros não podem ser recorrentes positivos, pelo resultado acima. Logo, recorrência nula também é propriedade de classe.\n\n\n\nO próximo resultado será útil mais adiante.\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 4.9 Uma CMTD irredutível finita (ou seja, com espaço dos estados finito) é recorrente positiva.\nDemonstração: Em uma cadeia irredutível todos os estados se comunicam. Suponha por absurdo que a cadeia é transiente. Então, todos os estados deveriam ser visitados um número finito de vezes. Isso é absurdo pois, como existe um número finito de estados, o processo sempre deve revisitar algum estado. Assim, toda CMTD irredutível e finita é recorrente.\nAgora, suponha por absurdo que \\(j\\) é recorrente nulo. Isto implica que a cadeia gasta pouco tempo neste estado. Mas essa afirmativa deveria ser verdadeira para todos os estados. Assim, saindo de \\(j\\), cada estado só poderia ser visitado poucas vezes. Como a cadeia é finita, o processo será obrigado a revisitar um dos estados em um tempo finito, fazendo com que esse estado seja recorrente positivo, e implicando que \\(j\\) deveria ser recorrente positivo, gerando um absurdo. Portanto, o estado \\(j\\) deve ser recorrente positivo.\n\n\n\n\n\n4.5.3 Periodicidade de um Estado\nAlguns estados em uma CM possuem a propriedade de só poderem ser atingidos em tempos distintos. Tais estados são ditos periódicos. Por exemplo, considere o grafo a seguir:\n\n\n\n\n\n\n\n\n\nSe o processo estiver em 0 no tempo \\(0\\), ele estará de volta ao estado 0 apenas nos tempos \\(4,8,12,\\ldots\\), que são múltiplos de 4. Cadeias que possuem esse tipo de regularidade são denominadas periódicas.\n\n\n\n\n\n\nDefinição: Estado periódico\n\n\n\n\nDefinição 4.8 O estado \\(i\\) de uma Cadeia de Markov é dito ser periódico se todos os retornos ao estado \\(i\\) ocorrem em um número de passos múltiplo de \\(k\\) (neste caso, é dito que o período de \\(i\\) é igual a \\(k\\)).\nFormalmente, seja \\(D_i=\\{n\\geq 1 : p_{ii}^{(n)}>0\\}\\), ou seja, o conjunto com os números de passos necessários para o retorno ao estado e seja \\(k\\) o máximo divisor comum (mdc) de \\(D_i\\). Então \\(k\\) é denominado período do estado \\(i\\). Notação: \\(d(i)=k\\).\n\n\n\nVoltando ao exemplo acima, pode-se notar que \\[D_0=\\{4n,n=1,2,\\ldots\\},\\] logo \\(d(0)=4\\).\nSejam \\(mdc(a,b)\\) o máximo divisor comum entre \\(a\\) e \\(b\\). É importante recordar alguns fatos:\n\nTodo número pode ser decomposto em fatores primos.\nSejam \\(a\\) e \\(b\\) dois números e sejam \\(a=p\\times p_a\\) e \\(b=p\\times p_b\\) suas respectivas decomposições em fatores primos, onde \\(p\\) é comum para ambos. Então o \\(mdc(a,b)=p\\).\nSejam \\(n_1\\) e \\(n_2\\) inteiros positivos e seja \\(c=n_1a+n_2b\\). Se \\(mdc(a,b)=p\\), então o \\(mcd(a,b,c)=p\\).\n\nÉ importante separar a noção de período com o número de passos necessários para retornar ao estado. Se um estado possui período \\(d\\), então o processo só retornará ao estado em passos múltiplos de \\(d\\), mas não em todos os passos múltiplos de \\(d\\). O exemplo abaixo ilustra esse fato.\n\n\n\n\n\n\nExemplo: Relação entre período e passos\n\n\n\n\nExemplo 4.14 É possível que uma CMTD tenha estados com período \\(d\\) que não podem ser atingidos em \\(d\\) passos (ou seja, com \\(p_{ii}^{(d)}=0\\)). Considere a CMDT abaixo:\n\n\n\n\n\n\n\n\n\nNo grafo acima, pode-se perceber que, saindo de 0, o processo só retorna por dois caminhos: de \\(\\{0,1,2,3,4,5,6,7,0\\}\\) ou \\(\\{0,1,2,3,4,5,0\\}\\). Neste caso, é possível voltar em um número de passos múltiplo de 6, de 8 e de combinações destes dois (por exemplo, é possível volar em 14 passos, fazendo o caminho completo de seis passos e depois fazendo o caminho de 8 passos). Entretanto, como todos esses caminhos são combinações de \\(6\\) e \\(8\\), precisamos apenas encontrar o \\(mdc\\) destes dois. Assim, o período de 0 é \\(d(0)=2\\). Entretanto, note que \\(p_{ii}^{(2)}\\) é igual a zero.\n\n\n\n\n\n\n\n\n\nExemplo\n\n\n\n\nExemplo 4.15 Considere a seguinte matriz de transição:\n\\[\\begin{align}{\\bf P}=\\left(\\begin{array}{cc} 0 & 1 \\\\ 1 & 0\\end{array}\\right)\\end{align}\\]\nNote que não podemos voltar para nenhum dos dois estados em um passo, mas\n\\[\\begin{align}{\\bf P}^2=\\left(\\begin{array}{cc} 1 & 0 \\\\ 0 & 1\\end{array}\\right),\\end{align}\\]\nlogo, o processo pode retornar para qualquer um dos estados em dois passos. É fácil notar que, \\({\\bf P}^{2n}={\\bf I}\\) para \\(n=1,2,\\ldots\\). Assim, para o estado \\(0\\) ou \\(1\\) teremos \\(D=\\{2,4,6,\\ldots\\}\\). Como o máximo denominador comum de \\(D_i\\) é 2, teremos que o período dos estados \\(0\\) e \\(1\\) é igual a 2.\n\n\n\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 4.9 Para um estado \\(i\\) qualquer, se \\(D_i=\\varnothing\\), é definido que \\(d(i)=0\\). Se \\(D_i\\) não for vazio, então \\(d(i)\\) será pelo menos 1. Em particular, se \\(d(i)=1\\), é dito que \\(i\\) é aperiódico.\n\n\n\n\n\n\n\n\n\nExemplo \\(d(i)=0\\) e \\(d(j)=1\\)\n\n\n\n\nExemplo 4.16 Considere a CMDT abaixo\n\n\n\n\n\n\n\n\n\nComeçando em 0, o processo nunca mais retorna a este estado, fazendo com que \\(D_0=\\varnothing\\) e \\(d(0)=0\\). Como o estado 1 pode retorna para ele mesmo em um passo, temos que \\(d(1)=1\\). Além disso, para o estado 2 temos \\(D=\\{2,3,4,\\ldots,\\}\\) fazendo com que \\(d(2)=1\\).\n\n\n\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 4.10 Seja \\(C\\) uma classe de estados. Se \\(i\\in C\\) e \\(d(i)=d\\), então todo estado em \\(C\\) terá período igual a \\(d\\).\nDemonstração: Como \\(i\\) e \\(j\\) se comunicam, existem \\(n_1\\) e \\(n_2\\) tais que \\(p_{ij}^{(n_1)}>0\\) e \\(p_{ji}^{(n_2)}>0\\). Assim, temos que \\[p_{ii}^{(n_1+n_2)}=\\sum_{s=0}^{\\infty}p_{is}^{(n_1)}p_{si}^{(n_2)}\\geq p_{ij}^{(n_1)}p_{ji}^{(n_2)}>0.\\] Portanto, \\(n_1+n_2\\in D_i\\), o que equivale a dizer que existe \\(a\\) inteiro positivo tal que \\(n_1+n_2=a\\times d(i)\\). Agora, note que \\[\\begin{align*}\np_{ii}^{(n_1+n_2+d(j))}&=\\sum_{s=0}^{\\infty}p_{is}^{(n_1)}p_{si}^{(n_2)}\\geq\np_{ij}^{(n_1)}p_{ji}^{(n_2+d(j))}\\\\\n&=p_{ij}^{(n_1)}\\sum_{s=0}^{\\infty}p_{js}^{(d(j))}p_{si}^{(n_2)}\\geq\np_{ij}^{(n_1)}p_{jj}^{(d(j))}p_{ji}^{(n_2)}>0.\n\\end{align*}\\] Portanto, \\(d(j)+n_1+n_2\\in D_i\\) e existe \\(b\\) inteiro positivo tal que \\(n_1+n_2+d(j)=b\\times d(i)\\). Portanto, \\[(n_1+n_2)+d(j)=b\\times d(i)\\Rightarrow a\\times d(i)+d(j)=b\\times d(i)\\Rightarrow a+\\frac{d(j)}{d(i)}=b.\\] Portanto, \\(d(j)\\) é divisível por \\(d(i)\\). Entretanto, trocando os estados \\(i\\) e \\(j\\) no desenvolvimento acima, pode-se concluir que \\(d(i)\\) é divisível por \\(d(j)\\). Isto implica que \\(d(i)=d(j)\\).\n\n\n\nPor último, temos a seguinte definição.\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 4.10 Um estado recorrente positivo e aperiódico é denominado ergódico. Por consequência, a classe desse estado é também denominada ergódica."
  },
  {
    "objectID": "cap_4_cmtd.html#sec-4.6",
    "href": "cap_4_cmtd.html#sec-4.6",
    "title": "4  Cadeias de Markov a Tempo Discreto",
    "section": "4.6 Distribuição Estacionária",
    "text": "4.6 Distribuição Estacionária\nConsidere o problema de determinar a probabilidade do processo estar em um estado \\(j\\) em particular. Conhecendo a matriz de transição e a probabilidade do estado no instante 0, para qualquer tem-se que \\(n\\), \\[P(X_n=j)=\\sum_{j=0}^{\\infty}P(X_{n}=j|X_0=i)P(X_0=i)=\\sum_{j=0}^{\\infty}p_{ij}^{n}P(X_0=i).\\] A probabilidade \\(P(X_n=j)\\) depende do valor de \\(n\\). Entretanto, se voltarmos ao Exemplo 4.10, podemos conjecturar que \\(p_{ij}^{(n)}\\) se aproxima de uma constante com o aumento de \\(n\\), fazendo com que \\(P(X_n=j)\\) também se torne constante. Com isso, considere a seguinte definição.\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 4.11 Seja \\(\\{X_n, n=0,1,\\ldots,\\}\\) uma CMTD, com o espaço dos estados igual a \\(\\mathbb{N}\\). Seja \\(\\pi_j,\\quad j=0,1,\\ldots\\) a probabilidade do processo estar no estado \\(j\\). Dizemos que \\(\\bf{\\pi}=\\{\\pi_0,\\pi_1,\\ldots\\}\\) é uma distribuição estacionária se\n\\[\\pi_j = \\sum_{i=0}^{\\infty}P(X_{m+n}=j|X_{n}=i)\\pi_i\\]\npara todo \\(j\\) e \\(m,n\\geq 0\\).\nSe um processo possui distribuição estacionária, então a probabilidade \\(P(X_n=j)=\\pi_j\\) é constante em relação a \\(n\\). De fato, temos que\n\\[\\begin{align}\nP(X_1=j)&=\\sum_{k=0}^{\\infty}P(X_1=j|X_0=k)P(X_0=k)=\\sum_{k=0}^{\\infty}\\textcolor{blue}{p_{kj}}\\pi_k =\\pi_j\n\\end{align}\\] e, por indução,\n\\[\\begin{align}\nP(X_n=j)&=\\sum_{k=0}^{\\infty}P(X_n=j|X_{n-1}=k)P(X_{n-1}=k)=\\sum_{k=0}^{\\infty}\\textcolor{blue}{p_{kj}}\\pi_k =\\pi_j.\n\\end{align}\\]\nEntretanto, uma CMTD não necessariamente possui distribuição estacionária. Por exemplo, considere a cadeia abaixo:\n\n\n\n\n\n\n\n\n\nSeja \\(\\pi_0=P(X_0=0)>0\\) (ou seja, a probabilidade do processo começar em zero). Note que \\[P(X_1=0)=\\sum_{j=0}^{2}p_{j0}\\pi_0=0\\neq\\pi_0,\\] logo esta cadeia não tem distribuição estacionária.\nComo já mencionado, em certas condições existe o limite \\[\\pi_j=\\lim_{n\\rightarrow\\infty}p_{ij}^{(n)},\\] independente do valor de \\(i\\). Sendo o limite acima verdadeiro para certa cadeia, teremos que \\[\\begin{align*}\n\\lim_{n\\rightarrow\\infty}P(X_n=j)&=\\lim_{n\\rightarrow\\infty}\\sum_{k=0}^{\\infty}p_{kj}^{(n)}P(X_{0}=k)\\\\\n&=\\sum_{k=0}^{\\infty}\\left[\\lim_{n\\rightarrow\\infty}p_{kj}^{(n)}\\right]P(X_{0}=k)\\\\\n&=\\pi_j\\sum_{k=0}^{\\infty}P(X_0=k)=\\pi_j,\n\\end{align*}\\] e, portanto, \\(\\pi\\) será a distribuição estacionária da cadeia. Tais probabilidades são muitas vezes é interpretadas como a proporção do tempo que o processo gasta no estado.\nNo que segue são discutidas em quais situações uma CMTD possui distribuição estacionária.\n\n\n\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 4.11 Cadeias irredutíveis transientes não possuem distribuição estacionária.\nDemonstração: Em cadeias transientes, todos os estados são visitados um número finito de vezes, logo \\(\\lim_{n\\rightarrow\\infty}p_{ij}^{(n)}=0\\) para quaisquer \\(i\\) e \\(j\\). Neste caso, teremos \\(\\pi_j=0\\) para todo \\(j\\).\n\n\n\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 4.12 Cadeias irredutíveis recorrente nulas não possuem distribuição estacionária.\nDemonstração: Em uma cadeia recorrente nula, é esperado que qualquer estado não seja revisitado em um tempo finito. Com isso, para qualquer \\(n\\) suficientemente grande e finito, o estado foi revisitado apenas um número finito de vezes e seu comportamento é análogo a uma cadeia transiente e teremos \\(\\pi_j=0\\) para todo \\(j\\).\n\n\n\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 4.13 Cadeias recorrente positivas com período maior que um não possuem distribuição estacionária.\nDemonstração: Se existe \\(\\lim_{n\\rightarrow\\infty}p_{ij}^{(n)}=\\pi_j\\), então a sequência \\(p_{ij}^{(1)},p_{ij}^{(2)},\\ldots\\) é convergente. Disto, qualquer subsequência infinita desta sequência deveria ser convergente. Isto não ocorre se houver um período maior que 1, pois haverá uma subsequência identicamente nula e outra estritamente positiva. Assim, apenas cadeias aperiódicas podem ter distribuição estacionária.\nPortanto, apenas cadeias ergódicas possuem distribuição estacionária. Considerando essas restrições verdadeiras, vamos provar a existência da distribuição estacionária, caracterizá-la e demonstrar sua unicidade.\n\n\n\n\n\n\n\n\n\nTeorema\n\n\n\n\nTeorema 4.1 Uma cadeia irredutível ergódica possui distribuição estacionária. Além disso, essa distribuição é única e é dada por \\[\\begin{equation}\n\\pi_j = \\lim_{n\\rightarrow\\infty}p_{ij}^{(n)}.\n\\end{equation}\\]\nDemonstração: Pelas equações de Chapman-Kolmogorov, teremos que \\[p_{ij}^{(n+1)}=\\sum_{k=0}^{\\infty}p_{ik}^{(n)}p_{kj}.\\] Como \\(\\pi_j =\\lim_{n\\rightarrow\\infty}p_{ij}^{(n)}\\), teremos que \\[\\lim_{n\\rightarrow \\infty}p_{ij}^{(n+1)}=\\sum_{k=0}^{\\infty}\\lim_{n\\rightarrow\\infty}p_{ik}^{(n)}p_{kj}\\Rightarrow \\pi_j=\\sum_{k=0}^{\\infty}\\pi_kp_{kj},\\] logo, \\(\\pi_j\\) é estacionária. Agora, seja \\(\\delta_0,\\delta_1,\\ldots\\) outra distribuição estacionária. Então, é verdade que \\[\\delta_j=\\sum_{k=0}^{\\infty}p_{kj}^{(n)}\\delta_k.\\] Além disso, temos que \\[\\begin{align*}\n\\lim_{n\\rightarrow \\infty} \\delta_j=\\sum_{k=0}^{\\infty}\\lim_{n\\rightarrow\\infty}p_{kj}^{(n)}\\delta_k\\Rightarrow \\delta_j =\\sum_{k=0}^\\infty \\pi_j\\delta_k = \\pi_j,\n\\end{align*}\\] logo, \\(\\delta_j=\\pi_j\\) e a distribuição estacionária é única.\n\n\n\n\n\n\n\n\n\nCorolário\n\n\n\n\nCorolário 4.4 Se existe distribuição estacionária, esta é calculada como solução do sistema \\[ \\mathcal{\\pi}= \\mathcal{\\pi}{\\bf P},\\] com a restrição de que \\(\\sum_{j}\\pi_j=1\\).\n\n\n\n\n\n\n\n\n\nExemplo: Chuva - conclusão\n\n\n\n\nExemplo 4.17 Vamos concluir o Exemplo 4.11. O processo considerado é \\(\\{X_n,n=0,1,\\ldots\\}\\), sendo que \\(X_{n}=I({\\text{Chove no dia n}})\\), com a seguinte matriz de transição\n\n\n\n\n\n\n\n\n\nEsta cadeia é irredutível, finita e aperiódica, logo ela é ergódica. A sua distribuição estacionária será dada por\n\\[\\left(\\pi_0,\\pi_1\\right)=\\left(\\pi_0,\\pi_1\\right)\\left(\\begin{array}{rccc}\n.25 & .75 \\\\\n.4 & .6\\\\\n\\end{array}\\right).\\]\nO sistema resultante é\n\\[\\begin{align}\\left\\{\\begin{array}{l}\\\n\\pi_0=\\frac{1}{4}\\pi_0+\\frac{2}{5}\\pi_1\\\\\n\\pi_1=\\frac{3}{4}\\pi_0+\\frac{3}{5}\\pi_1\\\\\n\\pi_0+\\pi_1=1.\n\\end{array}\\right.\n\\end{align}\\]\nNote que a terceira restrição é necessária, pois a primeira linha é linearmente dependente da segunda. Resolvendo o sistema, teremos \\(\\bf{π}\\) \\(= (8/23,15/23)\\) (compare estes valores com aqueles obtidos no o Exemplo 4.11). Assim, a proporção do tempo em que chove é de \\(\\approx 65,22\\% (15/23)\\)."
  },
  {
    "objectID": "cap_4_cmtd.html#processo-de-ramificação",
    "href": "cap_4_cmtd.html#processo-de-ramificação",
    "title": "4  Cadeias de Markov a Tempo Discreto",
    "section": "4.7 Processo de Ramificação",
    "text": "4.7 Processo de Ramificação\nO seguinte problema foi proposto por Galton, no fim do século 19. Considere que todo filho recebe o nome do pai. Considere ainda que a distribuição do número de filhos de um indivíduo não se altere ao longo dos anos. Qual é a probabilidade de que um sobrenome seja extinto? Este tipo de problema gera uma cadeia de Markov denominada processo de ramificação.\nSeja \\(Z_i\\) o número de descendentes do \\(i\\)-ésimo indivíduo, com \\(E(Z)=\\mu\\) e \\(Var(Z)=\\sigma^2<\\infty\\). Consideremos que os indivíduos geram sua descendência independente dos demais com igual distribuição. Seja \\(X_n\\) o número de indivíduos na \\(n\\)-ésima geração. Considere que, no tempo inicial, havia apenas um indivíduo (\\(X_0=1\\)). Então \\(X_1\\), o número de indivíduos na primeira geração, é igual ao número de descendentes na primeira geração (no caso \\(X_1=Z_1\\)). O número de indivíduos na segunda geração (\\(X_2\\)) dependerá do número de indivíduos da primeira geração, e assim sucessivamente, criando\n\\[\\begin{equation}\nX_n=\\sum_{i=1}^{X_{n-1}}Z_i.\n\\end{equation}\\] Claramente, \\(\\{X_n,n=0,1,2,\\ldots\\}\\) é uma cadeia de Markov. Desde que \\(P(Z_1\\leq 0)\\), existe a possibilidade de que uma dada geração seja nula. Se isto ocorrer, teremos a extinção desta população, o que implica em dizer que o estado 0 é absorvente. Como sempre há a possibilidade de o processo entrar no estado zero, teremos que todos os outros estados devem ser transientes.\nEmbora a distribuição de \\(X_n\\) possa ser complicada, podemos obter sua média e variância.\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 4.14 Temos que \\[\\begin{equation}E(X_n)=\\mu^n\n\\end{equation}\\] e que \\[\\begin{align}Var(X_n)=\\left\\{\\begin{array}{ll}\\sigma^2\\mu^{n-1}\\frac{1-\\mu^{n-1}}{1-\\mu} &,\\mu\\neq 1 \\\\ n\\sigma^2 &\\mu=1 \\\\ \\end{array} \\right.\n\\end{align}\\]\n\n\n\n\\[\\begin{align*}\nE(X_n)&=E\\left(\\sum_{i=1}^{X_{n-1}Z_i}\\right)=E\\left.\\left(E\\left(\\sum_{i=1}^{X_{n-1}}Z_i\\right|X_{n-1}\\right)\\right)=\nE\\left.\\left(\\sum_{i=1}^{X_{n-1}}E\\left(Z_1\\right|X_{n-1}\\right)\\right)\\\\\n&=E\\left(X_{n-1}E(Z_1)\\right)=E\\left(X_{n-1}\\mu\\right)=\\mu E(X_{n-1}).\n\\end{align*}\\] Utilizando o fato de que \\(X_0=1\\), temos que \\(E(X_1)=\\mu E(X_0)=\\mu\\) e que \\(E(X_2)=\\mu E(X_1)=\\mu^2\\). Uma simples indução sobre \\(n\\) mostra que \\(E(X_n)=\\mu^n\\).\nConsidere a amostra de estados \\(X_0,X_1,\\ldots,X_n\\). Assuma que a cadeia possui um número \\(k+1\\)(finito) de estados e seja\n\\[{\\bf P}=\\left(\\begin{array}{ccc}\n      \\theta_{00} & \\cdots & \\theta_{0k} \\\\\n      \\vdots & \\vdots & \\vdots \\\\\n      \\theta_{k0} & \\cdots & \\theta_{kk}\\\\\n      \\end{array}      \n      \\ \\right),\\]\nsua matriz de transição. Vamos estimar \\(\\theta_{ij}\\) via o método da máxima verossimilhança. A função de verossimilhança será dada por \\[\\begin{align}\nL({\\bf P})&= P(X_0=x_0|{\\bf P})\\prod_{l=1}^{k}P(X_l=x_l|X_{l-1}=x_{l-1},{\\bf P})\\\\ &=P(X_0=x_0|{\\bf P})\\prod_{i=0}^k\\prod_{j=0}^{k}\\theta_{ij}^{n_{ij}},\n\\end{align}\\] onde \\(n_{ij}\\) é o número de vezes que o processo realizou uma transição do estado \\(i\\) para o estado \\(j\\). Aplicando o logaritmo na equação acima teremos \\[\\begin{align}\nl({\\bf P})&=\\log L({\\bf P})=\\log P(X_0=x_0|{\\bf P}) + \\sum_{i=0}^{k}\\sum_{j=0}^{k}n_{ij}\\log \\theta_{ij}\\\\\n&\\approx \\sum_{i=0}^{k}\\sum_{j=0}^{k}n_{ij}\\log \\theta_{ij}\n\\end{align}\\]\nonde o termo \\(\\log P(X_1=x_1|{\\bf P})\\) pode ser negligenciado, desde que o tamanho da amostra seja razoavelmente grande. Lembrando que \\(\\sum_{j=0}^{k}\\theta_{ij}=1\\), façamos \\(\\theta_{ik}=1-\\theta_{i0}-\\cdots \\theta_{i,k-1}\\). Notando que, para \\(j=0,\\ldots,k-1\\), \\[\\begin{align}\n\\frac{\\partial}{\\partial\\theta_{ij}}l({\\bf P})=0\\Rightarrow \\frac{n_{ij}}{\\theta_{ij}} -\\frac{n_{ik}}{1-\\sum_{l=0}^{k-1}\\theta_{il}}=0,\n\\end{align}\\] teremos que \\[\\begin{align*}\n\\frac{n_{ij}}{\\theta_{ij}}=\\frac{n_{ik}}{1-\\sum_{l=0}^{k-1}\\theta_{il}} &\\Rightarrow n_{ij}(1-\\sum_{l=0}^{k-1}\\theta_{il})=n_{ik}\\theta_{ij}\\\\\n&\\Rightarrow \\sum_{j=0}^{k}n_{ij}(1-\\sum_{l=0}^{k-1}\\theta_{il})=n_{ik}\\sum_{j=0}^{k}\\theta_{ij}\\\\\n&\\Rightarrow 1-\\sum_{l=0}^{k-1}=\\frac{n_{ik}}{n_i},\n\\end{align*}\\] onde \\(n_i = \\sum_{j=0}^{k}n_{ij}\\) é o número de vezes que o estado \\(i\\) apareceu na amostra."
  },
  {
    "objectID": "cap_4_cmtd.html#cadeias-de-ordens-maiores",
    "href": "cap_4_cmtd.html#cadeias-de-ordens-maiores",
    "title": "4  Cadeias de Markov a Tempo Discreto",
    "section": "4.8 Cadeias de Ordens Maiores",
    "text": "4.8 Cadeias de Ordens Maiores\n\n4.8.1 Transformação para uma CMTD de ordem 1\n\n\n4.8.2 O Modelo de Rafttery"
  },
  {
    "objectID": "cap_4_cmtd.html#exercícios",
    "href": "cap_4_cmtd.html#exercícios",
    "title": "4  Cadeias de Markov a Tempo Discreto",
    "section": "4.9 Exercícios",
    "text": "4.9 Exercícios\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.1 Suponha que a moeda 1 tem probabilidade 0,7 de dar cara e a moeda 2 tem 0,6. Se a moeda lançada hoje der cara, amanhã jogaremos a moeda 1. Em caso contrário jogaremos a moeda 2. Se a moeda lançada inicialmente tem a mesma chance de ser a 1 ou a 2, qual a probabilidade da moeda lançada no terceiro dia ser a 1?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.2 Três bolas brancas e três bolas pretas são distribuídas em duas urnas de modo que cada uma contenha três bolas. Dizemos que o sistema está em \\(i\\) se a primeira urna contém \\(i\\) bolas brancas. A cada passo retiramos uma bola de cada urna. A bola retirada da primeira urna é recolocada na segunda e a que foi retirada da segunda é recolocada na primeira. Seja \\(X_n\\) o estado do sistema em \\(n\\) passos. Explique porque \\(\\{ X_n, n = 0,1,2,\\ldots\\}\\) é uma cadeia de Markov e encontre a sua matriz de transição.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.3 Determine a matriz de transição \\({\\bf P}\\) para as seguintes cadeias:\n\nConsidere uma sequência de lançamentos de uma moeda com probabilidade \\(p\\) de sair cara. Após \\(n\\) lançamentos o estado do processo é o número de caras em \\(n\\) lançamentos menos o número de coroas.\n\\(N\\) bolas pretas e \\(N\\) bolas brancas são colocadas em duas urnas, cada uma com \\(N\\) bolas. A cada passo uma bola e selecionada de cada urna e trocada de lugar. O estado do sistema é o número de bolas brancas na primeira urna.\nUm rato branco é colocado no labirinto abaixo. O rato se move através dos compartimentos ao acaso, ou seja, se existem \\(k\\) compartimentos vzsinhos ao que ele está, então ele irá para qualquer um deles com probabilidade \\(1/k\\). Em cada instante de tempo ele muda de compartimento. O estado do sistema é o número do compartimento em que o rato está.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.4 \n\nConsidere duas urnas \\(A\\) e \\(B\\) contendo \\(N\\) bolas no total. Um experimento é realizado no qual um bola é selecionada ao acaso no tempo \\(n (n=1,2,3,\\ldots)\\) entre as \\(N\\) bolas. Então uma urna é selecionada aleatoriamente (a probabilidade de escolher a urna \\(A\\) é \\(p\\)) e a bola selecionada é colocada nesta urna. O estado do sistema em cada instante de tempo é o número de bolas na urna \\(A\\). Determine a matriz de transição desta CM.\nAssuma que no tempo \\(t\\) existem exatamente \\(k\\) bolas em \\(A\\). No tempo \\(t+1\\) uma urna é selecionada com probabilidade igual á proporção de seu conteúdo (por exemplo, a urna \\(A\\) é selecionada com probabilidade \\(k/N\\)). Então uma bola é selecionada de \\(A\\) com probabilidade \\(p\\) ou de \\(B\\) com probabilidade \\(1-p\\) e colocada na urna selecionada anteriormente. Determine a matriz de transição desta CM.\nAgora assuma que no tempo \\(t+1\\) uma bola e uma urna são selecionados com probabilidade proporcional ao conteúdo da urna (uma bola da urna \\(A\\) é selecionada com probabilidade \\(k/N\\) e a urna \\(A\\) é selecionada com probabilidade \\(k/n\\)). Determine a matriz de transição da CM com estados representados pelo conteúdo de \\(A\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.5 Encontre a distribuição estacionária da cadeia de Markov com a seguinte matriz de transição: \\[\\begin{align*}\n   \\left(\\begin{array}{cc} p & 1-p \\\\ 1-p & p \\\\\\end{array}\\right).\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.6 Seja \\(\\{X_n,n=0,1,2,\\ldots\\}\\) uma cadeia de Markov com espaço dos estados \\(\\{0,1\\}\\), \\(P(X_n=0|X_{n-1}=0)=0,3=P(X_n=1|X_{n-1}=1)\\). Se \\(X_n=1\\), um jogador ganha um real. Em caso contrário, o jogador ganha dois reais. Seja \\(Y_n\\) a quantidade de dinheiro que o jogador ganhou {} \\(n\\) (ou seja, um ou dois reais). Para \\(n\\) suficientemente grande, calcule \\(E(Y_n)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.7 Mostre que uma cadeia irredutível finita com \\(p_{ii}>0\\) possui distribuição estacionária.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.8 Certo evento ocorre segundo um processo de Poisson com taxa um por hora. Em cada hora, verificamos se ocorreu pelo menos um evento deste tipo e, em caso afirmativo, colocamos uma bola dentro de uma urna. Seja \\(Y_n\\) o número de bolas na urna na \\(n\\)-ésima hora. Mostre que \\(Y_n\\) é uma cadeia de Markov e construa a sua matriz de transição. Encontre suas classes e classifique-as. Existe distribuição estacionária para esta cadeia? Se existir, encontre-a. Se não existir, justifique.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.9 Determine as classes e a periodicidade dos estados das CM com as seguintes matrizes de transição:\n\n\n\n\\[\n\\begin{align*}\\left(\n  \\begin{array}{cccc}\n    0 & 0 & 1 & 0 \\\\\n    1 & 0 & 0 & 0 \\\\\n    1/2&1/2&0 & 0 \\\\\n    1/3&1/3&1/3&0\n  \\end{array}\\right)\\end{align*}\\]\n\n\n\n\\[\n\\begin{align*}\\left(\n  \\begin{array}{cccc}\n    0 & 1 & 0 & 0 \\\\\n    0 & 0 & 0 & 1 \\\\\n    0 & 1 & 0 & 0 \\\\\n    1/3&0 &2/3&0\n\\end{array}\\right)\\end{align*}  \n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.10 Adapte o exemplo da fila discreta para o caso em que \\(2\\) clientes são atendidos ao mesmo tempo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.11 Encontre as classes a seguinte CMTD, classifique-as como recorrentes ou transientes e encontre seus períodos.\n\\[\n\\left(\\begin{array}{ccccccc}\n0 & 1/3 & 2/3 & 0 & 0 & 0 & 0 \\\\\n1 &  0  & 0   & 0 & 0 & 0 & 0 \\\\\n0 &  0  & 4/5   & 1/5 & 0 & 0 & 0 \\\\\n0 &  0  & 1/6   & 0   & 2/6 & 3/6 & 0 \\\\\n0 &  0  & 0   & 0 & 0 & 0 & 1 \\\\\n0 &  0  & 0   & 0 & 0 & 1 & 0 \\\\\n0 &  0  & 0   & 0 & 1/2 & 0 & 1/2 \\\\\n\\end{array}\\right)\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.12 Uma matriz estocástica (quadrada) é uma matriz \\({\\bf A}=\\{a_{ij}\\}\\), onde \\(\\sum_{j}a_{ij}=1\\) e \\(0,\\leq a_{ij}\\leq 1\\). Qualquer matriz estocástica é uma matriz de transição. Entretanto, não necessariamente uma matriz estocástica será uma matriz de transição em dois passos. Em particular, mostre que uma matriz estocástica \\(2\\times 2\\) será uma matriz de transição em dois passos se e somente se a soma dos elementos se sua diagonal principal for maior ou igual a 1.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.13 Considere uma CM com \\(r\\) estados. Prove que:\n\nSe um estado \\(k\\) é acessível a partir de \\(j\\), então ele pode ser atingido em \\(r-1\\) passos ou menos.\nSe \\(j\\) é um estado recorrente, então existe \\(\\alpha\\in(0,1)\\) tal que para \\(nr\\) a probabilidade de que o primeiro retorno ao estado \\(j\\) ocorra após \\(n\\) transições é \\(\\leq \\alpha^n\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.14 Seja \\[\\begin{align*}\n{\\bf P}=\\left(\\begin{array}{cc} 1-a & a \\\\ b & 1-b\\end{array}\\right),\\quad a>0,\\quad b<1.\n\\end{align*}\\] Prove que \\[\\begin{align*}\n{\\bf P}^n=\\frac{1}{a+b}\\left(\\begin{array}{cc} b & a \\\\ b & a\\end{array}\\right)+\n\\frac{(1-a-b)^n}{a+b}\\left(\\begin{array}{cc} a & -a \\\\ -b & b\\end{array}\\right)\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.15 Uma pessoa com uma doença contagiosa entra em uma população. Durante cada instante de tempo, ou ele infecta outra pessoa com probabilidade \\(p\\), ou seus sintomas aparecem e ele é descoberto pela vigilância sanitária com probabilidade \\(1-p\\). Encontre a distribuição de probabilidade do número de pessoas infectadas e sem sintomas na população após a descoberta do primeiro portador. Assuma que a doença se comporta da mesma forma em todas as pessoas.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.16 Uma CM possui a seguinte matriz de transição: \\[\\begin{align*}\n{\\bf P}=\\left(\n\\begin{array}{ccc}0,7 & 0,2 & 0,1 \\\\ 0 & 0,6 & 0,4 \\\\ 0,5 & 0 & 0,5 \\end{array}\\right).\n\\end{align*}\\] Determine as distribuições limites.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.17 Uma CM, com estados \\(\\{0,1,2\\}\\), possui a seguinte matriz de transição: \\[\\begin{align*}\n{\\bf P}=\\left(\n\\begin{array}{ccc}0,1 & 0,1 & 0,8 \\\\ 0,2 & 0,2 & 0,6 \\\\ 0,3 & 0,3 & 0,4 \\end{array}\\right).\n\\end{align*}\\] Assintoticamente, qual a proporção do tempo que o processo gasta no estado 1?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.18 Uma CM, com estados \\(\\{0,1,2\\}\\), possui a seguinte matriz de transição: \\[\\begin{align*}\n{\\bf P}=\\left(\n\\begin{array}{ccc}0,3 & 0,2 & 0,5 \\\\ 0,5 & 0,1 & 0,4 \\\\ 0,5 & 0,2 & 0,3 \\end{array}\\right).\n\\end{align*}\\]\nCada tempo que o processo gasta no estado um gera um custo de \\(R 2\\). Cada tempo que o processo gasta no estado dois gera um custo de \\(R 5\\). Cada tempo que o processo gasta no estado três gera um custo de \\(R 3\\). Assintoticamente, qual o custo esperado por essa CM?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.19 Um ônibus opera em uma rota contínua com paradas intermediárias. A chegada do ônibus em uma parada é classificada em uma das três classes:\n\nAdiantado\nPontual\nAtrasado\n\nSuponha que a sucessão desses estados é proveniente de uma CM com matriz de transição: \\[\\begin{align*}\n{\\bf P}=\\left(\n\\begin{array}{ccc}0,5 & 0,4 & 0,1 \\\\ 0,2 & 0,5 & 0,3 \\\\ 0,1 & 0,2 & 0,7 \\end{array}\\right).\n\\end{align*}\\] Encontre a distribuição estacionária desta cadeia. Qual é a probabilidade de que, em longo prazo, o ônibus esteja atrasado?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.20 Considere duas bolas brancas e duas pretas. Essas quatro bolas estão distribuídas em duas urnas. Cada urna contém duas bolas e, a cada minuto, uma bola é retirada da urna 1, outra da urna 2. Em seguida, a bola retirada da urna \\(i\\) é colocada na urna \\(j\\), com \\(i,j=\\{1,2\\}\\). Seja \\(\\{X_{n},n=0,1,\\ldots\\}\\) o número de bolas brancas na urna 1 no \\(n\\)-ésimo minuto.\n\nDiscuta porquê o processo \\(\\{X_n,n=0,1,\\ldots\\}\\) é uma CMTD.\nEncontre as classes desta cadeia e classifique-as como recorrentes e transientes.\nVerifique se existe distribuição estacionária para esta CMTD. Em caso afirmativo, encontre-a.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 4.21 O consumo energético de uma casa pode ser classificado como A, B ou C. Foi constatado que a classificação mensal desta casa é uma CMTD com a seguinte matriz de transição\n\n\n\n\nA\nB\nC\n\n\n\n\nA\n1/3\n2/3\n0\n\n\nB\n1/3\n1/3\n1/3\n\n\nC\n1/3\n0\n2/3\n\n\n\nMostre que esta cadeia satisfaz as condições necessárias para a existência da distribuição estacionária e calcule-a."
  },
  {
    "objectID": "cap_5_cmtc.html#definição-e-exemplos",
    "href": "cap_5_cmtc.html#definição-e-exemplos",
    "title": "5  Cadeias de Markov a Tempo Contínuo",
    "section": "5.1 Definição e Exemplos",
    "text": "5.1 Definição e Exemplos\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 5.1 Seja \\(\\{X(t),t\\geq 0\\}\\) um processo estocástico com espaço do tempo igual a \\([0,\\infty)\\) e espaço dos estados \\(D\\subseteq\\mathbb{Z}\\). Esse processo será uma cadeia de Markov a tempo contínuo (CMTC) se para todo \\(s,t\\geq 0\\) e para os inteiros \\(i,j\\) e \\(x(u)\\), com \\(0\\leq u<s\\),\n\\[\\begin{align}\nP(X(t+s)=j|X(s)=i,X(u)=x(u), 0\\leq u<s)=P(X(t+s)=j|X(s)=i).\n\\end{align}\\]\nA Equação acima é conhecida como propriedade de Markov para processos a tempo contínuo.\n\n\n\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 5.2 Quando o processo entra em um estado \\(i\\), o tempo gasto para deixá-lo é denominado tempo de espera.\nPara uma CMTC, a probabilidade do processo estar no estado \\(j\\) no tempo \\(t+s\\) sabendo que o processo esteve em \\(i\\) no tempo \\(s\\) é dada por\n\\[\np_{ij}(t+s,s)=P(X(t+s)=j|X(s)=i).\n\\]\nNotemos que a probabilidade acima considera o estado inicial, e o intervalo de tempo \\([s,s+t)\\). Se \\(p_{ij}(t+s_1,s_1)=p_{ij}(t+s_2,s_2)\\) para qualquer escolha de \\(s_1\\) e \\(s_2\\), dizemos que o processo é homogêneo (nesse caso, a probabilidade depende do comprimento do intervalo de tempo e não do tempo em si).\n\n\n\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 5.3 Denotaremos a probabilidade de transição em um tempo \\(t\\) para uma CMTC homogênea por \\[\\begin{equation}\np_{ij}(t):=P(X(t)=j|X(0)=i).\n\\end{equation}\\]\nNeste curso lidaremos apenas com CMTC homogêneas.\nExiste outro modo de definir uma CMTC. Seja \\(T_i\\) o tempo de espera associado ao estado \\(i\\). Note que \\(\\{T_i>t\\}\\) implica que o processo esteve em \\(i\\) até o tempo \\(t\\), ou seja, implica em \\(\\{X(t)=i\\}\\). Assim, teremos que \\[\\begin{align}\nP(T_i>t+s|T_i>s)&= P(X(t+s)=i|X(s)=i)\\notag\\\\\n&=P(X(t)=i|X(0)=i)=P(T_i>t).\n\\end{align}\\] Assim, uma CMTC homogênea possui perda de memória e, portanto, \\(T_i\\) tem distribuição exponencial. Isto motiva a seguinte definição.\n\n\n\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 5.4 O processo estocástico \\(\\{X(t),t\\geq 0\\}\\) com \\(X(t)\\in D\\subseteq \\mathbb{Z}\\) é uma CMTC se\n\n\\(T_i\\sim \\hbox{Exponencial}(\\nu_i)\\), com \\(E(T_i)=\\nu_i^{-1}\\), para todo \\(i\\in D\\).\nOs \\(T\\)’s são independentes.\n\n\n\n\n\n\n\n\n\n\nExemplo: Processo de Poisson\n\n\n\n\nExemplo 5.1 Seja \\(N(t)\\) um processo de Poisson com taxa \\(\\lambda\\). Então o tempo que o processo gasta para sair do estado \\(i\\) é o tempo que leva para ocorrer um novo evento (ou seja, o tempo de espera). Então \\(T_i\\sim\\hbox{Exponencial}(\\lambda)\\), e um processo de Poisson é uma CMTC.\n\n\n\n\n\n\n\n\n\nExemplo: Barbearia\n\n\n\n\nExemplo 5.2 Uma pequena barbearia possui uma cadeira para realizar seus serviços e outra para um cliente aguardar atendimento. Considere os seguintes estados:\n\n0 - a barbearia está vazia.\n1 - existe um cliente sendo atendido.\n2 - existe um cliente sendo antedido e outro esperando.\n\nExistem outras barbearias por perto, de modo que nenhum cliente gostaria de esperar em pé (assim, a barbearia só pode ter no máximo dois clientes). Seja \\(X(t)\\) o número de clientes na barbearia no tempo \\(t\\). Notemos que \\(X(t)\\in D=\\{0,1,2\\}\\). Sabe-se que o número clientes procurando o serviço segue um processo de Poisson com taxa 3 clientes por hora. Assim, o tempo entre as chegadas possui distribuição exponencial com média 1/3 (em horas). Sabe-se também que o tempo para atender um cliente tem distribuição exponencial com média 10 min (ou 1/6 horas).\nAssim, o tempo de espera no estado 0 tem distribuição Exponencial(\\(3\\)) (a barbearia está vazia e chega um cliente). Se mostrarmos que os outros tempos de espera possuem distribuição exponencial, teremos que \\(X(t)\\) será uma CMTC.\n\n\n\nNo caso do processo de Poisson, assim que o processo abandona o estado \\(i\\) ele automaticamente entra no estado \\(i+1\\). Mas nada impede que um particular estado de outras CMTC tenha várias opções de estados para visitar. Considere que, a partir do estado \\(i\\), o processo pode alcançar imediatamente \\(k\\) estados, denotados por \\(j_1,\\ldots,j_k\\). Seja \\(T_{ij}\\) o tempo que o estado leva para abandonar o estado \\(i\\) e fazer uma transição para o estado \\(j\\). Como o processo é uma CMTC, temos que \\(T_{ij}\\sim\\hbox{Exponencial}(\\nu_{ij})\\). E o que podemos dizer sobre \\(T_i\\) (o tempo que o processo demora para abandonar \\(i\\) sem se importar para o estado de destino)?\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 5.1 Considere que os estados \\(j_1,\\ldots,j_k\\) são acessíveis a partir de \\(i\\). Seja \\(\\nu_{ij}\\) a taxa do tempo de espera do estado \\(i\\) para o estado \\(j\\). Então \\(T_i\\sim\\hbox{Exponencial}(\\nu_i)\\), onde \\(\\nu_i = \\nu_{ij_{1}}+\\cdots +\\nu_{ij_{1}}\\).\nDemonstração: Existem \\(k\\) possibilidades para o processo, cada uma com seu tempo de ocorrência independente das demais. Assim, \\(T_i\\) será o menor tempo de ocorrência entre \\(T_{ij_1},\\ldots,T_{ij_k}\\). Mas, sabemos do Exemplo 6.8 que \\(T_i=\\min\\{T_{ij_1},\\ldots,T_{ij_k}\\}\\sim\\hbox{Exponencial}(\\nu_i)\\), onde \\(\\nu_i=\\nu_{ij_1}+\\cdots+\\nu_{ij_k}\\).\n\n\n\nEstando no estado \\(i\\), existe a possibilidade do processo fazer uma transição para diversos estados. Essa transição, independente do tempo de espera, será denominada simplesmente por probabilidade de transição e será denotada por \\(p_{ij}\\).\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 5.2 onsidere que os estados \\(j_1,\\ldots,j_k\\) são acessíveis a partir de \\(i\\). Seja \\(\\nu_{ij}\\) a taxa do tempo de espera do estado \\(i\\) para o estado \\(j\\). Então \\[\\begin{equation}\n  p_{ij}=\\frac{\\nu_{ij}}{\\nu_i},\\quad j=j_1,\\ldots,j_k\n\\end{equation}\\] onde \\(\\nu_i=\\sum_{l=1}^{k}\\nu_{ij_l}\\) é a taxa do tempo de espera do estado \\(i\\).\nDemonstração: É uma generalização do Exemplo 6.9 e já foi resolvido no Exercício 6.20.\n\n\n\nDe posse destes resultados, podemos construir um grafo para a CMTC de forma semelhante ao que foi feito no Capítulo 4:\n\nOs vértices do grafo são os estados do processo.\nSe \\(i\\rightarrow j\\), então existe um arco, saindo de \\(i\\) e chegando em \\(j\\).\nCada arco \\((i,j)\\) recebe o valor \\(\\nu_{ij}\\).\n\nA partir da construção do grafo, as seguintes operações são verdadeiras:\n\n\\(\\nu_i=\\)soma dos arcos de saem de \\(i\\).\n\\(p_{ij}=\\frac{\\text{arco (i,j)}}{\\nu_i}\\)\n\n\n\n\n\n\n\nExemplo: Barbearia revisitado\n\n\n\n\nExemplo 5.3 Considerando a barbearia do Exemplo 5.2, temos os seguintes estados:\n\n0 - a barbearia está vazia.\n1 - existe um cliente sendo atendido.\n2 - existe um cliente sendo antedido e outro esperando.\n\nAs possíveis transições são:\n\n\\(0\\rightarrow 1\\) - a barbearia estava vazia e entrou um cliente.\n\\(1\\rightarrow 0\\) - havia apenas um cliente e ele foi antedido e abandonou a barbearia.\n\\(1\\rightarrow 2\\) - havia um cliente sendo atendido e, neste meio tempo, um novo cliente entrou.\n\\(2\\rightarrow 1\\) - o serviço de um cliente termino e o serviço do que estava esperando começou.\n\nO tempo de chegada de potenciais clientes tem distribuição exponencial com taxa \\(3\\) clientes por hora e o tempo de atendimento tem distribuição exponencial com taxa \\(6\\) clientes por hora. É natural assumir que estes tempos são independentes. Disto, temos que:\n\n\\(T_{01}\\sim\\hbox{Exponencial}(3)\\) (só pode ter ocorrido uma chegada)\n\\(T_{10}\\sim\\hbox{Exponencial}(6)\\) (só pode ter ocorrido a execução de um serviço)\n\\(T_{12}\\sim\\hbox{Exponencial}(6)\\) (só pode ter ocorrido uma chegada)\n\\(T_{21}\\sim\\hbox{Exponencial}(6)\\) (só pode ter ocorrido a execução de um serviço)\n\ne, disto:\n\\(T_0=T_{01}\\sim\\hbox{Exponencial}(3)\\)\n\\(T_1=\\min\\{T_{10},T_{12}\\}\\sim\\hbox{Exponencial}(9)\\)\n\\(T_2=T_{21}\\sim\\hbox{Exponencial}(6)\\).\nComo todos os tempos de abandono possuem distribuição exponencial e são independentes, este processo é uma CMTC e seu grafo é dado abaixo:\n\n\n\n\n\n\n\n\n\nAs probabilidades de transição são dadas na matriz abaixo:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExemplo: Máquinas I\n\n\n\n\nExemplo 5.4 Uma fábrica possui duas máquinas, \\(A\\) e \\(B\\), e um único mecânico para consertá-las. Elas funcionam por um tempo \\(T_A\\) e \\(T_B\\), onde \\(T_i\\sim\\hbox{Exponencial}(\\lambda_i),\\; i\\in\\{A,B\\}\\). Assim que quebram, o tempo que o mecânico leva para consertá-las tem distribuição exponencial com média \\(1/\\mu\\). Se ambas estiverem quebradas, ele consertará a máquina \\(A\\) primeiro. Seja \\(\\{ (a,b)_t,t\\geq 0\\}\\) um processo estocástico onde \\(a,b\\in\\{0,1\\}\\), onde os estados representam:\n\n\\((0,0)\\) - ambas as máquinas estão quebradas.\n\\((0,1)\\) - a máquina \\(A\\) está quebrada e a máquina \\(B\\) está funcionando.\n\\((1,0)\\) - a máquina \\(B\\) está quebrada e a máquina \\(A\\) está funcionando.\n\\((1,1)\\) - ambas as máquinas estão funcionando.\n\nO grafo desta cadeia é dado abaixo:\n\n\n\n\n\n\n\n\n\nComo os tempos de quebra e conserto são independentes, temos que:\n\n\\(T_{(0,0)}\\sim\\hbox{Exponencial}(\\mu)\\)\n\\(T_{(1,0)}\\sim\\hbox{Exponencial}(\\mu+\\lambda_1)\\)\n\\(T_{(0,1)}\\sim\\hbox{Exponencial}(\\mu+\\lambda_2)\\)\n\\(T_{(1,1)}\\sim\\hbox{Exponencial}(\\lambda_1+\\lambda_2)\\)\n\nAs probabilidades de transição são:"
  },
  {
    "objectID": "cap_5_cmtc.html#distribuição-estacionária",
    "href": "cap_5_cmtc.html#distribuição-estacionária",
    "title": "5  Cadeias de Markov a Tempo Contínuo",
    "section": "5.2 Distribuição Estacionária",
    "text": "5.2 Distribuição Estacionária\nDe modo análogo ao que foi mostrado em CMTD, é possível observar que, sob certas condições, \\(p_{ij}(t)\\) se aproxima de uma constante com o crescimento de \\(t\\). Estamos interessados em saber em quais condições existe o limite \\[\\pi_j :=\\lim_{t\\rightarrow\\infty}p_{ij}(t)>0.\\] Essas condições são dados no Teorema a seguir.\n\n\n\n\n\n\nTeorema\n\n\n\n\nTeorema 5.1 Considere uma CMTC onde:\n\ntodos os estados se comunicam;\nsua única classe é recorrente positiva.\n\nEntão, existe a distribuição estacionária \\(\\pi_j\\), dada por \\[\\begin{align}\n\\nu_j\\pi_j = \\sum_{k\\neq j} \\nu_{kj}\\pi_k, \\quad\\forall j.\n\\label{eq::balanco_continuo}\\end{align}\\] com a restrição de que \\(\\sum_{k}\\pi_k=1\\).\nA equação acima é denominada equação de balanço.\n\n\n\n\n\n\n\n\n\nExemplo: Barbearia - conclusão\n\n\n\n\nExemplo 5.5 Vamos voltar ao Exemplo 5.2. Neste, o processo \\(\\{X(t),t>0\\}\\), onde \\(X(t)\\in\\{0,1,2\\}\\) era uma CMTC, com \\(X(t)\\) sendo o número de usuários no estabelecimento. O grafo desta cadeia está reproduzido abaixo:\n\n\n\n\n\n\n\n\n\nGostaríamos de saber qual a proporção do tempo em que a barbearia está vazia. Isto pode ser calculado encontrando a distribuição estacionária do processo, que é equivalente a resolver o seguinte sistema\n\\[\\nu_0\\pi_0 =\\nu_{10}\\pi_1 + \\nu_{20}\\pi_2\\Rightarrow 3\\pi_0=6\\pi_1 \\\\ \\] \\[ \\nu_1\\pi_1 =\\nu_{01}\\pi_0 + \\nu_{21}\\pi_2\\Rightarrow 9\\pi_1=3\\pi_0+6\\pi_2\\\\ \\] \\[ \\nu_2\\pi_2=\\nu_{02}\\pi_0 + \\nu_{12}\\pi_1\\Rightarrow 6\\pi_2=3\\pi_1\\\\ \\] \\[ \\pi_0+\\pi_1+\\pi_2=1 \\]\ncuja solução é \\({\\pi}=(4/7,2/7,1/7)\\) e a proporção do tempo em que a barbearia fica vazia é dada por \\(2/14\\approx 57,28\\%\\) das vezes. Assim, o barbeiro passa 57,28% do seu tempo ocioso.\n\n\n\n\n\n\n\n\n\nExemplo: Máquinas I - revisitado\n\n\n\n\nExemplo 5.6 Consideremos novamente o Exemplo 5.4, cujos os estados representam o funcionamento de cada máquina (1- máquina funciona, 0 - não funciona). Considere que o tempo que a máquina 1 funciona possui distribuição exponencial com taxa 2 falhas por mês, assim como o tempo da máquina 2, com uma taxa de 6 falhas/mês). Considere ainda que o tempo de conserto possui distribuição exponencial com taxa 10 consertos por mês. O grafo desta cadeia é dado abaixo:\n\n\n\n\n\n\n\n\n\nAs equações de balanço (com a restrição \\(\\sum_k \\pi_k=1\\)) são\n\\[\n\\begin{align*}\n\\nu_{(0,0)}\\pi_{(0,0)} &=\\nu_{(1,0),(0,0)}\\pi_{(1,0)}+\\nu_{(0,1),(0,0)}\\pi_{(0,1)}\\\\\n\\nu_{(0,1)}\\pi_{(0,1)} &=\\nu_{(1,1),(0,1)}\\pi_{(1,1)}\\\\\n\\nu_{(1,0)}\\pi_{(1,0)} &=\\nu_{(0,0),(1,0)}\\pi_{(0,0)}+\\nu_{(1,1),(1,0)}\\pi_{(1,1)}\\\\\n\\nu_{(1,1)}\\pi_{(1,1)} &=\\nu_{(0,1),(1,1)}\\pi_{(0,1)}+\\nu_{(1,0),(1,1)}\\pi_{(1,0)}\\\\\n\\pi_{(0,0)}&+\\pi_{(0,1)}+\\pi_{(1,0)}+\\pi_{(1,1)}=1.\n\\end{align*}\n\\]\nA resolução do sistema (arredondando em duas casas decimais) é \\(\\pi_{(0,0)}=0,1\\), \\(\\pi_{(0,1)}=0,06\\), \\(\\pi_{(1,0)}=0,34\\) e \\(\\pi_{(1,1)}=0,50\\). Podemos dizer, por exemplo, que a proporção do tempo em que as duas máquinas estão funcionando juntas é de 50%."
  },
  {
    "objectID": "cap_5_cmtc.html#processos-de-nascimento-e-morte",
    "href": "cap_5_cmtc.html#processos-de-nascimento-e-morte",
    "title": "5  Cadeias de Markov a Tempo Contínuo",
    "section": "5.3 Processos de Nascimento e Morte",
    "text": "5.3 Processos de Nascimento e Morte\nSeja \\(X(t)\\) o número de indivíduos em certo sistema no tempo \\(t\\). Em cada instante de tempo, um indivíduo pode entrar ou sair do sistema. Se \\(\\{X(t),t\\geq 0\\}\\) é uma CMTC, esta é denominada Processo de Nascimento e Morte (PNM). Seja \\(T_{ij}\\) o tempo espera para uma transição do estado \\(i\\) para \\(j\\in\\{i-1,i+1\\}\\). Então\n\n\\(T_{i,i+1}\\sim\\hbox{Exponencial}(\\lambda_i);\\)\n\\(T_{i,i-1}\\sim\\hbox{Exponencial}(\\mu_i);\\)\n\\(T_0\\sim\\hbox{Exponencial}(\\lambda_0);\\)\n\\(T_i=\\min\\{T_{i,i-1},T_{i,i+1}\\}\\sim\\hbox{Exponencial}(\\lambda_i+\\mu_i).\\)\n\nAs taxas \\(\\lambda_i\\) e \\(\\mu_i\\) são denominadas taxas de nascimento e morte, respectivamente. O grafo típico de um PNM é\n\n\n\n\n\n\n\n\n\nÉ imediato que em um PNM, \\[p_{i,i+1}=\\frac{\\lambda_i}{\\lambda_i+\\mu_i},\\] e que \\[p_{i,i-1}=1-p_{i,i+1}.\\] Com estas informações, podemos encontrar a distribuição estacionária deste processo.\n\n\n\n\n\n\nProposição: Distribuição estacionária\n\n\n\n\nProposição 5.3 Seja \\(\\{X(t),t\\geq 0\\}\\) um PNM. Então, se \\(\\lambda_i,\\mu_i\\neq 0\\) e se \\[\\sum_{j=1}^\\infty\\prod_{i=1}^{j}\\frac{\\lambda_{i-1}}{\\mu_i}<\\infty,\\] a distribuição limite deste processo será\n\\[\\begin{equation}\\label{eq::prob_limite_CC}  \n   \\pi_j = \\left\\{\\begin{array}{ll} \\left(1+\\sum_{j=1}^\\infty\\prod_{i=1}^{j}\\frac{\\lambda_{i-1}}{\\mu_i}\\right)^{-1} & j=0 \\\\\n   \\left(\\prod_{i=1}^j\\frac{\\lambda_{i-1}}{\\mu_i}\\right)\\left(1+\\sum_{j=1}^\\infty\\prod_{i=1}^{j}\\frac{\\lambda_{i-1}}{\\mu_i}\\right)^{-1} & j>0.\n   \\end{array}\\right.\n\\end{equation}\\]\nDemonstração:\nAs restrições \\(\\mu_j\\neq 0\\) e \\(\\lambda_j\\neq 0\\) servem para garantir que a cadeia seja irredutível. Resta saber se ela é recorrente positiva, o que ocorrerá se e somente se a distribuição estacionária for não nula. Assim, temos que \\[\\begin{equation}\n\\lambda_0\\pi_0 = \\sum_{k\\neq 0}\\textcolor{blue}{\\nu}_{k0}\\pi_k=\\nu_{10}\\pi_1=\\mu_1\\pi_1\\Rightarrow \\pi_1=\\frac{\\lambda_0}{\\mu_1}\\pi_0.\n\\end{equation}\\]\nAgora observe que, para qualquer \\(j>0\\), teremos\n\\[\\begin{align}\n\\nu_j\\pi_j &=\\sum_{k\\neq j}\\nu_{kj}\\pi_k=\\nu_{j+1,j}\\pi_{j+1}+\\nu_{j-1,j}\\pi_{j-1} \\notag \\\\\n&=\\mu_{j+1}\\pi_{j+1} + \\lambda_{j-1}\\pi_{j-1} .\n\\end{align}\\]\nAplicando a equação acima utilizando \\(j=1\\), e utilizando a equação anterior, teremos,\n\\[\\begin{align*}\n(\\lambda_1+\\mu_1)\\pi_1=\\pi_2\\mu_2+\\lambda_0\\pi_0 &\\Rightarrow (\\lambda_1+\\mu_1)\\frac{\\lambda_0}{\\mu_1}\\pi_0 = \\pi_2\\mu_2+\\lambda_0\\pi_0\\\\ & \\pi_2 = \\frac{\\lambda_0\\lambda_1}{\\mu_1\\mu_2}\\pi_0.\n\\end{align*}\\]\nSuponha que, \\(\\pi_j = \\prod_{i=1^j}\\lambda_{i-1}\\mu_i\\) é verdade para \\(j=1,\\ldots,n\\). Então, seguindo um raciocínio análogo ao que foi feito para o caso \\(j=1\\), teremos\n\\[\\begin{align*}\n&(\\lambda_n+\\mu_n)\\pi_n = \\mu_{n+1}\\pi_{n+1}+\\lambda_{n-1}\\pi_{n-1} \\\\ &\\Rightarrow (\\lambda_n+\\mu_n)\\prod_{i=1}^n\\frac{\\lambda_{i-1}}{\\mu_i}\\pi_0 = \\mu_{n+1}\\pi_{n+1} + \\lambda_{n-1}\\prod_{i=1}^{n-1}\\frac{\\lambda_{i-1}}{\\mu_i}\\pi_0 \\\\\n&\\Rightarrow \\pi_{n+1}=\\frac{\\pi_0}{\\mu_{n+1}}\\prod_{i=1}^{n-1}\\frac{\\lambda_{i-1}}{\\mu_i}\\left\\{(\\lambda_n+\\mu_n)\\frac{\\lambda_{n-1}}{\\mu_n}-\\lambda_{n-1}\\right\\}\\\\\n&\\Rightarrow \\pi_n = \\pi_0\\prod_{i=1}^n\\frac{\\lambda_{i-1}}{\\mu_i}.\n\\end{align*}\\]\nPortanto, mostramos por indução que cada probabilidade \\(\\pi_j\\), com \\(j>0\\), pode ser escrita como função de \\(\\pi_0\\). Agora, notemos que\n\\[\\begin{align*}\n&1=\\sum_{j=0}^\\infty \\pi_j = \\pi_0+\\sum_{j=1}^\\infty = \\pi_0 +\\pi_0\\sum_{j=1}^{\\infty}\\prod_{i=1}^j\\frac{\\lambda_{i-1}}{\\mu_i}\\\\\n&\\Rightarrow \\pi_0= \\left(1+\\sum_{j=1}^{\\infty}\\prod_{i=1}^{j}\\frac{\\lambda_{i-1}}{\\mu_i}\\right)^{-1},\n\\end{align*}\\]\ne, para qualquer \\(j>0\\),\n\\[\\begin{align*}\n\\pi_j = \\pi_0\\prod_{i=1}^j\\frac{\\lambda_{i-1}}{\\mu_i} = \\left(\\prod_{i=1}^j\\frac{\\lambda_{i-1}}{\\mu_i}\\right)\\left(1+\\sum_{j=1}^{\\infty}\\prod_{i=1}^{j}\\frac{\\lambda_{i-1}}{\\mu_i}\\right)^{-1}.\n\\end{align*}\\]\nOrganizar o seguinte quadro pode ser útil para encontrar a distribuição estacionária:\n\n\n\n\n\n\n\n\n\n\n\n\n\\(i\\)(estados)\n1\n2\n\\(\\cdots\\)\n\\(n-1\\)\n\\(n\\)\nTotal\n\n\n\n\n\\(\\lambda_{i-1}\\)\n\\(\\lambda_0\\)\n\\(\\lambda_1\\)\n\\(\\cdots\\)\n\\(\\lambda_{n-2}\\)\n\\(\\lambda_{n-1}\\)\n-\n\n\n\\(\\mu_{i-1}\\)\n\\(\\mu_1\\)\n\\(\\mu_2\\)\n\\(\\cdots\\)\n\\(\\mu_{n-1}\\)\n\\(\\mu_n\\)\n-\n\n\n\\(\\frac{\\lambda_{i-1}}{\\mu_i}\\)\n\\(\\frac{\\lambda_0}{\\mu_1}\\)\n\\(\\frac{\\lambda_1}{\\mu_2}\\)\n\\(\\cdots\\)\n\\(\\frac{\\lambda_{n-2}}{\\mu_{n-1}}\\)\n\\(\\frac{\\lambda_{n-1}}{\\mu_n}\\)\n-\n\n\n\\(\\prod_{j=1}^i\\frac{\\lambda_{j-1}}{\\mu_j}\\)\n\\(\\frac{\\lambda_0}{\\mu_1}\\)\n\\(\\frac{\\lambda_0}{\\mu_1}\\frac{\\lambda_1}{\\mu_2}\\)\n\\(\\cdots\\)\n\\(\\frac{\\lambda_0}{\\mu_1}\\frac{\\lambda_1}{\\mu_2}\\cdots\\frac{\\lambda_{n-2}}{\\mu_{n-1}}\\)\n\\(\\frac{\\lambda_0}{\\mu_1}\\frac{\\lambda_1}{\\mu_2}\\cdots\\frac{\\lambda_{n-1}}{\\mu_n}\\)\n\\(\\sum_{i=1}^n \\prod_{j=1}^i\\frac{\\lambda_{j-1}}{\\mu_j}\\)\n\n\n\n\n\n\n\n\n\n\n\n\nExemplo: Fila M/M/1\n\n\n\n\nExemplo 5.7 Clientes chegam a uma estação de serviço segundo um processo de Poisson com taxa \\(\\lambda\\). Os clientes entram em fila única e são atendidos por um único servidor. Seja \\(U_i\\) o tempo que o servidor demora para o \\(i\\)-ésimo cliente e considere que \\(U_i\\sim\\hbox{Exponencial}(\\mu)\\), com \\(T_i\\) independente de \\(T_j\\) para todo \\(i\\neq j\\). Por último, seja \\(X(t)\\) o número de clientes na estação de serviço no tempo \\(t\\). É fácil ver que \\(\\{X(t),t\\geq 0\\}\\) é um PNM. De fato, seja \\(T_{ij}\\) o tempo que o processo leva para fazer uma transição do estado \\(i\\) para o estado \\(j\\). Então\n\n\\(T_{i,i+1}\\sim\\hbox{Exponencial}(\\lambda)\\) (tempo de uma chegada)\n\\(T_{i,i-1}\\sim\\hbox{Exponencial}(\\mu)\\) (tempo de um atendimento)\n\\(T_{i,j}\\) não ocorre para qualquer \\(j\\neq\\{i-1,i+1\\}\\).\nTodos os tempos envolvidos são independentes entre si.\n\nAs taxas de nascimento e morte são \\(\\lambda_i=\\lambda\\) e \\(\\mu_j=\\mu\\) para \\(i=0,1,2,\\ldots\\) e \\(j=1,2,3,\\ldots\\). Então,\n\n\n\n\n\n\n\n\n\n\n\n\n\\(i\\)(estados)\n1\n2\n\\(\\cdots\\)\n\\(n-1\\)\n\\(n\\)\nTotal\n\n\n\n\n\\(\\lambda_{i-1}\\)\n\\(\\lambda\\)\n\\(\\lambda\\)\n\\(\\cdots\\)\n\\(\\lambda\\)\n\\(\\lambda\\)\n-\n\n\n\\(\\mu_{i-1}\\)\n\\(\\mu\\)\n\\(\\mu\\)\n\\(\\cdots\\)\n\\(\\mu\\)\n\\(\\mu\\)\n-\n\n\n\\(\\frac{\\lambda_{i-1}}{\\mu_i}\\)\n\\(\\frac{\\lambda}{\\mu}\\)\n\\(\\frac{\\lambda}{\\mu}\\)\n\\(\\cdots\\)\n\\(\\frac{\\lambda}{\\mu}\\)\n\\(\\frac{\\lambda}{\\mu}\\)\n-\n\n\n\\(\\prod_{j=1}^i\\frac{\\lambda_{j-1}}{\\mu_j}\\)\n\\(\\frac{\\lambda}{\\mu}\\)\n\\(\\left(\\frac{\\lambda}{\\mu}\\right)^2\\)\n\\(\\cdots\\)\n\\(\\left(\\frac{\\lambda}{\\mu}\\right)^{n-1}\\)\n\\(\\left(\\frac{\\lambda}{\\mu}\\right)^n\\)\n\\(\\sum_{i=1}^n \\left(\\frac{\\lambda}{\\mu}\\right)^n\\)\n\n\n\nPortanto, existirá distribuição estacionária se \\[\\sum_{i=1}^\\infty\\left(\\frac{\\lambda}{\\mu}\\right) ^i<\\infty\\] Notando que se trata da soma de uma progressão geométrica, sabemos que a série acima será convergente somente se \\(\\lambda / \\mu <1\\) (ou seja, a taxa de morte é maior que a de nascimento). Neste caso, teremos que \\[\\sum_{i=1}^\\infty\\left(\\frac{\\lambda}{\\mu}\\right) ^i=\\frac{\\lambda/\\mu}{1-\\lambda/\\mu}=\\frac{\\lambda}{\\mu - \\lambda},\\] o que implica em \\[\\pi_0=\\left[1+\\frac{\\lambda}{\\mu - \\lambda}\\right]^{-1}=\\frac{\\mu-\\lambda}{\\mu}=1-\\frac{\\lambda}{\\mu}\\] e, para \\(j>0\\), \\[\\pi_j=\\left(\\frac{\\lambda}{\\mu}\\right)^j\\left(1-\\frac{\\lambda}{\\mu}\\right).\\] Portanto, \\[\\begin{align*}\n\\pi_j = \\left(\\frac{\\lambda}{\\mu}\\right)^j\\left(1-\\frac{\\lambda}{\\mu}\\right),\\quad j=0,1,2,\\ldots\n\\end{align*}\\] Assim, a distribuição estacionária deste processo é Geométrica(\\(1-\\lambda/\\mu\\)).\n\n\n\n\n\n\n\n\n\nExemplo\n\n\n\n\nExemplo 5.8 Carros chegam em um posto de gasolina segundo um processo de Poisson com taxa \\(20\\) por hora. Este posto possui apenas uma bomba de gasolina e, se esta estiver ocupada, os demais clientes esperam em fila única. O tempo que um atendente leva para abastecer um carro possui distribuição exponencial com média 1/25 horas (aproximadamente 2,4 minutos). No regime estacionário, qual é a probabilidade do posto estar ocioso?\nRespostas:\nO número de clientes no tempo \\(t\\), denotado por \\(X(t)\\), é um PNM com \\(\\lambda_i=20\\), \\(i=0,1,2,\\ldots\\) e \\(\\mu_j=25\\), \\(j=1,2,3,\\ldots\\). Como \\(\\lambda<\\mu\\), existe distribuição estacionária, sendo esta uma Geométrica(1/5). Portanto, \\[\\pi_0=\\frac{1}{5}=0,2.\\]"
  },
  {
    "objectID": "cap_5_cmtc.html#exercícios",
    "href": "cap_5_cmtc.html#exercícios",
    "title": "5  Cadeias de Markov a Tempo Contínuo",
    "section": "5.4 Exercícios",
    "text": "5.4 Exercícios\n\n\n\n\n\n\n\n\n\n\n\nExercício 5.1 Suponha que um indivíduo unicelular pode estar em dois estados: \\(A\\) ou \\(B\\). Estando em \\(A\\), um indivíduo mudará para o estado \\(B\\) em tempo com distribuição exponencial com taxa \\(\\alpha\\). Um indivíduo no estado \\(B\\) se divide em dois indivíduos no estado \\(A\\) em um tempo exponencial com taxa \\(\\beta\\). Seja \\(\\{X(t),t\\geq 0\\}\\) um processo estocástico onde \\(X(t)=(a(t),b(t))\\), sendo que \\(a(t)\\) e \\(b(t)\\) são o número de indivíduos dos tipos \\(A\\) e \\(B\\) no tempo \\(t\\), respectivamente. Encontre \\(v_i\\) e \\(P_{ij}\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 5.2 Duas máquinas que são consertadas por um único mecânico. A máquina \\(i\\) funciona por um tempo com distribuição exponencial com taxa \\(\\mu_i\\), \\(i=1,2\\). Os tempos de reparo para qualquer máquina possuem distribuição exponencial com taxa \\(\\mu\\). Seja \\(X(t)\\) o número de máquinas quebradas no tempo \\(t\\). Este processo é um processo de nascimento e morte?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 5.3 Clientes em potencial entram em uma estação de serviço com um único servidor de acordo com um processo de Poisson com taxa \\(\\lambda\\). Entretanto, se houverem \\(n\\) clientes na estação, então o próximo cliente entrará no sistema com probabilidade \\(\\alpha_n\\). Assumindo que o tempo de serviço tem distribuição exponencial com taxa \\(\\mu\\), analise a cadeia como um processo de nascimento e morte, determinando as taxas de nascimento e morte.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 5.4 Clientes chegam em uma estação de serviço segundo um processo de Poisson com taxa 1 cliente por minuto. Existem dois servidores que recebem os clientes provenientes de uma fila única. O tempo de serviço de cada servidor é exponencialmente distribuído com taxa 2 clientes por minuto. Seja \\(X(t)\\) o número de clientes deste sistema.\n\nMostre que \\(X(t)\\) é um processo de nascimento e morte.\nEncontre \\(\\nu_i\\), \\(\\lambda_i\\) e \\(\\mu_i\\).\nEncontre a distribuição estacionária de \\(X(t)\\).\nA empresa ganha em média 1 unidade de dinheiro por cliente no sistema. Utilize a distribuição estacionária para calcular o ganho esperado da empresa.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 5.5 Cada indivíduo de certa população gera um novo indivíduo em um tempo com distribuição exponencial com taxa \\(\\lambda\\) e morre em um tempo com distribuição exponencial com taxa \\(\\mu\\). Além disso, um indivíduo imigra para a população em um tempo exponencial com taxa \\(\\theta\\). Entretanto, a imigração não é permitida se o tamanho da população for maior ou igual a \\(N\\).\n\nAnalise esta população como um processo de nascimento e morte, encontrando as taxas e a probabilidade de transição.\nSe \\(N=3\\), \\(\\theta=\\lambda=1\\) e \\(\\mu=2\\), determine a proporção do tempo na qual a imigração está vetada.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 5.6 Clientes chegam ao pronto socorro de um hospital segundo um processo de Poisson com taxa 12 por hora. A probabilidade de que um paciente precise de intervenção imediata é de 1/3. Os pacientes que precisam de intervenção imediata são encaminhados para uma fila com um único servidor, cujo tempo de atendimento possui distribuição exponencial com média 1/8 horas. Os demais pacientes são enviados para outra fila, também com um único servidor, com tempo de serviço exponencialmente distribuído com taxa 16 pacientes por hora. Calcule a probabilidade (estacionária) do hospital não ter pacientes para serem atendidos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 5.7 Seja \\(X(t)\\) um processo de Poisson. Para \\(k>1\\) inteiro e \\(X(t)\\geq 1\\), se \\(X(t)\\) for múltiplo de \\(k\\), então \\(N(t)=1\\). Em caso contrário, \\(N(t)=0\\).\n\nMostre que \\(N(t)\\) é uma cadeia de Markov para \\(k=2\\).\nPara \\(k=2\\), encontre a distribuição estacionária de \\(N(t)\\).\nMostre que para \\(k>2\\) \\(N(t)\\) não é uma cadeia de Markov.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 5.8 Seja \\(\\{X(t),t\\geq 0\\}\\) uma CMTC e seja \\(S=\\{0,1\\}\\) seu espaço dos estados. Considere ainda que os tempos de transição \\(T_{01}\\) e \\(T_{10}\\) são identicamente distribuídos. Seja \\(N(t)\\) o número de vezes que o processo mudou de estado, até o tempo \\(t\\geq 0\\). Encontre \\(P(N(t)=n)\\)."
  },
  {
    "objectID": "cap_6_notas.html#introdução",
    "href": "cap_6_notas.html#introdução",
    "title": "6  Notas",
    "section": "6.1 Introdução",
    "text": "6.1 Introdução\nEste capítulo destina-se enumerar uma série de resultados que serão utilizados posteriormente. Tais resultados já são de conhecimento dos alunos que cursam processos estocásticos e servem unicamente para revisão. É importante ressaltar que este capítulo é colocado neste momento por motivos didáticos, mas que poderia perfeitamente fazer parte de um apêndice, pois a maioria dos resultados será utilizada poucas vezes."
  },
  {
    "objectID": "cap_6_notas.html#resultados-importantes",
    "href": "cap_6_notas.html#resultados-importantes",
    "title": "6  Notas",
    "section": "6.2 Resultados importantes",
    "text": "6.2 Resultados importantes\nNesta seção, apresentamos alguns resultados de séries e de análise combinatória.\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 6.1 A sequência \\(a_1,a_2,\\ldots\\) será um progressão aritmética (PA) se \\(a_i=a_1+(i-1)r\\) para \\(i=1,2,3,\\ldots\\) e \\(r\\in \\mathbb{R}\\).\n\n\n\n\n\n\n\n\n\nExemplo: Soma de uma PA\n\n\n\n\nExemplo 6.1 Talvez você já conheça a demonstração da fórmula da soma finita de \\(n\\) termos de uma PA, denotada por \\(S_n\\). Vamos demonstrar essa fórmula utilizando nosso conhecimento de probabilidade. Seja \\(X\\) a variável aleatória que assume qualquer valor no conjunto \\(\\{a_1,\\ldots,a_n\\}\\) e atribui probabilidade \\(1/n\\) para cada ponto. Então \\[E(X)=\\frac{a_1+\\cdots +a_n}{n}=\\frac{S_n}{n}.\\] Por definição, \\(E(X)\\) é o baricentro da distribuição e, como cada ponto possui a mesma probabilidade e todos eles são equidistantes, o baricentro será o ponto médio do conjunto \\(\\{a_1,\\ldots,a_n\\}\\). Assim, \\[E(X) =\\frac{a_1+a_n}{2}.\\] Igualando as duas equações acima teremos \\[\\begin{equation}\nS_n=\\frac{(a_1+a_n)n}{2}.\n\\end{equation}\\]\n\n\n\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 6.2 A sequência \\(a_1,a_2,\\ldots\\) será um progressão geométrica (PG) se \\(a_i=a_1q^{i-1}\\) para \\(i=1,2,3,\\ldots\\) e \\(q\\neq 0\\).\n\n\n\n\n\n\n\n\n\nExemplo\n\n\n\n\nExemplo 6.2 Certo vírus de computador cria uma cópia de si mesmo a cada segundo. Cada nova cópia gerada procede da mesma maneira.\n\nQuantas cópias deste vírus teremos em uma hora?\nCada cópia possui 1Kb. Quanto tempo é necessário para que os vírus ocupem 1Tb?\n\nResolução:\nSeja \\(X_i\\) o número de cópias no segundo \\(i\\), sneo que \\(X_0=1\\). Como apenas um vírus está no computador, no primeiro segundo ele fará uma cópia de si mesmo, gerando \\(X_1=2\\). No segundo, existem dois vírus e cada um fará uma cópia de si mesmo, gerando \\(X_2=4\\). Um raciocínio análogo mostra que \\(\\{X_0,X_1,X_2,\\ldots\\}=\\{2,4,8,16,\\ldots\\}\\). Assim, temos um PG com \\(q=2\\). Identificando \\(a_1\\) com \\(X_0\\), é fácil ver que \\(X_t=2^t\\) e que\n\\[X_{3600}=2^{3600}.\\]\nAgora, sabendo que um terabyte equivale a \\(10^9\\) kilobytes, temos que \\[X_t=10^9=2^t\\Rightarrow t = \\frac{9\\log 10}{\\log 2}\\approx 29,89,\\] logo, serão necessários 30 segundos para que os vírus ocupem 1Tb de espaço no disco rígido.\n\n\n\n\n\n\n\n\n\nExemplo: Soma de uma PG\n\n\n\n\nExemplo 6.3 Seja \\(\\{a_1,\\ldots,a_n\\}\\) uma PG se seja \\(S_n=a_1+\\cdots+ a_n.\\) Notemos que\n\\[\n\\begin{align}\n  S_1 &= a_1 \\notag\\\\\n  S_2 &= S_1 + a_1q =a_1 (1+q)\\notag\\\\\n  S_3 &= S_2 + a_1q^2 =a_1 (1+q+q^2)\\notag\\\\\n  \\cdots &= \\cdots \\notag\\\\\n  S_n &= S_{n-1} + a_1q^{n-1} =a_1 (1+q+\\cdots q^{n-1}),\\\\\n\\end{align}\n\\tag{6.1}\\]\ne que\n\\[\\begin{align}\nqS_n = a_1(q+q^2+\\cdots + q^n).\n\\end{align}\n\\tag{6.2}\\] De Equação 6.1 e Equação 6.2, temos que\n\\[\\begin{align}\nS_n - qS_n  =a_1(1-q^n) \\Rightarrow S_n = a_1\\frac{1-q^n}{1-q}.\n\\end{align}\\]\nEm especial, se \\(q\\in (0,1)\\), então \\(q^n\\rightarrow 0\\) quando \\(n\\rightarrow\\infty\\) e\n\\[\n\\begin{align}\n\\lim_{n\\rightarrow\\infty}S_n = \\frac{a_1}{1-q}.\n\\end{align}\n\\tag{6.3}\\]\n\n\n\n\n\n\n\n\n\nExemplo: Valor esperado da geométrica\n\n\n\n\nExemplo 6.4 Se \\(X\\) assume valores inteiros não negativos, então \\(E(X)=\\sum_{x=0}^{\\infty}(1-F(x))\\). Seja \\(X\\sim\\hbox{Geometrica}_1(q)\\), onde\n\\[P(X=x)=q(1-q)^{x},\\quad x=0,1,2,\\ldots\\]\ne \\(q\\in(0,1)\\). Em particular, utilizando Equação 6.3 temos que\n\\[\n\\begin{align}\n1-F(x)=P(X>x)=\\sum_{y=x+1}^\\infty q(1-q)^y=(1-q)^{x+1}.\n\\end{align}\\] Assim, utilizando Equação 6.3 novamente, teremos \\[\\begin{align}\nE(X)=\\sum_{x=0}^{\\infty}(1-q)^{x+1}=(1-q)\\sum_{x=0}^{\\infty}(1-q)^{x}=\\frac{1-q}{q}.\n\\end{align}\n\\]\n\n\n\n\n\n\n\n\n\nTeorema: Binomial\n\n\n\n\nTeorema 6.1 Para \\(n\\) natural, \\(x,y>0\\) teremos \\[\\begin{align}\n(x+y)^n=\\sum_{t=0}^n{n\\choose t}x^ty^{n-t}.\n\\end{align}\\]\n\n\n\n\n\n\n\n\n\nExemplo: Função geratriz de momentos da Binomial\n\n\n\n\nExemplo 6.5 Seja \\(X\\sim\\hbox{Binomial}(n,\\theta)\\). Então, sua função geratriz de momentos será \\[\\begin{align*}\nM_X(t)&=\\sum_{x=0}^ne^{tx}{n \\choose x}\\theta^x(1-\\theta)^{n-x}=\\sum_{x=0}^n{n \\choose x}(\\theta e^{t})^x(1-\\theta)^{n-x}=(\\theta e^{t}+1-\\theta)^n.\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nTeorema: Multinomial\n\n\n\n\nTeorema 6.2 Seja \\({\\bf n}=(n_1,n_2,\\ldots,n_k)\\). Então, para \\(x_1,\\ldots,x_k>0\\), teremos \\[\\begin{align}\n(x_1+x_2+\\cdots+ x_k)^n =\\sum_{ \\{ {\\bf n}: \\sum_{i=1}^{k}n_i=n \\}} \\frac{n!}{n_1! n_2!\\ldots n_k!}x_1^{n_1}x_2^{n_2}\\ldots x_k^{n_k}\n\\end{align}\\]\n\n\n\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 6.3 Definimos a constante de Euler, representada por \\(e\\), como \\(e = \\lim_{n\\rightarrow\\infty}\\left(1+\\frac{1}{n}\\right)^n.\\)\nEntretanto, ela pode ser encontrada de outros modos. Abaixo, apresentamos outra forma.\n\n\n\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 6.1 A constante de Euler pode ser escrita como \\[\\begin{align*}\n   e=\\sum_{t=0}^{\\infty} \\frac{1}{t!}.\n\\end{align*}\\]\nDemonstração: Utilizando o Teorema 6.1: \\[\\begin{align*}\n\\left(1+\\frac{1}{n}\\right)^n&=\\sum_{t=0}^{n}{n\\choose t}\\frac{1}{n^t}=\\sum_{t=0}^{n}\\frac{1}{t!}\\frac{n(n-1)\\ldots(n-t+1)}{n^t}\n\\\\&=\\sum_{t=0}^{n}\\frac{1}{t!}\\left(1-\\frac{1}{n}\\right)\\left(1-\\frac{2}{n}\\right)\\ldots\\left(1-\\frac{t-1}{n}\\right)\n\\end{align*}\\] Podemos notar que \\[\\begin{align*}\n\\lim_{n\\rightarrow\\infty}\\frac{1}{t!}\\left(1-\\frac{1}{n}\\right)\\left(1-\\frac{2}{n}\\right)\\ldots\\left(1-\\frac{t-1}{n}\\right)=\\frac{1}{t!}\n\\end{align*}\\] Vamos utilizar (sem provar) que é válida a seguinte equação: \\[\\begin{align*}\n\\lim_{n\\rightarrow\\infty}\\sum_{t=0}^{n}{n\\choose t}\\frac{1}{n^t}=\\sum_{t=0}^{\\infty}\\lim_{n\\rightarrow\\infty}{n\\choose t}\\frac{1}{n^t}.\n\\end{align*}\\] Assim, \\[\\begin{equation}\ne=\\sum_{x=0}^{\\infty}\\frac{1}{t!}.\n\\end{equation}\\]\n\n\n\nAlém disso, teremos a seguinte proposição:\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 6.2 Para qualquer \\(\\theta\\) real teremos \\[\\begin{equation}\n\\sum_{x=0}^\\infty\\frac{\\theta^x}{x!}=e^\\theta.\n\\end{equation}\\]\nDemonstração: Podemos proceder de forma análoga ao que foi exposto na Proposição 6.1, fazendo apenas uma mudança de variável. Uma forma alternativa para demonstrar este resultado será explorada nos exercícios.\n\n\n\nA função gama, definida abaixo, é utilizada em diversas distribuições de probabilidade.\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 6.4 A função gama é definida por \\[\\begin{equation}\n\\Gamma(a)=\\int_0^{\\infty} t^{a-1}e^{-t}dt,\\quad a>0.\n\\end{equation}\\]\nA seguinte propriedade mostra que a função gama é uma generalização da função fatorial.\n\n\n\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 6.3 Demonstração:\nPara \\(\\alpha>0\\), \\(\\Gamma(\\alpha+1)=\\alpha\\Gamma(\\alpha)\\).\n\\[\\begin{align*}\n\\Gamma(a)&=\\int_0^{\\infty} t^{a-1}e^{-t}dt,\\quad \\left(\\hbox{fazendo $u=t^{a-1}$ e $dv=e^{-t}$}\\right)\\\\\n&=-\\left. t^{a-1}e^{-t}\\right|_0^{\\infty}+\\int_0^{\\infty}(a-1)t^{a-2}e^{-t}dt\\\\\n&=(a-1)\\int_0^{\\infty}t^{a-2}e^{-t}dt=(a-1)\\Gamma(a-1)\n\\end{align*}\\] logo, \\(\\Gamma(a)=(a-1)\\Gamma(a-1)\\).\nEm especial, notemos que \\[\\begin{align}\n\\Gamma(1)=\\int_0^\\infty e^{-t}dt=1\n\\end{align}\\] e \\(\\Gamma(2)=(2-1)\\Gamma(1)=1\\). O seguinte corolário pode ser provado por indução.\n\n\n\n\n\n\n\n\n\nCorolário\n\n\n\n\nCorolário 6.1 Se \\(\\alpha\\) é um inteiro maior que zero, então \\(\\Gamma(\\alpha)=(\\alpha-1)!\\).\nDemonstração: Exercício 6.10\nAssim, a função gama pode ser interpretada como uma versão contínua da função fatorial. Alguns valores de \\(\\Gamma(\\alpha)\\) são utilizados em algumas distribuições, como é o caso de \\(\\Gamma(1/2)\\) na distribuição qui-quadrado.\n\n\n\n\n\n\n\n\n\nExemplo: O valor de \\(\\Gamma(1/2)\\)\n\n\n\n\nExemplo 6.6 Existe um modo interessante de mostrar que \\(\\Gamma(1/2)=\\sqrt{\\pi}\\), através da distribuição normal. Temos que \\[\\begin{align}\n\\Gamma(1/2)&=\\int_0^{\\infty}x^{-1/2}e^{-x}dx \\quad\\left(\\hbox{fazendo $x=u^2$ }\\right)\n\\notag \\\\&=2\\int_0^\\infty e^{-u^2}du.\n\\end{align}\\] Agora, tomemos \\(Y\\sim\\hbox{Normal}(0,1/2)\\). Sabemos que a densidade da normal é simétrica e que \\[\\begin{align}\n1&=\\int_{-\\infty}^\\infty \\frac{1}{\\sqrt{\\pi}}e^{-y^2}dy=2\\int_0^{\\infty}\\frac{1}{\\sqrt{\\pi}}e^{-y^2}dy=\\frac{2}{\\sqrt{\\pi}}\\int_0^\\infty e^{-y^2}dy\\notag \\\\\n&\\Rightarrow \\int_0^\\infty e^{-y^2}dy=\\frac{\\sqrt{\\pi}}{2}.\n\\end{align}\\] Assim, \\[\\Gamma\\left(\\frac{1}{2}\\right)=\\sqrt{\\pi}.\\]\nDefinimos a função gama incompleta como segue: \\[\\begin{equation}\n\\Gamma_x(a)=\\int_0^x t^{a-1}e^{-t}dt\n\\end{equation}\\]"
  },
  {
    "objectID": "cap_6_notas.html#distribuições-importantes",
    "href": "cap_6_notas.html#distribuições-importantes",
    "title": "6  Notas",
    "section": "6.3 Distribuições importantes",
    "text": "6.3 Distribuições importantes\nDiscutiremos nesta seção as seguintes distribuições: exponencial, gama e Poisson.\n\n6.3.1 Exponencial\nDizemos que a variável aleatória \\(T\\) possui distribuição exponencial com taxa \\(\\lambda\\), (\\(T\\sim\\hbox{Exponencial}(\\lambda)\\)) se sua densidade for \\[\\begin{equation}\nf(t)=\\lambda e^{-\\lambda t},\\quad \\lambda>0,\\quad t>0.\n\\end{equation}\\] A função de distribuição da exponencial é\n\\[\n\\begin{align}\nF(x)=\\int_0^x \\lambda e^{-\\lambda t}dt =1-e^{-\\lambda x},\n\\end{align}\n\\tag{6.4}\\]\ne seus momentos podem ser calculados como segue:\n\\[\\begin{align*}\nE(T^k)&=\\int_0^{\\infty}t^k\\lambda e^{-\\lambda t}dt, \\quad \\left(\\hbox{fazendo $\\lambda t=u$}\\right),\\\\\n&=\\frac{1}{\\lambda^k}\\int_0^\\infty u^k e^{-u}du=\\frac{\\Gamma(k+1)}{\\lambda^k}=\\frac{k!}{\\lambda^k}.\n\\end{align*}\\] Em especial, teremos \\[\\begin{align}\nE(T)&=\\frac{\\Gamma(2)}{\\lambda}=\\frac{1}{\\lambda}\\\\\nE(T^2)&=\\frac{\\Gamma(3)}{\\lambda^2}=\\frac{2}{\\lambda^2}\\\\\nVar(T)&=\\frac{1}{\\lambda^2}\n\\end{align}\\] A função geratriz de momentos da exponencial é \\[\\begin{align}\nM_X(t)=E(e^{tX})=\\int_0^\\infty \\lambda e^{-x(\\lambda - t)}dx=\\frac{\\lambda}{\\lambda-t},\\quad t<\\lambda.\n\\end{align}\\]\n\n\n\n\n\n\nExemplo: Falta de Memória\n\n\n\n\nExemplo 6.7 Suponha que o tempo de vida de uma lâmpada possui distribuição exponencial com média 2 anos. Você liga essa lâmpada uma vez e sai para viajar por um ano. Quando Você volta, a lâmpada ainda está ligada. Qual a probabilidade da lâmpada durar mais um ano? Seja \\(T\\) o tempo de vida da lâmpada. O evento lâmpada não queimou no primeiro ano é dado por \\(\\{T>1\\}\\). De modo análogo, o evento no qual a lâmpada dura dois anos é \\(\\{T>2\\}\\). Assim, a probabilidade da lâmpada durar dois anos dado que ela durou um ano é \\[P(T>2|T>1)\\] O fato curioso é que essa probabilidade é mesma de que uma lâmpada nova do mesmo tipo dure um ano! Isso acontece porque a distribuição exponencial possui a propriedade de falta de memória. Vamos mostrar isso de um modo geral: seja \\(T\\sim\\hbox{Exponencial}(\\lambda)\\) e sejam \\(t,s>0\\). Então\n\\[\\begin{align*}\nP(T>t+s|T>s)&=\\frac{P(T>t+s,T>s)}{P(T>s)}=\\frac{P(T>t+s)}{P(T>s)}\\\\&=\\frac{e^{-\\lambda(t+s)}}{e^{-\\lambda s}}=e^{-\\lambda t}=P(T>t).\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nExemplo: Mínimo de exponenciais\n\n\n\n\nExemplo 6.8 Sejam \\(T_1\\) e \\(T_2\\) variáveis aleatórias independentes com distribuição exponencial com taxas \\(\\lambda_1\\) e \\(\\lambda_2\\), respectivamente. Seja \\(M_2=\\min\\{T_1,T_2\\}\\). Notemos que, se \\(M_2>m\\), então \\(T_1\\) e \\(T_2\\) devem ser maiores de \\(m\\). Disto, teremos\n\\[\\begin{align*}\n1-F_{M_2}(m)&=P(M_2> m)=P(T_1>m,T_2>m)=e^{-(\\lambda_1+\\lambda_2)m},\n\\end{align*}\\] logo \\(F_{M_2}(m)=1-\\exp\\left\\{-(\\lambda_1+\\lambda_2)m\\right\\}\\). Notando que \\(F_{M_2}\\) é da mesma forma que Equação 6.4, teremos que \\(M_2\\sim\\hbox{Exponencial}(\\lambda_1+\\lambda_2)\\).\nÉ fácil mostrar que \\(M_n=\\min\\{X_1,\\ldots,X_n\\}\\sim\\hbox{Exponencial}(\\lambda_1+\\cdots+\\lambda_n)\\).\n\n\n\n\n\n\n\n\n\nExemplo: Dois atletas\n\n\n\n\nExemplo 6.9 Dois atletas disputam uma corrida. É sabido que o atleta \\(A\\) demora \\(T_A\\) minutos para terminar a prova, enquanto que o \\(B\\) demora \\(T_B\\) minutos. Se \\(T_i\\sim\\hbox{Exponencial}(\\lambda_i)\\), onde \\(i\\in\\{A,B\\}\\) e \\(T_A\\) é independente de \\(T_B\\), qual a probabilidade de que o atleta \\(A\\) ganhe a prova?\nResolução:\nO atleta \\(A\\) ganhará a prova se \\(T_A<T_B\\). Assim,\n\\[\n\\begin{align}\nP(T_A<T_B)&=\\int_0^\\infty P(T_A<T_B|T_B=t)f_{T_B}(t)dt \\\\&= \\int_0^\\infty P(T_A<t|T_B=t)f_{T_B}(t), \\quad \\hbox{por independência}\\\\\n&=\\int_0^\\infty F_{T_A}(t)f_{T_B}(t)dt = \\int_0^\\infty (1-e^{-\\lambda_A t})\\lambda_B e^{-\\lambda_B t}\\\\\n&= 1-\\lambda_B\\int_{0}^\\infty e^{-(\\lambda_A+\\lambda_B)t}dt = \\frac{\\lambda_A}{\\lambda_A+\\lambda_B}.\n\\end{align}\n\\]\nO resultado acima pode ser facilmente generalizado para o caso de \\(n\\) atletas (ver Exercício 6.20).\n\n\n\n\n\n6.3.2 Gama\nDizemos que a variável aleatória \\(S\\) possui distribuição gama com parâmetros \\(\\alpha\\) e \\(\\beta\\) (notação \\(S\\sim\\hbox{Gama}(\\alpha,\\beta)\\)) se sua densidade for como segue\n\\[\\begin{equation}\nf(s)=\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}s^{\\alpha-1}e^{-\\beta s},\\quad s,\\alpha,\\beta>0.\n\\end{equation}\\]\nSua função distribuição será dada por\n\\[\\begin{align}\nF(s)&=\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}\\int_0^s x^{\\alpha-1}e^{-\\beta x}dx, \\quad \\left(\\hbox{ fazendo $u=\\beta x$}\\right)\\notag\\\\\n&=\\frac{1}{\\Gamma(\\alpha)}\\int_0^{\\beta s} u^{\\alpha-1}e^{-u}du =\\frac{\\Gamma_{\\beta s}(\\alpha)}{\\Gamma(\\alpha)}.\n\\end{align}\\]\nMomentos:\n\\[\\begin{align}\nE(S^k)&=\\int_0^\\infty s^k\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}s^{\\alpha-1}e^{-\\beta s}ds=\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}\\int_0^\\infty s^{\\alpha+k-1}e^{-\\beta s}ds,\\quad\\left(\\hbox{ fazendo $u=\\beta s$}\\right),\\notag\\\\\n&=\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}\\beta^{-k-\\alpha}\\int_0^\\infty u^{\\alpha+k}e^{-u}du    =\\frac{\\Gamma(\\alpha+k)}{\\beta^k\\Gamma(\\alpha)}\n\\end{align}\\]\nEm especial,\n\\[\\begin{align}\nE(S)&=\\frac{\\alpha}{\\beta}\\\\\nE(S^2)&=\\frac{(\\alpha+1)\\alpha}{\\beta^2}=\\left(E(S)+\\frac{1}{\\beta}\\right)E(S)\\\\\nV(S)&=\\frac{E(S)}{\\beta}=\\frac{\\alpha}{\\beta^2}\n\\end{align}\\]\nA função geratriz de momentos de \\(S\\) é dada por\n\\[\\begin{align}\nM_S(t)=E(e^{ts})=\\int_0^\\infty \\frac{\\beta^\\alpha\n}{\\Gamma(\\alpha)}s^{\\alpha-1}e^{-s(\\beta-t)}ds =\\left(\\frac{\\beta}{\\beta-t}\\right)^\\alpha,\\quad t<\\beta.\n\\end{align}\\]\n\n\n\n\n\n\nExemplo: Gama Inversa\n\n\n\n\nExemplo 6.10 Seja \\(S\\sim \\hbox{Gama}(\\alpha,\\beta)\\). Seja \\(Z=1/S\\). Podemos notar que \\[P(Z\\leq z )=P(S\\geq 1/z)= F_S(1/z),\\] logo \\[\\begin{equation}\nf_Z(z) = f_S(1/z)\\frac{1}{z^2}=\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}\\left(\\frac{1}{z}\\right)^{\\alpha+1}e^{\\frac{\\beta}{z}},\n\\end{equation}\\] onde \\(z>0\\). Essa distribuição é denominada gama inversa. Notação: \\(Z\\sim\\hbox{GI}(\\alpha,\\beta)\\).\n\n\n\n\n\n6.3.3 Poisson\nDizemos que a variável \\(N\\) possui distribuição Poisson com taxa \\(\\lambda\\) (\\(N\\sim\\hbox{Poisson}(\\lambda)\\)), se\n\\[\\begin{equation}\nP(N=n)=\\frac{e^{-\\lambda}\\lambda^n}{n!}\n\\end{equation}\\]\nFunção geratriz de momentos\n\\[\n\\begin{align}\nM_N(t)&=\\sum_{n=0}^\\infty e^{nt}\\frac{e^{-\\lambda}\\lambda^n}{n!}=e^{-\\lambda}\\sum_{n=0}^\\infty \\frac{[\\lambda e^{t}]^n}{n!}=\\exp\\{-\\lambda(1-e^t)\\}\n\\end{align}\n\\tag{6.5}\\]\nEm especial\n\\[\\begin{align}\n\\frac{d}{dt}M_N(t)&=\\lambda e^t M_N(t),\\Rightarrow E(N)= \\lambda\\\\\n\\frac{d^2}{dt^2}M_N(t)&=\\lambda e^t M_N(t)+\\lambda^2 e^{2t}M_N(t),\\Rightarrow E(N^2)=\\lambda +\\lambda^2\\\\\nV(N)=\\lambda\n\\end{align}\\]\n\n\n\n\n\n\nExemplo: Soma de Poissons\n\n\n\n\nExemplo 6.11 Sejam \\(X_1,\\ldots,X_n\\) variáveis aleatórias com distribuição Poisson com taxas \\(\\lambda_1,\\ldots,\\lambda_n\\). Notemos que \\[\\begin{align}\nM_{X_1+\\cdots +X_n}(t)&=\\prod_{i=1}^n M_{X_i}(t)=\\exp\\{-(\\lambda_1+\\cdots+\\lambda_n)(1-e^t)\\}\n\\end{align}\\] Logo, \\(X_1+\\cdots+X_n\\sim\\hbox{Poisson}(\\lambda_1+\\cdots+\\lambda_n)\\). Assim, soma devariáveis aleatórias independentes com distribuição Poisson tambéem possuem distribuição Poisson.\n\n\n\n\n\n\n\n\n\nExemplo: Condicionando somas de Poissons\n\n\n\n\nExemplo 6.12 Outro resultado interessante: Sejam \\(N_1,N_2\\) variáveis aleatórias independentes com distribuição Poisson com taxas \\(\\lambda_1\\) e \\(\\lambda_2\\). Sejam \\(N=N_1+N_2\\). Então \\((N_1|N)\\sim\\hbox{Binomial}(N,p)\\), onde \\(p=\\lambda_1/(\\lambda_1+\\lambda_2)\\). De fato, \\[\\begin{align}\nP(N_1=n_1|N=n)&=\\frac{P(N_1=n_1,N_1+N_2=n)}{P(N=n)}=\\frac{P(N_1=n_1,N_2=n-n_1)}{P(N=n)}\\notag\\\\&=\n\\frac{e^{-\\lambda_1}\\lambda_1^{n_1}}{n_1!}\\frac{e^{-\\lambda_2}\\lambda_2^{n-n_1}}{(n-n_1)!}\\frac{n!}{e^{-\\lambda_1-\\lambda_2}(\\lambda_1+\\lambda_2)^{n-n_1}}\\notag\\\\\n&={n\\choose n_1}\\left(\\frac{\\lambda_1}{\\lambda_1+\\lambda_2}\\right)^{n_1}\\left(\\frac{\\lambda_2}{\\lambda_1+\\lambda_2}\\right)^{n-n_1}\n\\end{align}\\]\n\n\n\n\n\n\n\n\n\nExemplo: Aproximação da Binomial para a Poisson\n\n\n\n\nExemplo 6.13 Seja \\(X\\sim\\hbox{Binomial}(n,p)\\). Pelo Exemplo 6.5, temos que \\[M_X(t)= (1-p(1-e^t))^n.\\] Façamos \\(\\lambda=pn\\). Então\n\\[\\begin{align}\n\\lim_{n\\rightarrow \\infty}M_X(t)=\\lim_{x\\rightarrow\\infty}\\left(1-\\frac{\\lambda}{n}(1-e^t)\\right)^{n}=e^{\\lambda(1-e^t)}.\n\\end{align}\n\\tag{6.6}\\]\nComparando a Equação 6.6 com Equação 6.5, podemos perceber que \\(X\\) se aproxima da distribuiçao Poisson com taxa \\(\\lambda=np\\)."
  },
  {
    "objectID": "cap_6_notas.html#esperança-condicional",
    "href": "cap_6_notas.html#esperança-condicional",
    "title": "6  Notas",
    "section": "6.4 Esperança condicional",
    "text": "6.4 Esperança condicional\nNeste curso, será comum avaliarmos a ocorrência de uma variável aleatória condicionada a outra. Por exemplo, seja \\(X\\) o número de itens comprados por um cliente em um supermercado e seja \\(Y\\) o número de clientes no supermercado em um dia. Suponha que \\(X\\sim\\hbox{Poisson}(\\lambda)\\) e \\(Y\\sim\\hbox{Poisson}(\\delta)\\). Qual o número de esperado de itens vendidos em um dia?\nNeste problema, sabemos que o número de itens vendidos será \\(W=X_1+\\cdots+X_Y\\), onde \\(X_i\\) É o número de itens comprados pelo \\(i\\)-ésimo cliente. Contudo, não conhecemos a distribuição de \\(W\\), pois \\(Y\\) é desconhecido. É claro que esta distribuição pode ser obtida pela relação. \\[\\begin{align*}\nP(W=w)=\\sum_{y=0}^{\\infty}P(W=w|Y=y)P(Y=y).\n\\end{align*}\\] A distribuição \\(W|Y\\) \\é conhecida, pois, uma vez que \\(Y\\) está fixado, \\(W\\) é equivalente a soma de \\(Y\\) variáveis independentes com distribuição Poisson, ou seja, \\(W|Y\\sim\\hbox{Poisson}(Y\\lambda)\\). Já a distribuição de \\(W\\) é difícil de lidar. Entretanto, podemos encontrar o valor esperado de \\(W\\) através dos valores esperados de \\(W|Y\\) e \\(Y\\). De fato, teremos que\n\\[\\begin{align}\nE(W)&=\\sum_{w=\\infty}^{\\infty}wP(W=w)=\\sum_{w=\\infty}^{\\infty}\\sum_{y=\\infty}^{\\infty}wP(W=w,Y=y)\\notag\\\\\n&=\\sum_{w=\\infty}^{\\infty}\\sum_{y=\\infty}^{\\infty}wP(W=w|Y=y)P(Y=y)\\notag\\\\\n&=\\sum_{y=\\infty}^{\\infty}\\sum_{w=\\infty}^{\\infty}wP(W=w|Y=y)P(Y=y)\\notag\\\\\n&=\\sum_{y=\\infty}^{\\infty}E(W|Y)P(Y=y)=E_Y\\left(E(W|Y)\\right).\n\\end{align}\\] Desde que as esperanas envolvidas existam, a equação acima é válida tanto para variáveis discretas quanto para contínuas. Voltanto ao problema dos itens no supermercado, teremos que \\[\\begin{align*}\nE(W)&=E_Y\\left(E(W|Y)\\right)=E_Y\\left(\\lambda Y\\right)=\\delta\\lambda.\n\\end{align*}\\] Fica como exercício mostrar que, se \\(E(X^k|Y)<\\infty\\) e \\(E(Y^k)<\\infty\\), então \\[\\begin{align}\nE(X^k)=E_Y\\left(E(X^k|Y)\\right).\n\\end{align}\\] Com a última igualdade, podemos mostrar que \\[\\begin{align}\nV(X)&=E_Y\\left(E(X^2|Y)\\right) - \\left[E_Y\\left(E(X|Y)\\right)\\right]^2\\pm E_Y(E(X|Y)^2)\\notag\\\\\n&=\\left(E_Y\\left(E(X^2|Y)\\right) - E_Y(E(X|Y)^2)\\right)+\\left(E_Y(E(X|Y)^2)- \\left[E_Y\\left(E(X|Y)\\right)\\right]^2\\right)\\notag\\\\\n&=E_Y\\left[E(X^2|Y)-E(X|Y)^2)\\right]+V_Y\\left[E(X|Y)\\right]\\notag\\\\\n&=E_Y\\left[V(X|Y)\\right]+V_Y\\left[E(X|Y)\\right]\n\\end{align}\\] Aplicando esta última identidade no problema dos itens do supermercado, teremos que \\[V(W)=E_Y(\\lambda Y)+V_Y(\\lambda Y)=\\lambda\\delta +\\lambda^2\\delta=\\delta\\lambda(1-\\lambda).\\]"
  },
  {
    "objectID": "cap_6_notas.html#inferência",
    "href": "cap_6_notas.html#inferência",
    "title": "6  Notas",
    "section": "6.5 Inferência",
    "text": "6.5 Inferência\nEsse tópico será inserido em outro curso."
  },
  {
    "objectID": "cap_6_notas.html#teoria-dos-grafos",
    "href": "cap_6_notas.html#teoria-dos-grafos",
    "title": "6  Notas",
    "section": "6.6 Teoria dos grafos",
    "text": "6.6 Teoria dos grafos\nNesta seção, mostraremos o conceito básico de grafos. A experiência diz que alguns conceitos de processos estocásticos, como as cadeias de Markov, são melhor compreendidos com o uso dessa ferramenta. O leitor interessado no uso de grafos, pode consultar os livros XX e YY.\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 6.5 Seja \\(V\\) um conjunto discreto, denominado conjunto dos vértices, e seja \\(E\\) um conjunto de arestas, onde dizemos que existe uma aresta entre os vértices \\((v,w)\\) se ambos estão relacionados. A dupla \\(G=(V,E)\\) é denominada grafo.\n\n\n\nEm termos didáticos, grafos simples oferecem a vantagem de uma fácil visualização gráfica: cada vértice pode ser representado por um ponto no plano e as arestas podem ser representadas por linhas unindo os pontos se estes estão relacionados.\n\n\n\n\n\n\nExemplo: Arestas orientadas\n\n\n\n\nDefinição 6.6 Dizemos que uma aresta é orientada quando a relação entre o par \\((x,y)\\) não necessariamente é válida para o par \\((y,x)\\). Por exemplo, seja \\(V=\\{2,6,4,5,10\\}\\) e seja \\(E\\) o conjunto de arestas tal que existe a aresta \\((x,y)\\) se \\(x\\) é divisível por \\(y\\), com \\(x\\neq y\\). Existe a aresta \\((4,2)\\), pois 4 é divisível por 2, mas não existe a aresta \\((2,4)\\) pois 2 não é divisível por \\(4\\). As arestas existentes são: \\((4,2),(6,2),(10,2)\\) e \\((10,5)\\). A representação gráfica deste grafo é dada a seguir\n\n\n\n\n\n\n\n\n\nNote que em um grafo orientado, uma seta é colocada na aresta para indicar a direção da relação.\n\n\n\nNeste texto, arestas orientadas serão denominadas arcos. Além disso, o arco \\((v,v)\\) será denominado laço.\n\n\n\n\n\n\nExemplo: Grafos de dependência\n\n\n\n\nExemplo 6.14 Considere as variáveis \\(X_1,X_2,X_3,X_4\\) onde \\(X_1|X_2,X_3\\) é independente de \\(X_4\\), \\(X_3\\) é independente de \\(X_4\\) e \\(X_2\\) é dependente de \\(X_4\\). Um grafo de dependências é construído da seguinte forma:\n\nFaça \\(V=\\{X_1,X_2,X_3,X_4\\}\\)\nCrie a aresta \\(v,w\\) se as variáveis aleatórias \\(v\\) e \\(w\\) são dependentes.\n\nSe \\(Y\\) é dependente de \\(Z\\), então \\(Z\\) é dependente de \\(Y\\). Assim, as arestas deste grafo não são orientadas. Para esse exemplo, temos as seguintes arestas\n\n\\(e_1: (X_1,X_2)\\) pois \\(X_1\\) é dependente de \\(X_2\\)\n\\(e_2: (X_1,X_3)\\) pois \\(X_1\\) é dependente de \\(X_3\\)\n\nO grafo de dependências será dado por \\(G=(V,E)\\), onde \\(E=\\{e_1,e_2,e_3\\}\\). Esse grafo pode ser representado graficamente como segue:\n\n\n\n\n\n\n\n\n\nNotemos que as arestas não possuem setas (se \\(A\\) é dependente de \\(B\\), então \\(B\\) é dependente de \\(A\\)). Algumas conclusões podem ser tiradas: Os vértices \\(X_1,X_2,X_3\\) são independentes de \\(X_4\\) (não existem arestas ligando os primeiros vértices a \\(X_4\\)) e, dado \\(X_1\\), \\(X_2\\) e \\(X_3\\) são independentes (retirando \\(X_1\\), o caminho entre \\(X_2\\) e \\(X_3\\) some).\n\n\n\nAo longo deste curso, utilizaremos apenas grafos orientados. Além disso, em muitos momentos apresentaremos a representação gráfica de um grafo como sendo o grafo. Isso é um abuso de linguagem, uma vez que o grafo é uma entidade matemática bem definida. Outro conceito importante é dado a seguir.\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 6.7 A matriz \\(A\\) na qual o elemento \\((i,j)\\) é igual a 1 se existe a aresta \\((i,j)\\) e 0 em caso contrário é denominada matriz de adjacências.\n\n\n\nA matriz de adjacências também é utilizada para definir o grafo, uma vez que ela contém todos os vértices e todas as arestas do grafo. Considere a seguinte matriz de adjacências, onde os rótulos das linhas e colunas correspondem aos vértices do grafo.\n\n\n\n\n\n\n\n\n\nDesta matriz, podemos concluir, por exemplo, que existe a aresta \\((1,2)\\), mas não existe a aresta \\((2,1)\\), fazendo deste um grafo orientado. A representação gráfica deste grafo é dada abaixo:\n\n\n\n\n\n\n\n\n\nImagine agora que um indivíduo se encontra no vértice zero. Em cada passo, o indivíduo pode seguir por um arco. A matriz de adjacências mostra quais são os possíveis lugares que este indivíduo pode chegar após dar um passo. Assim, essa matriz também é denominada matriz de transição um passo à frente. Um aspecto importante de um grafo é saber se é possível alcançar o vértice \\(i\\) através do vértice \\(j\\). Por exemplo, é possível sair do vértice zero e chegar no vértice 2? A resposta é: sim, basta seguir as arestas \\((0,1)\\) e \\((1,2)\\). Tal aspecto é denominado acessibilidade.\n\n\n\n\n\n\nDefinição\n\n\n\n\nDefinição 6.8 Dizemos que o vértice \\(j\\) é acessível a partir de \\(i\\) se existe uma sucessão de arcos que ligam o vértice \\(i\\) ao vértice \\(j\\). Denotamos isso por \\(i\\rightarrow j\\). Se tal sucessão não existe, dizemos que \\(j\\) não é acessível a partir de \\(i\\) e denotamos este fator por \\(i\\nrightarrow j\\).\n\n\n\nNota: por convenção, vamos assumir que sempre \\(i\\rightarrow i\\), considerando que podemos voltar para \\(i\\) em zero passos.\nÉ importante notarmos que a acessibilidade é invariante ao número de passos! No exemplo em estudo, \\(0\\rightarrow 1\\), pois podemos sair do vértice 0 e chegar ao vértice 2 em dois passos. A matriz de adjacências nos mostra quais vértices estão acessíveis a partir de um passo, mas também podemos construir matrizes que nos mostrem os vértices acessíveis dois passos à frente, três passos, e assim por diante. Essa construção é fácil, como mostra a seguinte proposição.\n\n\n\n\n\n\nProposição\n\n\n\n\nProposição 6.4 Considere um grafo com matriz de transição \\(\\textbf{A}\\). Seja \\({\\bf A}_n\\) a matriz de transição \\(n\\) passos à frente (neste caso, \\({\\bf A}_1={\\bf A}\\)). Então \\({\\bf A}_n={\\bf A}^n\\).\nNota: a matriz \\({\\bf A}_n\\) indica quantos caminhos existem entre cada par de vértices. Uma entrada igual a zero implica que aquele caminho não existe.\nPara qualquer \\(a_{ij}\\in {\\bf A}\\), sabemos que \\(a_{ij}=1\\) se existe o arco \\((i,j)\\) e zero em caso contrário. Suponha que queremos verificar se \\(j_0\\) é acessível a partir de \\(i_0\\) em dois passos. Primeiro, vamos determinar todos os estados que podem ser alcançados um passo a frente à partir de \\(i_0\\). Depois, vamos verificar qual destes estados chega em \\(j_0\\). Sem perda de generalidade, assuma que existem \\(n\\) vértices no grafo. Consideremos então a seguinte soma:\n\\[\n\\begin{align}\n\\sum_{l=1}^{n}a_{i_0,l}a_{i,j_0}=a_{i_0,1}a_{1,j_0}+a_{i_0,2}a_{2,j_0}+a_{i_0,3}a_{3,j_0}+\\cdots+a_{i_0,n}a_{n,j_0}\n\\end{align}\n\\tag{6.7}\\]\nSe \\(a_{i_0,1}a_{1,i0}=1\\), então existem os arcos \\((i_0,1)\\) e \\((1,j_0)\\), indicando que existe um caminho em dois passos saindo de \\(i_0\\) e chegando em \\(j_0\\). Se \\(a_{i_0,1}a_{1,j_0}=0\\), então um dos dois arcos não existe, fazendo com que o caminho \\((i_0,1)\\) e \\((1,j_0)\\) não exista. Assim, a soma em Equação 6.7 indica quantos caminhos existem saindo de \\(j_0\\) e chegando a \\(j_0\\) em dois passos. Acontece que Equação 6.7 é exatamente elemento \\((i_0,j_0)\\) do produto matricial \\({\\bf A}{\\bf A}\\). Como \\(i_0\\) e \\(j_0\\) foram escolhidos arbitrariamente, temos que \\[{\\bf A}_2={\\bf A}^2.\\] A demonstração para todo \\(n\\) pode ser concluída facilmente por indução."
  },
  {
    "objectID": "cap_6_notas.html#exercícios",
    "href": "cap_6_notas.html#exercícios",
    "title": "6  Notas",
    "section": "6.7 Exercícios",
    "text": "6.7 Exercícios\n\nSeção 6.2\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.1 Para qualquer \\(n\\geq 0\\) inteiro, mostre que \\[5^n = \\sum_{x=0}^{n}{n\\choose x}2^x 3^{n-x}.\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.2 Mostre que\n\n\\(\\sum_{x=0}^{n}{n\\choose x}=2^n\\)\n\\(\\sum_{x=0}^{n}x{n\\choose x}a^xb^{n-x}=na(a+b)^{n-1}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.3 Assumindo que \\(r\\neq 1\\), demonstre os seguintes resultados:\n\n\\(\\frac{d}{dr}\\sum_{n=0}^{k}r^n=\\sum_{n=0}^{k-1}nr^{n-1}\\)\n\\(\\sum_{n=0}^{k-1}nr^{n-1}=\\frac{kr^{k+1}+1-(k+1)r^k}{(1-r)^2}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.4 Sejam \\(n_1,n_2,n_3\\) inteiros positivos. O conjunto \\(\\{n_1+n_2+n_3=n\\}\\) representa todos os valores possíveis de \\(n_1,n_2\\) e \\(n_3\\) tais que a soma destes é igual a \\(n\\). Assim, encontre todos os elementos dos seguintes conjuntos:\n\n\\(\\{n_1+n_2+n_3=0\\}\\)\n\\(\\{n_1+n_2+n_3=1\\}\\)\n\\(\\{n_1+n_2+n_3=2\\}\\)\n\\(\\{n_1+n_2+n_3=3\\}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.5 Calcule \\[\\sum_{n_1+n_2+n_3+n_4=1}\\frac{n!}{n_1!n_2!n_3!n_4!}2^{n_1}.\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.6 Sejam \\(x_1,x_2,x_3\\) números reais positivos e seja \\(n\\geq 0\\) inteiro. Utilize o Teorema 6.1 para mostrar que \\[(x_1+x_2+x_3)^n=\\sum_{u=0}^{n}{n\\choose u}x_1^u(x_2+x_3)^{n-u}.\\] Em seguida, utilize o Teorema Binomial novamente para mostrar que \\[(x_1+x_2+x_3)^n=\\sum_{u=0}^{n}\\sum_{t=0}^{n-u}{n\\choose u}{n-u\\choose t}x_1^u x_2^tx_3^{n-u-t}.\\] Por último, mostre que a expressão acima é equivalente a \\[(x_1+x_2+x_3)^n=\\sum_{n_1+n_2+n_3=n}\\frac{n!}{n_1!n_2!n_3!}x_1^{n_1} x_2^{n_2}x_3^{n_3}.\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.7 Encontre o valor de \\(c\\) tal que as seguintes funções sejam funções de probabilidade:\n\n\\(P(X=x)=cx,\\quad x\\in\\{0,1,2,\\ldots,N\\}.\\)\n\\(P(X=x)=ce^{-x},\\quad x\\in\\{0,1,2,\\ldots\\}.\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.8 Seja \\(X\\sim\\hbox{Geometrica}_2(q)\\), onde \\[\\begin{equation}\nP(X=x)=q(1-q)^{x-1},\\quad x=1,2,3,\\ldots\n\\end{equation}\\] Utilizando o resultado da soma de uma PG infinita, mostre que\n\n\\(F(x)=(1-q)^{x}\\).\n\\(E(X)=1/q\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.9 Uma função \\(f\\) pode ser escrita via séries de Taylor, da seguinte forma: \\[f(x)=\\sum_{n=0}^{\\infty}\\frac{f^{(n)}(y)}{n!}(x-y)^n,\\] onde \\(y\\) é um ponto no mesmo domínio de \\(x\\) e \\(f^{(n)}\\) é a \\(n\\)-ésima derivada de \\(f\\) (sendo que \\(f^{(0)}=f\\)). Utilizando este resultado, prove que \\[e^{\\lambda}=\\sum_{n=0}^{\\infty} \\frac{\\lambda^n}{n!}.\\]\n\n\n\n\n\n\n\n\n\nExercício 6.10\n\n\n\n\nExercício 6.10 Mostre que, se \\(a\\) for inteiro maior que zero, então \\(\\Gamma(a)=(a-1)!\\)\n\n\n\n\nSeção 6.3\n\n\n\n\n\n\n\nExercício 6.11\n\n\n\n\nExercício 6.11 O número de clientes por hora em uma loja tem distribuição Poisson com taxa 9 clientes/hora. A loja tem capacidade para 13 clientes. Encontre\n\nA probabilidade de que em uma hora existam mais de 10 clientes na loja.\nO número médio de clientes por hora na loja.\nO desvio padrão do número de clientes por hora na loja.\nQuando a loja está cheia, um novo cliente não entra. Qual é a probabilidade de que novos clientes não entrem na loja?\nO dono gostaria de diminuir a probabilidade acima para 5%. Para tanto, qual deveria ser a capacidade da loja?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.12 Seja \\(N\\sim\\hbox{Poisson}(\\lambda)\\), com \\(0<\\lambda<1\\). Mostre que \\(E(N!)=e^{-\\lambda}/(1-\\lambda)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.13 Suponha que \\(Y\\sim\\hbox{Poisson}(\\theta)\\). Calcule \\(E(a^Y)\\), onde \\(a\\) é uma constante.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.14 Sejam \\(N_1,\\ldots,N_d\\) variáveis aleatórias independentes com distribuição Poisson com taxas \\(\\lambda_1,\\ldots,\\lambda_d\\). Mostre que \\((N_1,\\ldots,N_d|N)\\sim\\hbox{Multinomial}(N,p_1,\\ldots,p_d)\\), onde \\(p_i=\\lambda_i/\\sum_{j=0}^d\\lambda_j\\) e \\(N=\\sum_{i=1}^{d}N_i\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.15 Seja \\(X_i\\) o número de acidentes aéreos na região \\(i\\in\\{1,2,3,4\\}\\). Considere que \\(X_i\\sim\\hbox{Poisson}(i)\\) e que \\(X_i\\) é independente de \\(X_j\\) para todo \\(i\\neq j\\). Em certo ano foram registrados \\(12\\) acidentes. Qual a probabilidade de que tenha ocorrido \\((X_1=0,X_2=2,X_3=5,X_4=5)\\)?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.16 Dizemos que \\(X\\sim\\chi^2_n\\) se sua densidade é da forma \\[f(x)=\\frac{1}{2^{n/2}\\Gamma(n/2)}x^{\\frac{n}{2}-1}e^{-x/2}.\\] Mostre que \\(E(X)=n\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.17 Sejam \\(T_1,\\ldots,T_n\\) variáveis aleatórias independentes com distribuição exponencial com taxa \\(\\lambda\\). Seja \\(\\bar{T}=\\sum_{i=1}^{n}T_i/n\\). Mostre que:\n\n\\(\\bar{T}\\sim\\hbox{Gama}(n,n\\lambda)\\);\n\\(\\lambda/\\bar{T}\\sim\\hbox{GI}(n,n)\\) (esse tipo de variável, cuja distribuição não depende do parâmetro, é denominada quantidade pivotal).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.18 Encontre o valor de \\(c\\) para que as seguintes funções sejam densidades: \\[ f(x) = c x^{\\beta(\\alpha+1)-1}e^{-x^\\beta},\\quad \\alpha,\\beta,x>0.\\] Sugestão: faça a transformação \\(u=x^\\beta\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.19 Mostre que \\(M_n=\\min\\{T_1,\\ldots,T_n\\}\\) possui distribuição exponencial com taxa \\(\\lambda_1+\\cdots+\\lambda_n\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.20 Sejam \\(T_1,\\ldots, T_n\\) variáveis aleatórias independentes onde \\(T_i\\sim\\hbox{Exponencial}(\\lambda_i)\\). Mostre que \\(P(T_i < T_j, \\forall j\\neq i)=\\lambda_i/\\lambda\\), onde \\(\\lambda=\\sum_{k=1}^{m}\\lambda_k\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.21 Um campeonato automotivo com \\(m\\) circuitos é disputado por \\(n\\) pilotos. Seja \\(T_ij\\) o tempo que o \\(i\\)-ésimo piloto leva para concluir o \\(j\\)-ésimo circuito. Considere que \\(T_ij\\sim\\hbox{Exponencial}\\), e que todos os tempo são independentes.\n\nSeja \\(W_j\\) o tempo que o vencedor do \\(j\\)-ésimo circuito leva para completar a prova. Encontre o valor médio de \\(W_j\\).\nQual é a probabilidade de que o \\(i\\)-ésimo piloto ganhe todas as provas.\nRefaça o item anterior supondo que todos os pilotos possuem a mesma habilidade.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.22 Dois jogadores disputam uma prova na qual determinada tarefa deve ser concluída no menor tempo possível. O tempo em que o jogador \\(i\\) termina a tarefa possui distribuição exponencial com taxas \\(\\alpha_i\\), \\(i=1,2\\). Considerando estes tempos independentes:\n\nQual é a probabilidade de que o jogador 1 vença a prova?\nQual o tempo médio de conclusão da tarefa do vencedor desta disputa?\nO tempo recorde deste jogo é \\(t^*\\). Qual a probabilidade de que o vencedor da prova bata este recorde?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.23 O \\(k\\)-ésimo momento central de uma variável aleatória é definido por \\(\\mathbb{E}(X-\\mathbb{E}(X))^k\\). Mostre que o \\(k\\)-ésimo momento central de \\(X\\sim\\hbox{Exponencial}(\\lambda)\\) é dado por \\[\\frac{k!}{\\lambda^k}\\sum_{i=0}^{k}\\frac{(-1)^{k-i}}{(k-i)!}\\] Sugestão: use o teorema binomial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.24 Utilize o resultado do exercício anterior para encontrar a variância, assimetria e curtose de \\(X\\sim\\hbox{Exponencial}(\\lambda)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.25 A distribuição exponencial surge em outros contextos. Mostre que \\(-\\lambda\\log U\\), com \\(U\\sim\\hbox{Uniforme}\\) possui distribuição Exponencial\\((1/\\lambda)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.26 Sejam \\(S_1,\\ldots,S_n\\) variáveis aleatórias independentes com distribuição Gama\\((\\alpha_i,\\beta)\\). Mostre que \\(S=S_1+\\cdots+S_n\\sim\\hbox{Gama}(\\sum_{i=1}^{n}\\alpha_i,\\beta)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.27 Seja \\(T\\sim\\hbox{Gama}(n+1,1)\\) e \\(X\\sim\\hbox{Poisson}(\\lambda)\\). Mostre que \\(P(T>\\lambda)=P(X\\leq n)\\). Sugestão: integre \\(\\mathbb{P}(T>\\lambda)\\) por partes, semelhante ao que foi feito para mostrar que \\(\\Gamma(a+1)=a\\Gamma(a)\\).\n\n\n\n\nSeção 6.4\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.28 O número de terremotos em uma determinada cidade possui distribuição Poisson com taxa 3 terremotos por década.\n\nQual o número esperado de terremotos por década?\nCalcule a probabilidade de que, em uma década qualquer, não tenham ocorrido terremotos.\nSejam \\(\\mu\\) e \\(\\sigma\\) a média e o desvio-padrão do prejuízo devido a um terremoto. Calcule a média e a variância do prejuízo causado por terremotos durante uma década qualquer. (suponha que os prejuízos são independentes e identicamente distribuídos).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.29 Seja \\((Y|X)\\sim\\hbox{Poisson}(\\exp\\{\\alpha+\\beta X\\})\\) e seja \\(X\\sim\\hbox{Poisson}(\\lambda)\\). Encontre o valor esperado de \\(Y\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.30 Seja \\(T\\sim\\hbox{Exponencial}(\\lambda)\\) o tempo corrido até a ocorrência de certo evento. Seja \\(X_i=1\\) se o evento ocorreu no intervalo \\((i,i+1]\\) e \\(X_i=0\\) em caso contrário, com \\(i=0,1,2,\\ldots\\).\n\nQual é a distribuição de \\(X_i\\)?\nEncontre a distribuição de \\(\\sum_{j=0}^{n}X_j\\).\n\n\n\n\n\nSeção 6.6\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.31 Considere o seguinte grafo:\n\n\n\n\n\n\n\n\n\nRelativo ao grafo acima:\n\nEscreva seu conjunto de vértices e arcos.\nConstrua sua matriz de adjacências e denote-a por \\(A\\).\nEncontre \\(A^2\\). O que significa cada valor desta matriz?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.32 Considere o seguinte grafo:\n\n\n\n\n\n\n\n\n\nRelativo ao grafo acima:\n\nEscreva seu conjunto de vértices e arcos.\nConstrua sua matriz de adjacências e denote-a por \\(A\\).\nEncontre \\(A^2\\) e \\(A^3\\). Compare estes valores e interprete-os.\nUse o resultado anterior para provar que \\(A^n=A^2\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercício 6.33 A figura abaixo representa um lago com 9 vitórias régias. Um sapo se movimenta exclusivamente saltando entre uma planta e outra. Estando em uma vitória régia no tempo \\(n\\), ele faz um deslocamento no tempo \\(n+1\\) para uma das plantas vizinhas, nunca saltando na diagonal.\n\n\n\n\n\n\n\n\n\nConstrua um grafo que mostra a localização do sapo no tempo \\(n\\) e seu deslocamento no tempo \\(n+1\\). Especificamente:\n\nConstrua um conjunto de vértices e de arestas adequado.\nConstrua a matriz de adjacências (matriz de um passo à frente).\nFaça a representação gráfica deste grafo."
  }
]